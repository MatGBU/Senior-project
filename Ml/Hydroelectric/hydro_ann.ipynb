{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydro ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avishai\\AppData\\Local\\Temp\\ipykernel_59096\\2660157751.py:6: DtypeWarning: Columns (12,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('C:/Users/Avishai/Desktop/Senior-project/Two_Year_Training_Set.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv('C:/Users/Avishai/Desktop/Senior-project/Two_Year_Training_Set.csv')\n",
    "data = data.fillna(0)\n",
    "data['BeginDate'] = pd.to_datetime(data['BeginDate']).dt.tz_localize(None)\n",
    "data[\"Sum\"] = data[[\"Coal\", \"Hydro\", \"Natural Gas\", \"Nuclear\", \"Oil\", \"Other\", \"Landfill Gas\", \"Refuse\", \"Solar\", \"Wind\", \"Wood\"]].sum(axis=1)\n",
    "data['Previous_Day'] = data['BeginDate'] - pd.Timedelta(days=1)\n",
    "data['Previous_2Day'] = data['BeginDate'] - pd.Timedelta(days=2)\n",
    "data['Previous_Year'] = data['BeginDate'] - pd.DateOffset(years=1)\n",
    "wind_data = data[['BeginDate', 'Hydro','Previous_Day','Previous_Year','Previous_2Day']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_day_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Hydro'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Day']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_two_days_before_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Hydro'].values\n",
    "    \n",
    "    # Calculate two days before\n",
    "    target_date = row['BeginDate'] - pd.Timedelta(days=2)\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_year_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Hydro'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Year']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large computation \n",
    "data['Previous_Year_Hydro'] = data.apply(get_previous_year_Wind, axis=1, reference_df=wind_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"2024-9-01\").tz_localize(None)\n",
    "usable_data = data[data['BeginDate'] > cutoff_date].copy()\n",
    "solar_data2 = usable_data[['BeginDate', 'Hydro','Previous_Day','Previous_2Day','Previous_Year']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "usable_data['Previous_Day_Hydro'] = usable_data.apply(get_previous_day_Wind, axis=1, reference_df=solar_data2)\n",
    "usable_data['Previous_2Day_Hydro'] = usable_data.apply(get_two_days_before_Wind, axis=1, reference_df=solar_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (13618, 18)\n",
      "Target shape:  (13618,)\n"
     ]
    }
   ],
   "source": [
    "usable_data['Hour_of_Day'] = usable_data['BeginDate'].dt.hour\n",
    "usable_data['Year'] = usable_data['BeginDate'].dt.year\n",
    "usable_data['Month'] = usable_data['BeginDate'].dt.month\n",
    "features = usable_data[['Month','Previous_Day_Hydro','Previous_2Day_Hydro','Sum','Hour_of_Day','Previous_Year_Hydro','solarradiation','Year','precip','humidity','temp','dew','snow','snowdepth','windspeed','sealevelpressure','cloudcover','severerisk']]\n",
    "\n",
    "# Useless Features , ,\n",
    "target = usable_data['Hydro']\n",
    "\n",
    "print(\"Features shape: \", features.shape)\n",
    "print('Target shape: ', target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avishai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Avishai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 522.5999 - val_loss: 509.4709 - learning_rate: 0.0010\n",
      "Epoch 2/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 521.4667 - val_loss: 507.3302 - learning_rate: 0.0010\n",
      "Epoch 3/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 521.4900 - val_loss: 504.5285 - learning_rate: 0.0010\n",
      "Epoch 4/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 517.3265 - val_loss: 501.2844 - learning_rate: 0.0010\n",
      "Epoch 5/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 509.5828 - val_loss: 497.4137 - learning_rate: 0.0010\n",
      "Epoch 6/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 506.9575 - val_loss: 492.7581 - learning_rate: 0.0010\n",
      "Epoch 7/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 504.6796 - val_loss: 486.9525 - learning_rate: 0.0010\n",
      "Epoch 8/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 494.8164 - val_loss: 479.8057 - learning_rate: 0.0010\n",
      "Epoch 9/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 487.7871 - val_loss: 473.0805 - learning_rate: 0.0010\n",
      "Epoch 10/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 478.8281 - val_loss: 464.9377 - learning_rate: 0.0010\n",
      "Epoch 11/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 472.2817 - val_loss: 457.3965 - learning_rate: 0.0010\n",
      "Epoch 12/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 466.7397 - val_loss: 447.0698 - learning_rate: 0.0010\n",
      "Epoch 13/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 455.4186 - val_loss: 434.7503 - learning_rate: 0.0010\n",
      "Epoch 14/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 445.3196 - val_loss: 422.1444 - learning_rate: 0.0010\n",
      "Epoch 15/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 424.1326 - val_loss: 411.3486 - learning_rate: 0.0010\n",
      "Epoch 16/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 415.8975 - val_loss: 398.4456 - learning_rate: 0.0010\n",
      "Epoch 17/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 402.7596 - val_loss: 386.3668 - learning_rate: 0.0010\n",
      "Epoch 18/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.6364 - val_loss: 373.5867 - learning_rate: 0.0010\n",
      "Epoch 19/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 380.4034 - val_loss: 359.1548 - learning_rate: 0.0010\n",
      "Epoch 20/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 360.8922 - val_loss: 342.4752 - learning_rate: 0.0010\n",
      "Epoch 21/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 348.8113 - val_loss: 324.3335 - learning_rate: 0.0010\n",
      "Epoch 22/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 334.4982 - val_loss: 429.0865 - learning_rate: 0.0010\n",
      "Epoch 23/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 312.0888 - val_loss: 291.4893 - learning_rate: 0.0010\n",
      "Epoch 24/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 302.1751 - val_loss: 277.6691 - learning_rate: 0.0010\n",
      "Epoch 25/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 277.7708 - val_loss: 261.7377 - learning_rate: 0.0010\n",
      "Epoch 26/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 260.7817 - val_loss: 237.4544 - learning_rate: 0.0010\n",
      "Epoch 27/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 250.4104 - val_loss: 212.2217 - learning_rate: 0.0010\n",
      "Epoch 28/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 231.1105 - val_loss: 199.8650 - learning_rate: 0.0010\n",
      "Epoch 29/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 216.9304 - val_loss: 185.5132 - learning_rate: 0.0010\n",
      "Epoch 30/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 203.3993 - val_loss: 174.0142 - learning_rate: 0.0010\n",
      "Epoch 31/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 185.0941 - val_loss: 166.1620 - learning_rate: 0.0010\n",
      "Epoch 32/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 168.4460 - val_loss: 156.4283 - learning_rate: 0.0010\n",
      "Epoch 33/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161.5852 - val_loss: 155.1381 - learning_rate: 0.0010\n",
      "Epoch 34/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156.1889 - val_loss: 141.1365 - learning_rate: 0.0010\n",
      "Epoch 35/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146.0801 - val_loss: 130.6442 - learning_rate: 0.0010\n",
      "Epoch 36/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141.5272 - val_loss: 131.8665 - learning_rate: 0.0010\n",
      "Epoch 37/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133.6124 - val_loss: 112.1858 - learning_rate: 0.0010\n",
      "Epoch 38/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123.4187 - val_loss: 114.9245 - learning_rate: 0.0010\n",
      "Epoch 39/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.9103 - val_loss: 102.9270 - learning_rate: 0.0010\n",
      "Epoch 40/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109.0808 - val_loss: 105.7996 - learning_rate: 0.0010\n",
      "Epoch 41/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109.2589 - val_loss: 92.5685 - learning_rate: 0.0010\n",
      "Epoch 42/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.1784 - val_loss: 93.5278 - learning_rate: 0.0010\n",
      "Epoch 43/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 100.5116 - val_loss: 83.5230 - learning_rate: 0.0010\n",
      "Epoch 44/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 97.6469 - val_loss: 84.3713 - learning_rate: 0.0010\n",
      "Epoch 45/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 95.2074 - val_loss: 82.4825 - learning_rate: 0.0010\n",
      "Epoch 46/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 96.7827 - val_loss: 76.3699 - learning_rate: 0.0010\n",
      "Epoch 47/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 93.6129 - val_loss: 78.2593 - learning_rate: 0.0010\n",
      "Epoch 48/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 91.2122 - val_loss: 72.2939 - learning_rate: 0.0010\n",
      "Epoch 49/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 87.7784 - val_loss: 80.3448 - learning_rate: 0.0010\n",
      "Epoch 50/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 86.9426 - val_loss: 77.0603 - learning_rate: 0.0010\n",
      "Epoch 51/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 89.7943 - val_loss: 70.7625 - learning_rate: 0.0010\n",
      "Epoch 52/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 87.0277 - val_loss: 65.8572 - learning_rate: 0.0010\n",
      "Epoch 53/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 83.4514 - val_loss: 66.2854 - learning_rate: 0.0010\n",
      "Epoch 54/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 84.2311 - val_loss: 65.9721 - learning_rate: 0.0010\n",
      "Epoch 55/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.9496 - val_loss: 66.5353 - learning_rate: 0.0010\n",
      "Epoch 56/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.7911 - val_loss: 69.2592 - learning_rate: 0.0010\n",
      "Epoch 57/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 81.4259 - val_loss: 64.4987 - learning_rate: 0.0010\n",
      "Epoch 58/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.8265 - val_loss: 65.7548 - learning_rate: 0.0010\n",
      "Epoch 59/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.5879 - val_loss: 65.3510 - learning_rate: 0.0010\n",
      "Epoch 60/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.9481 - val_loss: 62.6566 - learning_rate: 0.0010\n",
      "Epoch 61/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.4308 - val_loss: 62.9989 - learning_rate: 0.0010\n",
      "Epoch 62/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.6697 - val_loss: 71.7180 - learning_rate: 0.0010\n",
      "Epoch 63/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.1825 - val_loss: 64.1224 - learning_rate: 0.0010\n",
      "Epoch 64/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.8505 - val_loss: 60.2317 - learning_rate: 0.0010\n",
      "Epoch 65/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.3989 - val_loss: 66.3903 - learning_rate: 0.0010\n",
      "Epoch 66/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.0788 - val_loss: 70.7231 - learning_rate: 0.0010\n",
      "Epoch 67/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.6383 - val_loss: 61.3234 - learning_rate: 0.0010\n",
      "Epoch 68/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.7528 - val_loss: 61.0727 - learning_rate: 0.0010\n",
      "Epoch 69/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 77.6165 - val_loss: 61.3316 - learning_rate: 0.0010\n",
      "Epoch 70/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 73.7433 - val_loss: 58.7055 - learning_rate: 0.0010\n",
      "Epoch 71/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.4501 - val_loss: 63.3885 - learning_rate: 0.0010\n",
      "Epoch 72/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 75.3249 - val_loss: 58.9267 - learning_rate: 0.0010\n",
      "Epoch 73/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.6409 - val_loss: 58.3085 - learning_rate: 0.0010\n",
      "Epoch 74/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.8792 - val_loss: 57.4467 - learning_rate: 0.0010\n",
      "Epoch 75/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.0562 - val_loss: 61.6197 - learning_rate: 0.0010\n",
      "Epoch 76/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 77.2952 - val_loss: 57.1272 - learning_rate: 0.0010\n",
      "Epoch 77/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.8952 - val_loss: 63.9603 - learning_rate: 0.0010\n",
      "Epoch 78/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.4716 - val_loss: 64.3253 - learning_rate: 0.0010\n",
      "Epoch 79/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.8742 - val_loss: 63.4191 - learning_rate: 0.0010\n",
      "Epoch 80/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 75.5365 - val_loss: 59.1061 - learning_rate: 0.0010\n",
      "Epoch 81/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.2160 - val_loss: 57.6958 - learning_rate: 0.0010\n",
      "Epoch 82/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.1831 - val_loss: 59.3487 - learning_rate: 0.0010\n",
      "Epoch 83/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.1077 - val_loss: 58.2043 - learning_rate: 0.0010\n",
      "Epoch 84/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.7652 - val_loss: 61.7630 - learning_rate: 0.0010\n",
      "Epoch 85/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 75.9821 - val_loss: 56.0721 - learning_rate: 0.0010\n",
      "Epoch 86/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.4000 - val_loss: 60.6391 - learning_rate: 0.0010\n",
      "Epoch 87/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.2270 - val_loss: 58.0753 - learning_rate: 0.0010\n",
      "Epoch 88/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 75.0292 - val_loss: 57.4748 - learning_rate: 0.0010\n",
      "Epoch 89/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.5464 - val_loss: 58.5829 - learning_rate: 0.0010\n",
      "Epoch 90/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.9408 - val_loss: 57.3660 - learning_rate: 0.0010\n",
      "Epoch 91/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.4984 - val_loss: 53.4592 - learning_rate: 0.0010\n",
      "Epoch 92/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 75.0289 - val_loss: 56.0587 - learning_rate: 0.0010\n",
      "Epoch 93/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.7996 - val_loss: 56.5617 - learning_rate: 0.0010\n",
      "Epoch 94/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.7709 - val_loss: 56.8161 - learning_rate: 0.0010\n",
      "Epoch 95/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.8624 - val_loss: 58.7890 - learning_rate: 0.0010\n",
      "Epoch 96/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.3190 - val_loss: 55.7390 - learning_rate: 0.0010\n",
      "Epoch 97/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.7686 - val_loss: 54.6596 - learning_rate: 0.0010\n",
      "Epoch 98/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.0457 - val_loss: 61.3592 - learning_rate: 0.0010\n",
      "Epoch 99/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.3970 - val_loss: 54.4653 - learning_rate: 0.0010\n",
      "Epoch 100/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.6752 - val_loss: 54.1640 - learning_rate: 0.0010\n",
      "Epoch 101/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.7752 - val_loss: 55.7227 - learning_rate: 0.0010\n",
      "Epoch 102/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.1953 - val_loss: 53.0963 - learning_rate: 5.0000e-04\n",
      "Epoch 103/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.1165 - val_loss: 51.4890 - learning_rate: 5.0000e-04\n",
      "Epoch 104/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.4056 - val_loss: 56.1519 - learning_rate: 5.0000e-04\n",
      "Epoch 105/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.9367 - val_loss: 51.1415 - learning_rate: 5.0000e-04\n",
      "Epoch 106/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.5350 - val_loss: 53.6271 - learning_rate: 5.0000e-04\n",
      "Epoch 107/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.9483 - val_loss: 52.7298 - learning_rate: 5.0000e-04\n",
      "Epoch 108/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.7809 - val_loss: 52.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 109/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.2784 - val_loss: 51.6782 - learning_rate: 5.0000e-04\n",
      "Epoch 110/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.7466 - val_loss: 53.1677 - learning_rate: 5.0000e-04\n",
      "Epoch 111/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.4087 - val_loss: 49.5707 - learning_rate: 5.0000e-04\n",
      "Epoch 112/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.3525 - val_loss: 50.4746 - learning_rate: 5.0000e-04\n",
      "Epoch 113/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.0901 - val_loss: 52.8735 - learning_rate: 5.0000e-04\n",
      "Epoch 114/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.8476 - val_loss: 50.4377 - learning_rate: 5.0000e-04\n",
      "Epoch 115/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.1039 - val_loss: 52.4339 - learning_rate: 5.0000e-04\n",
      "Epoch 116/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2288 - val_loss: 49.6115 - learning_rate: 5.0000e-04\n",
      "Epoch 117/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.1350 - val_loss: 50.4975 - learning_rate: 5.0000e-04\n",
      "Epoch 118/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.1146 - val_loss: 50.2092 - learning_rate: 5.0000e-04\n",
      "Epoch 119/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.0448 - val_loss: 49.7577 - learning_rate: 5.0000e-04\n",
      "Epoch 120/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.5257 - val_loss: 48.7087 - learning_rate: 5.0000e-04\n",
      "Epoch 121/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.8520 - val_loss: 50.7950 - learning_rate: 5.0000e-04\n",
      "Epoch 122/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.3230 - val_loss: 47.8082 - learning_rate: 5.0000e-04\n",
      "Epoch 123/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.4545 - val_loss: 49.8419 - learning_rate: 5.0000e-04\n",
      "Epoch 124/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.6232 - val_loss: 55.0495 - learning_rate: 5.0000e-04\n",
      "Epoch 125/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.1031 - val_loss: 48.4885 - learning_rate: 5.0000e-04\n",
      "Epoch 126/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.9204 - val_loss: 49.8659 - learning_rate: 5.0000e-04\n",
      "Epoch 127/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.4946 - val_loss: 50.9220 - learning_rate: 5.0000e-04\n",
      "Epoch 128/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.2708 - val_loss: 48.3981 - learning_rate: 5.0000e-04\n",
      "Epoch 129/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.8858 - val_loss: 48.6866 - learning_rate: 5.0000e-04\n",
      "Epoch 130/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.0971 - val_loss: 48.3721 - learning_rate: 5.0000e-04\n",
      "Epoch 131/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.2226 - val_loss: 50.5624 - learning_rate: 5.0000e-04\n",
      "Epoch 132/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.3055 - val_loss: 52.1802 - learning_rate: 5.0000e-04\n",
      "Epoch 133/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.3874 - val_loss: 48.9983 - learning_rate: 2.5000e-04\n",
      "Epoch 134/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.9404 - val_loss: 46.2274 - learning_rate: 2.5000e-04\n",
      "Epoch 135/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.5719 - val_loss: 46.4121 - learning_rate: 2.5000e-04\n",
      "Epoch 136/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.4993 - val_loss: 47.0687 - learning_rate: 2.5000e-04\n",
      "Epoch 137/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7730 - val_loss: 46.8049 - learning_rate: 2.5000e-04\n",
      "Epoch 138/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.7431 - val_loss: 47.3101 - learning_rate: 2.5000e-04\n",
      "Epoch 139/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.9242 - val_loss: 46.4403 - learning_rate: 2.5000e-04\n",
      "Epoch 140/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.6464 - val_loss: 48.8058 - learning_rate: 2.5000e-04\n",
      "Epoch 141/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7505 - val_loss: 47.1935 - learning_rate: 2.5000e-04\n",
      "Epoch 142/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.0590 - val_loss: 47.8061 - learning_rate: 2.5000e-04\n",
      "Epoch 143/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.2109 - val_loss: 51.1601 - learning_rate: 2.5000e-04\n",
      "Epoch 144/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9685 - val_loss: 48.3606 - learning_rate: 2.5000e-04\n",
      "Epoch 145/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.3724 - val_loss: 46.7126 - learning_rate: 1.2500e-04\n",
      "Epoch 146/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.9248 - val_loss: 48.9470 - learning_rate: 1.2500e-04\n",
      "Epoch 147/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7547 - val_loss: 46.3417 - learning_rate: 1.2500e-04\n",
      "Epoch 148/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.3928 - val_loss: 46.9028 - learning_rate: 1.2500e-04\n",
      "Epoch 149/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2088 - val_loss: 46.4164 - learning_rate: 1.2500e-04\n",
      "Epoch 150/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.1782 - val_loss: 46.5404 - learning_rate: 1.2500e-04\n",
      "Epoch 151/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.0681 - val_loss: 48.7635 - learning_rate: 1.2500e-04\n",
      "Epoch 152/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.4583 - val_loss: 45.4366 - learning_rate: 1.2500e-04\n",
      "Epoch 153/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.8792 - val_loss: 45.4175 - learning_rate: 1.2500e-04\n",
      "Epoch 154/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.5630 - val_loss: 45.5414 - learning_rate: 1.2500e-04\n",
      "Epoch 155/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.4216 - val_loss: 45.7226 - learning_rate: 1.2500e-04\n",
      "Epoch 156/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7961 - val_loss: 45.4009 - learning_rate: 1.2500e-04\n",
      "Epoch 157/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.5511 - val_loss: 46.7126 - learning_rate: 1.2500e-04\n",
      "Epoch 158/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.5796 - val_loss: 45.2343 - learning_rate: 1.2500e-04\n",
      "Epoch 159/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7994 - val_loss: 46.3031 - learning_rate: 1.2500e-04\n",
      "Epoch 160/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.4398 - val_loss: 46.3306 - learning_rate: 1.2500e-04\n",
      "Epoch 161/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8672 - val_loss: 45.8236 - learning_rate: 1.2500e-04\n",
      "Epoch 162/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.7224 - val_loss: 45.5373 - learning_rate: 1.2500e-04\n",
      "Epoch 163/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.3401 - val_loss: 45.4960 - learning_rate: 1.2500e-04\n",
      "Epoch 164/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1246 - val_loss: 44.9524 - learning_rate: 1.2500e-04\n",
      "Epoch 165/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.0178 - val_loss: 45.2850 - learning_rate: 1.2500e-04\n",
      "Epoch 166/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6488 - val_loss: 46.1273 - learning_rate: 1.2500e-04\n",
      "Epoch 167/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.5086 - val_loss: 45.4366 - learning_rate: 1.2500e-04\n",
      "Epoch 168/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8373 - val_loss: 46.0528 - learning_rate: 1.2500e-04\n",
      "Epoch 169/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.1702 - val_loss: 46.4835 - learning_rate: 1.2500e-04\n",
      "Epoch 170/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2512 - val_loss: 45.2405 - learning_rate: 1.2500e-04\n",
      "Epoch 171/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.3794 - val_loss: 44.9576 - learning_rate: 1.2500e-04\n",
      "Epoch 172/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.4581 - val_loss: 45.3419 - learning_rate: 1.2500e-04\n",
      "Epoch 173/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.8793 - val_loss: 44.7433 - learning_rate: 1.2500e-04\n",
      "Epoch 174/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.3248 - val_loss: 44.8558 - learning_rate: 1.2500e-04\n",
      "Epoch 175/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.9839 - val_loss: 45.9430 - learning_rate: 1.2500e-04\n",
      "Epoch 176/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.2467 - val_loss: 45.3231 - learning_rate: 1.2500e-04\n",
      "Epoch 177/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.7743 - val_loss: 46.5862 - learning_rate: 1.2500e-04\n",
      "Epoch 178/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7668 - val_loss: 45.4681 - learning_rate: 1.2500e-04\n",
      "Epoch 179/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.3691 - val_loss: 46.0400 - learning_rate: 1.2500e-04\n",
      "Epoch 180/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.7735 - val_loss: 45.6729 - learning_rate: 1.2500e-04\n",
      "Epoch 181/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6183 - val_loss: 44.9196 - learning_rate: 1.2500e-04\n",
      "Epoch 182/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6430 - val_loss: 45.1633 - learning_rate: 1.2500e-04\n",
      "Epoch 183/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6230 - val_loss: 44.5024 - learning_rate: 1.2500e-04\n",
      "Epoch 184/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.0009 - val_loss: 45.4869 - learning_rate: 1.2500e-04\n",
      "Epoch 185/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.4818 - val_loss: 44.8103 - learning_rate: 1.2500e-04\n",
      "Epoch 186/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9057 - val_loss: 45.4047 - learning_rate: 1.2500e-04\n",
      "Epoch 187/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2597 - val_loss: 46.3572 - learning_rate: 1.2500e-04\n",
      "Epoch 188/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4542 - val_loss: 46.3457 - learning_rate: 1.2500e-04\n",
      "Epoch 189/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.2186 - val_loss: 45.1184 - learning_rate: 1.2500e-04\n",
      "Epoch 190/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4931 - val_loss: 45.1556 - learning_rate: 1.2500e-04\n",
      "Epoch 191/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.5767 - val_loss: 44.8184 - learning_rate: 1.2500e-04\n",
      "Epoch 192/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.8537 - val_loss: 44.1812 - learning_rate: 1.2500e-04\n",
      "Epoch 193/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.1740 - val_loss: 47.1655 - learning_rate: 1.2500e-04\n",
      "Epoch 194/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8219 - val_loss: 44.4378 - learning_rate: 1.2500e-04\n",
      "Epoch 195/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1433 - val_loss: 45.0969 - learning_rate: 1.2500e-04\n",
      "Epoch 196/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.0782 - val_loss: 47.0305 - learning_rate: 1.2500e-04\n",
      "Epoch 197/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1706 - val_loss: 45.0772 - learning_rate: 1.2500e-04\n",
      "Epoch 198/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.3595 - val_loss: 44.3109 - learning_rate: 1.2500e-04\n",
      "Epoch 199/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1587 - val_loss: 44.2267 - learning_rate: 1.2500e-04\n",
      "Epoch 200/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.8360 - val_loss: 46.3143 - learning_rate: 1.2500e-04\n",
      "Epoch 201/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.4184 - val_loss: 45.4251 - learning_rate: 1.2500e-04\n",
      "Epoch 202/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8605 - val_loss: 44.6513 - learning_rate: 1.2500e-04\n",
      "Epoch 203/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.6428 - val_loss: 45.5456 - learning_rate: 6.2500e-05\n",
      "Epoch 204/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.5502 - val_loss: 45.4688 - learning_rate: 6.2500e-05\n",
      "Epoch 205/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.5900 - val_loss: 44.4744 - learning_rate: 6.2500e-05\n",
      "Epoch 206/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.5285 - val_loss: 44.4261 - learning_rate: 6.2500e-05\n",
      "Epoch 207/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.4116 - val_loss: 44.3883 - learning_rate: 6.2500e-05\n",
      "Epoch 208/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8183 - val_loss: 44.8261 - learning_rate: 6.2500e-05\n",
      "Epoch 209/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9850 - val_loss: 44.8039 - learning_rate: 6.2500e-05\n",
      "Epoch 210/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.0645 - val_loss: 45.0891 - learning_rate: 6.2500e-05\n",
      "Epoch 211/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1267 - val_loss: 44.0826 - learning_rate: 6.2500e-05\n",
      "Epoch 212/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.2036 - val_loss: 44.7237 - learning_rate: 6.2500e-05\n",
      "Epoch 213/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.3087 - val_loss: 46.1759 - learning_rate: 6.2500e-05\n",
      "Epoch 214/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.6947 - val_loss: 44.2999 - learning_rate: 6.2500e-05\n",
      "Epoch 215/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8279 - val_loss: 44.8942 - learning_rate: 6.2500e-05\n",
      "Epoch 216/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.1989 - val_loss: 44.3846 - learning_rate: 6.2500e-05\n",
      "Epoch 217/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.2064 - val_loss: 44.3342 - learning_rate: 6.2500e-05\n",
      "Epoch 218/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.8772 - val_loss: 45.0695 - learning_rate: 6.2500e-05\n",
      "Epoch 219/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.5182 - val_loss: 44.8376 - learning_rate: 6.2500e-05\n",
      "Epoch 220/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2997 - val_loss: 44.7003 - learning_rate: 6.2500e-05\n",
      "Epoch 221/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.5020 - val_loss: 45.0455 - learning_rate: 6.2500e-05\n",
      "Epoch 222/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.9412 - val_loss: 44.2930 - learning_rate: 3.1250e-05\n",
      "Epoch 223/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.2673 - val_loss: 44.0449 - learning_rate: 3.1250e-05\n",
      "Epoch 224/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9055 - val_loss: 44.5364 - learning_rate: 3.1250e-05\n",
      "Epoch 225/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.3199 - val_loss: 44.3228 - learning_rate: 3.1250e-05\n",
      "Epoch 226/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8519 - val_loss: 44.5397 - learning_rate: 3.1250e-05\n",
      "Epoch 227/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.9307 - val_loss: 44.3496 - learning_rate: 3.1250e-05\n",
      "Epoch 228/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8258 - val_loss: 43.4906 - learning_rate: 3.1250e-05\n",
      "Epoch 229/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.8520 - val_loss: 43.9164 - learning_rate: 3.1250e-05\n",
      "Epoch 230/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.3114 - val_loss: 44.4749 - learning_rate: 3.1250e-05\n",
      "Epoch 231/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.3181 - val_loss: 43.8652 - learning_rate: 3.1250e-05\n",
      "Epoch 232/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.9264 - val_loss: 44.3815 - learning_rate: 3.1250e-05\n",
      "Epoch 233/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.0594 - val_loss: 44.5903 - learning_rate: 3.1250e-05\n",
      "Epoch 234/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2089 - val_loss: 43.8701 - learning_rate: 3.1250e-05\n",
      "Epoch 235/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.5746 - val_loss: 44.0707 - learning_rate: 3.1250e-05\n",
      "Epoch 236/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1771 - val_loss: 44.3868 - learning_rate: 3.1250e-05\n",
      "Epoch 237/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.7742 - val_loss: 44.2811 - learning_rate: 3.1250e-05\n",
      "Epoch 238/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.4155 - val_loss: 44.2766 - learning_rate: 3.1250e-05\n",
      "Epoch 239/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5448 - val_loss: 44.2776 - learning_rate: 1.5625e-05\n",
      "Epoch 240/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2614 - val_loss: 43.9935 - learning_rate: 1.5625e-05\n",
      "Epoch 241/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.6126 - val_loss: 44.0333 - learning_rate: 1.5625e-05\n",
      "Epoch 242/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.3442 - val_loss: 44.0306 - learning_rate: 1.5625e-05\n",
      "Epoch 243/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1474 - val_loss: 44.5422 - learning_rate: 1.5625e-05\n",
      "Epoch 244/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.9386 - val_loss: 44.4699 - learning_rate: 1.5625e-05\n",
      "Epoch 245/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2107 - val_loss: 44.0100 - learning_rate: 1.5625e-05\n",
      "Epoch 246/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.3764 - val_loss: 44.0452 - learning_rate: 1.5625e-05\n",
      "Epoch 247/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.1201 - val_loss: 44.0034 - learning_rate: 1.5625e-05\n",
      "Epoch 248/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.8546 - val_loss: 43.9419 - learning_rate: 1.5625e-05\n",
      "Epoch 249/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6561 - val_loss: 43.8390 - learning_rate: 7.8125e-06\n",
      "Epoch 250/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8198 - val_loss: 43.7313 - learning_rate: 7.8125e-06\n",
      "Epoch 251/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.3869 - val_loss: 43.8994 - learning_rate: 7.8125e-06\n",
      "Epoch 252/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4500 - val_loss: 43.9877 - learning_rate: 7.8125e-06\n",
      "Epoch 253/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8512 - val_loss: 43.9886 - learning_rate: 7.8125e-06\n",
      "Epoch 254/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2785 - val_loss: 43.8172 - learning_rate: 7.8125e-06\n",
      "Epoch 255/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.0946 - val_loss: 44.0192 - learning_rate: 7.8125e-06\n",
      "Epoch 256/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.6309 - val_loss: 43.8993 - learning_rate: 7.8125e-06\n",
      "Epoch 257/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.1570 - val_loss: 43.7693 - learning_rate: 7.8125e-06\n",
      "Epoch 258/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.7133 - val_loss: 44.0521 - learning_rate: 7.8125e-06\n",
      "Epoch 259/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7359 - val_loss: 43.9415 - learning_rate: 3.9063e-06\n",
      "Epoch 260/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1165 - val_loss: 43.9901 - learning_rate: 3.9063e-06\n",
      "Epoch 261/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1636 - val_loss: 44.0477 - learning_rate: 3.9063e-06\n",
      "Epoch 262/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.7633 - val_loss: 44.2256 - learning_rate: 3.9063e-06\n",
      "Epoch 263/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7670 - val_loss: 44.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 264/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.9103 - val_loss: 44.0392 - learning_rate: 3.9063e-06\n",
      "Epoch 265/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.7900 - val_loss: 44.0036 - learning_rate: 3.9063e-06\n",
      "Epoch 266/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.5783 - val_loss: 44.0942 - learning_rate: 3.9063e-06\n",
      "Epoch 267/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7558 - val_loss: 43.9342 - learning_rate: 3.9063e-06\n",
      "Epoch 268/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.4525 - val_loss: 44.0370 - learning_rate: 3.9063e-06\n",
      "Epoch 269/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.9252 - val_loss: 43.9021 - learning_rate: 1.9531e-06\n",
      "Epoch 270/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6702 - val_loss: 43.7836 - learning_rate: 1.9531e-06\n",
      "Epoch 271/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.4495 - val_loss: 43.8454 - learning_rate: 1.9531e-06\n",
      "Epoch 272/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.4521 - val_loss: 43.9197 - learning_rate: 1.9531e-06\n",
      "Epoch 273/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2732 - val_loss: 44.0097 - learning_rate: 1.9531e-06\n",
      "Epoch 274/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2124 - val_loss: 43.9128 - learning_rate: 1.9531e-06\n",
      "Epoch 275/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0045 - val_loss: 43.8137 - learning_rate: 1.9531e-06\n",
      "Epoch 276/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7030 - val_loss: 43.8694 - learning_rate: 1.9531e-06\n",
      "Epoch 277/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7586 - val_loss: 43.5733 - learning_rate: 1.9531e-06\n",
      "Epoch 278/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2089 - val_loss: 43.6913 - learning_rate: 1.9531e-06\n",
      "Epoch 279/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7836 - val_loss: 43.7836 - learning_rate: 1.0000e-06\n",
      "Epoch 280/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.2835 - val_loss: 43.7540 - learning_rate: 1.0000e-06\n",
      "Epoch 281/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6842 - val_loss: 43.8603 - learning_rate: 1.0000e-06\n",
      "Epoch 282/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.0028 - val_loss: 43.7540 - learning_rate: 1.0000e-06\n",
      "Epoch 283/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7807 - val_loss: 43.7433 - learning_rate: 1.0000e-06\n",
      "Epoch 284/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5173 - val_loss: 43.8582 - learning_rate: 1.0000e-06\n",
      "Epoch 285/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1064 - val_loss: 43.9809 - learning_rate: 1.0000e-06\n",
      "Epoch 286/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.5620 - val_loss: 44.0161 - learning_rate: 1.0000e-06\n",
      "Epoch 287/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.3879 - val_loss: 43.8513 - learning_rate: 1.0000e-06\n",
      "Epoch 288/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7952 - val_loss: 43.8717 - learning_rate: 1.0000e-06\n",
      "Epoch 289/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7774 - val_loss: 43.9166 - learning_rate: 1.0000e-06\n",
      "Epoch 290/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.5371 - val_loss: 43.7321 - learning_rate: 1.0000e-06\n",
      "Epoch 291/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.3913 - val_loss: 43.7982 - learning_rate: 1.0000e-06\n",
      "Epoch 292/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.9136 - val_loss: 43.8558 - learning_rate: 1.0000e-06\n",
      "Epoch 293/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7204 - val_loss: 43.8282 - learning_rate: 1.0000e-06\n",
      "Epoch 294/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.0003 - val_loss: 43.8361 - learning_rate: 1.0000e-06\n",
      "Epoch 295/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.4038 - val_loss: 43.7282 - learning_rate: 1.0000e-06\n",
      "Epoch 296/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.9985 - val_loss: 43.8203 - learning_rate: 1.0000e-06\n",
      "Epoch 297/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7874 - val_loss: 43.6644 - learning_rate: 1.0000e-06\n",
      "Epoch 298/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.1074 - val_loss: 43.7690 - learning_rate: 1.0000e-06\n",
      "Epoch 299/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.6721 - val_loss: 43.7701 - learning_rate: 1.0000e-06\n",
      "Epoch 300/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9678 - val_loss: 43.8004 - learning_rate: 1.0000e-06\n",
      "Epoch 301/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.6326 - val_loss: 43.8809 - learning_rate: 1.0000e-06\n",
      "Epoch 302/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.4732 - val_loss: 43.8343 - learning_rate: 1.0000e-06\n",
      "Epoch 303/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.9084 - val_loss: 43.7176 - learning_rate: 1.0000e-06\n",
      "Epoch 304/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0970 - val_loss: 43.6880 - learning_rate: 1.0000e-06\n",
      "Epoch 305/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2465 - val_loss: 43.8469 - learning_rate: 1.0000e-06\n",
      "Epoch 306/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.1622 - val_loss: 44.0628 - learning_rate: 1.0000e-06\n",
      "Epoch 307/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.8727 - val_loss: 44.1164 - learning_rate: 1.0000e-06\n",
      "Epoch 308/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5669 - val_loss: 44.0847 - learning_rate: 1.0000e-06\n",
      "Epoch 309/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.8779 - val_loss: 43.8889 - learning_rate: 1.0000e-06\n",
      "Epoch 310/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8777 - val_loss: 43.8662 - learning_rate: 1.0000e-06\n",
      "Epoch 311/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.3237 - val_loss: 43.8899 - learning_rate: 1.0000e-06\n",
      "Epoch 312/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0853 - val_loss: 44.0305 - learning_rate: 1.0000e-06\n",
      "Epoch 313/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.9101 - val_loss: 44.0159 - learning_rate: 1.0000e-06\n",
      "Epoch 314/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.8013 - val_loss: 44.2085 - learning_rate: 1.0000e-06\n",
      "Epoch 315/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7512 - val_loss: 44.0328 - learning_rate: 1.0000e-06\n",
      "Epoch 316/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.0925 - val_loss: 43.9323 - learning_rate: 1.0000e-06\n",
      "Epoch 317/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.0726 - val_loss: 43.7085 - learning_rate: 1.0000e-06\n",
      "Epoch 318/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.9023 - val_loss: 43.6912 - learning_rate: 1.0000e-06\n",
      "Epoch 319/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.7133 - val_loss: 43.9334 - learning_rate: 1.0000e-06\n",
      "Epoch 320/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.2897 - val_loss: 44.1372 - learning_rate: 1.0000e-06\n",
      "Epoch 321/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.8613 - val_loss: 43.8567 - learning_rate: 1.0000e-06\n",
      "Epoch 322/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1066 - val_loss: 43.9458 - learning_rate: 1.0000e-06\n",
      "Epoch 323/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6014 - val_loss: 43.9535 - learning_rate: 1.0000e-06\n",
      "Epoch 324/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.3844 - val_loss: 43.8911 - learning_rate: 1.0000e-06\n",
      "Epoch 325/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.3391 - val_loss: 44.0194 - learning_rate: 1.0000e-06\n",
      "Epoch 326/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.4014 - val_loss: 44.0216 - learning_rate: 1.0000e-06\n",
      "Epoch 327/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1308 - val_loss: 44.0061 - learning_rate: 1.0000e-06\n",
      "Epoch 328/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.2323 - val_loss: 43.8838 - learning_rate: 1.0000e-06\n",
      "Epoch 329/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.5247 - val_loss: 43.8440 - learning_rate: 1.0000e-06\n",
      "Epoch 330/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4214 - val_loss: 43.9447 - learning_rate: 1.0000e-06\n",
      "Epoch 331/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6998 - val_loss: 44.1042 - learning_rate: 1.0000e-06\n",
      "Epoch 332/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5252 - val_loss: 43.8745 - learning_rate: 1.0000e-06\n",
      "Epoch 333/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1035 - val_loss: 43.8373 - learning_rate: 1.0000e-06\n",
      "Epoch 334/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1742 - val_loss: 43.8740 - learning_rate: 1.0000e-06\n",
      "Epoch 335/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9035 - val_loss: 43.8127 - learning_rate: 1.0000e-06\n",
      "Epoch 336/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1937 - val_loss: 43.7584 - learning_rate: 1.0000e-06\n",
      "Epoch 337/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9170 - val_loss: 43.9067 - learning_rate: 1.0000e-06\n",
      "Epoch 338/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.8884 - val_loss: 43.8835 - learning_rate: 1.0000e-06\n",
      "Epoch 339/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1717 - val_loss: 43.8932 - learning_rate: 1.0000e-06\n",
      "Epoch 340/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.9666 - val_loss: 43.7547 - learning_rate: 1.0000e-06\n",
      "Epoch 341/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2931 - val_loss: 43.7669 - learning_rate: 1.0000e-06\n",
      "Epoch 342/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4629 - val_loss: 43.8465 - learning_rate: 1.0000e-06\n",
      "Epoch 343/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.6959 - val_loss: 43.7577 - learning_rate: 1.0000e-06\n",
      "Epoch 344/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.1324 - val_loss: 43.6982 - learning_rate: 1.0000e-06\n",
      "Epoch 345/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.6315 - val_loss: 43.8275 - learning_rate: 1.0000e-06\n",
      "Epoch 346/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9078 - val_loss: 43.8858 - learning_rate: 1.0000e-06\n",
      "Epoch 347/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8306 - val_loss: 43.9903 - learning_rate: 1.0000e-06\n",
      "Epoch 348/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.6116 - val_loss: 44.1827 - learning_rate: 1.0000e-06\n",
      "Epoch 349/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6751 - val_loss: 43.9504 - learning_rate: 1.0000e-06\n",
      "Epoch 350/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.0154 - val_loss: 43.7930 - learning_rate: 1.0000e-06\n",
      "Epoch 351/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.4091 - val_loss: 43.8680 - learning_rate: 1.0000e-06\n",
      "Epoch 352/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8491 - val_loss: 43.9925 - learning_rate: 1.0000e-06\n",
      "Epoch 353/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9995 - val_loss: 43.8907 - learning_rate: 1.0000e-06\n",
      "Epoch 354/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.3217 - val_loss: 43.9324 - learning_rate: 1.0000e-06\n",
      "Epoch 355/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.7621 - val_loss: 43.9453 - learning_rate: 1.0000e-06\n",
      "Epoch 356/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0177 - val_loss: 43.7703 - learning_rate: 1.0000e-06\n",
      "Epoch 357/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8806 - val_loss: 43.8188 - learning_rate: 1.0000e-06\n",
      "Epoch 358/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.1846 - val_loss: 43.8577 - learning_rate: 1.0000e-06\n",
      "Epoch 359/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.3194 - val_loss: 44.0001 - learning_rate: 1.0000e-06\n",
      "Epoch 360/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.0543 - val_loss: 43.9387 - learning_rate: 1.0000e-06\n",
      "Epoch 361/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.3607 - val_loss: 44.0010 - learning_rate: 1.0000e-06\n",
      "Epoch 362/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6821 - val_loss: 43.9047 - learning_rate: 1.0000e-06\n",
      "Epoch 363/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5580 - val_loss: 43.8616 - learning_rate: 1.0000e-06\n",
      "Epoch 364/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9949 - val_loss: 44.1842 - learning_rate: 1.0000e-06\n",
      "Epoch 365/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.3454 - val_loss: 44.0498 - learning_rate: 1.0000e-06\n",
      "Epoch 366/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.0987 - val_loss: 43.8364 - learning_rate: 1.0000e-06\n",
      "Epoch 367/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.3450 - val_loss: 43.7914 - learning_rate: 1.0000e-06\n",
      "Epoch 368/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.4008 - val_loss: 43.8884 - learning_rate: 1.0000e-06\n",
      "Epoch 369/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6357 - val_loss: 43.9500 - learning_rate: 1.0000e-06\n",
      "Epoch 370/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.3478 - val_loss: 43.7857 - learning_rate: 1.0000e-06\n",
      "Epoch 371/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.2810 - val_loss: 43.9318 - learning_rate: 1.0000e-06\n",
      "Epoch 372/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.4022 - val_loss: 43.9245 - learning_rate: 1.0000e-06\n",
      "Epoch 373/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.2929 - val_loss: 44.0223 - learning_rate: 1.0000e-06\n",
      "Epoch 374/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0991 - val_loss: 43.9838 - learning_rate: 1.0000e-06\n",
      "Epoch 375/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.1999 - val_loss: 43.8538 - learning_rate: 1.0000e-06\n",
      "Epoch 376/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0682 - val_loss: 43.9073 - learning_rate: 1.0000e-06\n",
      "Epoch 377/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.5424 - val_loss: 43.8643 - learning_rate: 1.0000e-06\n",
      "Epoch 378/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.9685 - val_loss: 43.9330 - learning_rate: 1.0000e-06\n",
      "Epoch 379/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.8748 - val_loss: 43.8936 - learning_rate: 1.0000e-06\n",
      "Epoch 380/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.8915 - val_loss: 43.8624 - learning_rate: 1.0000e-06\n",
      "Epoch 381/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.7326 - val_loss: 43.8200 - learning_rate: 1.0000e-06\n",
      "Epoch 382/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0263 - val_loss: 43.8284 - learning_rate: 1.0000e-06\n",
      "Epoch 383/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2704 - val_loss: 44.1049 - learning_rate: 1.0000e-06\n",
      "Epoch 384/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.8817 - val_loss: 43.7692 - learning_rate: 1.0000e-06\n",
      "Epoch 385/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.8806 - val_loss: 43.9401 - learning_rate: 1.0000e-06\n",
      "Epoch 386/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1823 - val_loss: 44.0893 - learning_rate: 1.0000e-06\n",
      "Epoch 387/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 68.5698 - val_loss: 44.2625 - learning_rate: 1.0000e-06\n",
      "Epoch 388/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.1183 - val_loss: 44.1013 - learning_rate: 1.0000e-06\n",
      "Epoch 389/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.9472 - val_loss: 44.0437 - learning_rate: 1.0000e-06\n",
      "Epoch 390/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6948 - val_loss: 43.9602 - learning_rate: 1.0000e-06\n",
      "Epoch 391/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.0754 - val_loss: 43.9000 - learning_rate: 1.0000e-06\n",
      "Epoch 392/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9522 - val_loss: 43.9973 - learning_rate: 1.0000e-06\n",
      "Epoch 393/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.5903 - val_loss: 43.8152 - learning_rate: 1.0000e-06\n",
      "Epoch 394/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.6659 - val_loss: 43.8814 - learning_rate: 1.0000e-06\n",
      "Epoch 395/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7482 - val_loss: 43.8158 - learning_rate: 1.0000e-06\n",
      "Epoch 396/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.6373 - val_loss: 43.7242 - learning_rate: 1.0000e-06\n",
      "Epoch 397/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.3150 - val_loss: 43.8795 - learning_rate: 1.0000e-06\n",
      "Epoch 398/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.3270 - val_loss: 44.0872 - learning_rate: 1.0000e-06\n",
      "Epoch 399/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.3587 - val_loss: 43.9022 - learning_rate: 1.0000e-06\n",
      "Epoch 400/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4420 - val_loss: 43.7327 - learning_rate: 1.0000e-06\n",
      "Epoch 401/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7791 - val_loss: 43.6951 - learning_rate: 1.0000e-06\n",
      "Epoch 402/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.2899 - val_loss: 43.6860 - learning_rate: 1.0000e-06\n",
      "Epoch 403/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7777 - val_loss: 43.8825 - learning_rate: 1.0000e-06\n",
      "Epoch 404/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.4959 - val_loss: 44.0633 - learning_rate: 1.0000e-06\n",
      "Epoch 405/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7878 - val_loss: 43.9907 - learning_rate: 1.0000e-06\n",
      "Epoch 406/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9183 - val_loss: 43.8707 - learning_rate: 1.0000e-06\n",
      "Epoch 407/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.6543 - val_loss: 43.9165 - learning_rate: 1.0000e-06\n",
      "Epoch 408/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.6143 - val_loss: 43.7757 - learning_rate: 1.0000e-06\n",
      "Epoch 409/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9711 - val_loss: 43.8239 - learning_rate: 1.0000e-06\n",
      "Epoch 410/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.1780 - val_loss: 44.0194 - learning_rate: 1.0000e-06\n",
      "Epoch 411/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.4261 - val_loss: 44.1172 - learning_rate: 1.0000e-06\n",
      "Epoch 412/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.0645 - val_loss: 44.1141 - learning_rate: 1.0000e-06\n",
      "Epoch 413/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.3082 - val_loss: 44.1803 - learning_rate: 1.0000e-06\n",
      "Epoch 414/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5597 - val_loss: 44.1311 - learning_rate: 1.0000e-06\n",
      "Epoch 415/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.1987 - val_loss: 43.7891 - learning_rate: 1.0000e-06\n",
      "Epoch 416/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.1947 - val_loss: 43.8163 - learning_rate: 1.0000e-06\n",
      "Epoch 417/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.5977 - val_loss: 43.8318 - learning_rate: 1.0000e-06\n",
      "Epoch 418/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.2522 - val_loss: 43.9339 - learning_rate: 1.0000e-06\n",
      "Epoch 419/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.3989 - val_loss: 43.9241 - learning_rate: 1.0000e-06\n",
      "Epoch 420/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9019 - val_loss: 43.7822 - learning_rate: 1.0000e-06\n",
      "Epoch 421/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.0058 - val_loss: 43.8673 - learning_rate: 1.0000e-06\n",
      "Epoch 422/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.5141 - val_loss: 44.0463 - learning_rate: 1.0000e-06\n",
      "Epoch 423/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.0796 - val_loss: 43.9390 - learning_rate: 1.0000e-06\n",
      "Epoch 424/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.9052 - val_loss: 43.9754 - learning_rate: 1.0000e-06\n",
      "Epoch 425/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.2458 - val_loss: 44.0146 - learning_rate: 1.0000e-06\n",
      "Epoch 426/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.4170 - val_loss: 43.9148 - learning_rate: 1.0000e-06\n",
      "Epoch 427/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.7388 - val_loss: 44.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 428/10000\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.2232 - val_loss: 43.8884 - learning_rate: 1.0000e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43.3682\n",
      "Test Loss: 42.23622512817383\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "istory = model.fit(X_train, y_train, epochs=10000, validation_split=0.15, batch_size=128, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnFElEQVR4nO3deXwM5+MH8M/u5r4JSYS4r8RdZ1A9pILUrVpN0VbrS4OiVP3cetCTtorqIT2o0qLqDnWL+wqJuCWOJIhsDjl3n98fYydZCZLI7ETyeb9e+8ruzLMzz8xenzzzzDMaIYQAERERURmlVbsCREREREpi2CEiIqIyjWGHiIiIyjSGHSIiIirTGHaIiIioTGPYISIiojKNYYeIiIjKNIYdIiIiKtMYdoiIiKhMY9ghoieGRqPBjBkzivy8y5cvQ6PRIDQ0tMTrRESlH8MOERVJaGgoNBoNNBoN9uzZk2++EAI+Pj7QaDR48cUXVahh8e3YsQMajQZ//fWX2lUhohLEsENExWJnZ4dly5blm75z505cvXoVtra2KtSKiCg/hh0iKpbu3btj5cqVyMnJMZu+bNkytGzZEl5eXirVjIjIHMMOERXLwIEDcfv2bYSFhcnTsrKy8Ndff+HVV18t8DlpaWl477334OPjA1tbWzRo0ABffPEFhBBm5TIzMzF27FhUrlwZzs7O6NmzJ65evVrgMq9du4Y333wTnp6esLW1RaNGjfDzzz+X3IYW4OLFi3jppZdQsWJFODg4oF27dli/fn2+ct9++y0aNWoEBwcHVKhQAa1atTJrDUtJScGYMWNQs2ZN2NrawsPDAy+88AKOHj2qaP2JyhuGHSIqlpo1a8Lf3x9//PGHPG3jxo3Q6/V45ZVX8pUXQqBnz56YO3cuunbtiq+++goNGjTAhAkTMG7cOLOyb731FubNm4cuXbpgzpw5sLa2RlBQUL5lxsfHo127dti6dStGjhyJr7/+GnXr1sXQoUMxb968Et9m0zrbt2+PzZs345133sHHH3+MjIwM9OzZE6tXr5bL/fDDDxg9ejT8/Pwwb948zJw5E82bN8eBAwfkMsOHD8fChQvRr18/LFiwAOPHj4e9vT2ioqIUqTtRuSWIiIpgyZIlAoA4dOiQmD9/vnB2dhZ3794VQgjx0ksvieeee04IIUSNGjVEUFCQ/Lw1a9YIAOKjjz4yW17//v2FRqMR58+fF0IIcfz4cQFAvPPOO2blXn31VQFATJ8+XZ42dOhQUaVKFXHr1i2zsq+88opwdXWV63Xp0iUBQCxZsuSh27Z9+3YBQKxcufKBZcaMGSMAiN27d8vTUlJSRK1atUTNmjWFwWAQQgjRq1cv0ahRo4euz9XVVYSEhDy0DBE9PrbsEFGxDRgwAOnp6Vi3bh1SUlKwbt26Bx7C2rBhA3Q6HUaPHm02/b333oMQAhs3bpTLAchXbsyYMWaPhRD4+++/0aNHDwghcOvWLfkWGBgIvV6vyOGgDRs2oE2bNujYsaM8zcnJCcOGDcPly5cRGRkJAHBzc8PVq1dx6NChBy7Lzc0NBw4cwPXr10u8nkSUi2GHiIqtcuXKCAgIwLJly7Bq1SoYDAb079+/wLJXrlyBt7c3nJ2dzab7+vrK801/tVot6tSpY1auQYMGZo9v3ryJpKQkLF68GJUrVza7vfHGGwCAhISEEtnO+7fj/roUtB0TJ06Ek5MT2rRpg3r16iEkJAR79+41e85nn32GU6dOwcfHB23atMGMGTNw8eLFEq8zUXlnpXYFiOjJ9uqrr+Ltt99GXFwcunXrBjc3N4us12g0AgBee+01DBkypMAyTZs2tUhdCuLr64vo6GisW7cOmzZtwt9//40FCxZg2rRpmDlzJgCpZezpp5/G6tWrsWXLFnz++ef49NNPsWrVKnTr1k21uhOVNWzZIaLH0qdPH2i1Wuzfv/+Bh7AAoEaNGrh+/TpSUlLMpp85c0aeb/prNBpx4cIFs3LR0dFmj01nahkMBgQEBBR48/DwKIlNzLcd99eloO0AAEdHR7z88stYsmQJYmJiEBQUJHdoNqlSpQreeecdrFmzBpcuXYK7uzs+/vjjEq83UXnGsENEj8XJyQkLFy7EjBkz0KNHjweW6969OwwGA+bPn282fe7cudBoNHJLhunvN998Y1bu/rOrdDod+vXrh7///hunTp3Kt76bN28WZ3MeqXv37jh48CDCw8PlaWlpaVi8eDFq1qwJPz8/AMDt27fNnmdjYwM/Pz8IIZCdnQ2DwQC9Xm9WxsPDA97e3sjMzFSk7kTlFQ9jEdFje9BhpLx69OiB5557DpMnT8bly5fRrFkzbNmyBf/88w/GjBkj99Fp3rw5Bg4ciAULFkCv16N9+/bYtm0bzp8/n2+Zc+bMwfbt29G2bVu8/fbb8PPzQ2JiIo4ePYqtW7ciMTGxWNvz999/yy0192/nBx98gD/++APdunXD6NGjUbFiRfzyyy+4dOkS/v77b2i10v+QXbp0gZeXFzp06ABPT09ERUVh/vz5CAoKgrOzM5KSklCtWjX0798fzZo1g5OTE7Zu3YpDhw7hyy+/LFa9iegB1D0ZjIieNHlPPX+Y+089F0I6RXvs2LHC29tbWFtbi3r16onPP/9cGI1Gs3Lp6eli9OjRwt3dXTg6OooePXqI2NjYfKeeCyFEfHy8CAkJET4+PsLa2lp4eXmJzp07i8WLF8tlinrq+YNuptPNL1y4IPr37y/c3NyEnZ2daNOmjVi3bp3Zsr7//nvRqVMn4e7uLmxtbUWdOnXEhAkThF6vF0IIkZmZKSZMmCCaNWsmnJ2dhaOjo2jWrJlYsGDBQ+tIREWnEeK+oUuJiIiIyhD22SEiIqIyjWGHiIiIyjSGHSIiIirTGHaIiIioTGPYISIiojKNYYeIiIjKNA4qCOkaO9evX4ezszM0Go3a1SEiIqJCEEIgJSUF3t7e8oCeBWHYAXD9+nX4+PioXQ0iIiIqhtjYWFSrVu2B8xl2ADg7OwOQdpaLi4vKtSEiIqLCSE5Oho+Pj/w7/iAMO4B86MrFxYVhh4iI6AnzqC4o7KBMREREZRrDDhEREZVpDDtERERUprHPDhERPTaDwYDs7Gy1q0FljLW1NXQ63WMvh2GHiIiKTQiBuLg4JCUlqV0VKqPc3Nzg5eX1WOPgMewQEVGxmYKOh4cHHBwcODArlRghBO7evYuEhAQAQJUqVYq9LIYdIiIqFoPBIAcdd3d3tatDZZC9vT0AICEhAR4eHsU+pMUOykREVCymPjoODg4q14TKMtP763H6hDHsEBHRY+GhK1JSSby/GHaIiIioTGPYISIiKgE1a9bEvHnzCl1+x44d0Gg0PJPNAhh2iIioXNFoNA+9zZgxo1jLPXToEIYNG1bo8u3bt8eNGzfg6uparPUVFkMVz8ZSVEJKBjKyjPBwsYWd9eMPikRERI/vxo0b8v0///wT06ZNQ3R0tDzNyclJvi+EgMFggJXVo38uK1euXKR62NjYwMvLq0jPoeJhy46CXloUjk6fb8epa3q1q0JERPd4eXnJN1dXV2g0GvnxmTNn4OzsjI0bN6Jly5awtbXFnj17cOHCBfTq1Quenp5wcnJC69atsXXrVrPl3n8YS6PR4Mcff0SfPn3g4OCAevXqYe3atfL8+1tcQkND4ebmhs2bN8PX1xdOTk7o2rWrWTjLycnB6NGj4ebmBnd3d0ycOBFDhgxB7969i70/7ty5g8GDB6NChQpwcHBAt27dcO7cOXn+lStX0KNHD1SoUAGOjo5o1KgRNmzYID83ODgYlStXhr29PerVq4clS5YUuy5KYdhRkI1O2r1ZOUaVa0JEZBlCCNzNylHlJoQose344IMPMGfOHERFRaFp06ZITU1F9+7dsW3bNhw7dgxdu3ZFjx49EBMT89DlzJw5EwMGDMDJkyfRvXt3BAcHIzEx8YHl7969iy+++AK//fYbdu3ahZiYGIwfP16e/+mnn2Lp0qVYsmQJ9u7di+TkZKxZs+axtvX111/H4cOHsXbtWoSHh0MIge7du8uneoeEhCAzMxO7du1CREQEPv30U7n1a+rUqYiMjMTGjRsRFRWFhQsXolKlSo9VHyXwMJaCbK2lsJNpYNghovIhPdsAv2mbVVl35KxAONiUzM/arFmz8MILL8iPK1asiGbNmsmPP/zwQ6xevRpr167FyJEjH7ic119/HQMHDgQAfPLJJ/jmm29w8OBBdO3atcDy2dnZWLRoEerUqQMAGDlyJGbNmiXP//bbbzFp0iT06dMHADB//ny5laU4zp07h7Vr12Lv3r1o3749AGDp0qXw8fHBmjVr8NJLLyEmJgb9+vVDkyZNAAC1a9eWnx8TE4MWLVqgVatWAKTWrdKILTsKMrXsZGYz7BARPUlMP94mqampGD9+PHx9feHm5gYnJydERUU9smWnadOm8n1HR0e4uLjIlz8oiIODgxx0AOkSCabyer0e8fHxaNOmjTxfp9OhZcuWRdq2vKKiomBlZYW2bdvK09zd3dGgQQNERUUBAEaPHo2PPvoIHTp0wPTp03Hy5Em57IgRI7B8+XI0b94c77//Pvbt21fsuiiJLTsKsrWSOiVnsWWHiMoJe2sdImcFqrbukuLo6Gj2ePz48QgLC8MXX3yBunXrwt7eHv3790dWVtZDl2NtbW32WKPRwGh88G9CQeVL8vBccbz11lsIDAzE+vXrsWXLFsyePRtffvklRo0ahW7duuHKlSvYsGEDwsLC0LlzZ4SEhOCLL75Qtc73Y8uOgmys2GeHiMoXjUYDBxsrVW5KjuS8d+9evP766+jTpw+aNGkCLy8vXL58WbH1FcTV1RWenp44dOiQPM1gMODo0aPFXqavry9ycnJw4MABedrt27cRHR0NPz8/eZqPjw+GDx+OVatW4b333sMPP/wgz6tcuTKGDBmC33//HfPmzcPixYuLXR+lsGVHQVZa6YNneEiKJyKi0q9evXpYtWoVevToAY1Gg6lTpz60hUYpo0aNwuzZs1G3bl00bNgQ3377Le7cuVOooBcREQFnZ2f5sUajQbNmzdCrVy+8/fbb+P777+Hs7IwPPvgAVatWRa9evQAAY8aMQbdu3VC/fn3cuXMH27dvh6+vLwBg2rRpaNmyJRo1aoTMzEysW7dOnleaMOwoaEDi9+htHQtNyv8BqK52dYiIqJi++uorvPnmm2jfvj0qVaqEiRMnIjk52eL1mDhxIuLi4jB48GDodDoMGzYMgYGBhboaeKdOncwe63Q65OTkYMmSJXj33Xfx4osvIisrC506dcKGDRvkQ2oGgwEhISG4evUqXFxc0LVrV8ydOxeANFbQpEmTcPnyZdjb2+Ppp5/G8uXLS37DH5NGqH0wsBRITk6Gq6sr9Ho9XFxcSmy5cR83hld2LLa0+RlduvcrseUSEZUGGRkZuHTpEmrVqgU7Ozu1q1MuGY1G+Pr6YsCAAfjwww/Vro4iHvY+K+zvN1t2FGTQSKlYY3h4BzYiIqLCuHLlCrZs2YJnnnkGmZmZmD9/Pi5duoRXX31V7aqVauygrKCce2EHDDtERFQCtFotQkND0bp1a3To0AERERHYunVrqewnU5qwZUdBbNkhIqKS5OPjg71796pdjSeOqi07M2bMyHe12YYNG8rzMzIyEBISAnd3dzg5OaFfv36Ij483W0ZMTAyCgoLg4OAADw8PTJgwATk5OZbelAIZtPfCjjFb5ZoQERGVX6q37DRq1MjsYmp5ryw7duxYrF+/HitXroSrqytGjhyJvn37yqnWYDAgKCgIXl5e2LdvH27cuIHBgwfD2toan3zyicW35X45GhsAbNkhIiJSk+phx8rKqsBL3Ov1evz0009YtmwZnn/+eQDAkiVL4Ovri/3796Ndu3bYsmULIiMjsXXrVnh6eqJ58+b48MMPMXHiRMyYMQM2NjaW3hxz2nsNZ0aDuvUgIiIqx1TvoHzu3Dl4e3ujdu3aCA4Olq8zcuTIEWRnZyMgIEAu27BhQ1SvXh3h4eEAgPDwcDRp0gSenp5ymcDAQCQnJ+P06dMPXGdmZiaSk5PNbkoQkMY9EIKDChIREalF1bDTtm1bhIaGYtOmTVi4cCEuXbqEp59+GikpKYiLi4ONjQ3c3NzMnuPp6Ym4uDgAQFxcnFnQMc03zXuQ2bNnw9XVVb75+PiU7IbdI0wjWrJlh4iISDWqHsbq1q2bfL9p06Zo27YtatSogRUrVsDe3l6x9U6aNAnjxo2THycnJysTeDT3RrQUDDtERERqUf0wVl5ubm6oX78+zp8/Dy8vL2RlZSEpKcmsTHx8vNzHx8vLK9/ZWabHBfUDMrG1tYWLi4vZTREaU58dHsYiIiprnn32WYwZM0Z+XLNmTcybN++hz9FoNFizZs1jr7ukllNelKqwk5qaigsXLqBKlSpo2bIlrK2tsW3bNnl+dHQ0YmJi4O/vDwDw9/dHREQEEhIS5DJhYWFwcXExu1qrWoz3wo5gyw4RUanRo0cPdO3atcB5u3fvhkajwcmTJ4u83EOHDmHYsGGPWz0zM2bMQPPmzfNNv3HjhtnRESWEhobm60rypFI17IwfPx47d+7E5cuXsW/fPvTp0wc6nQ4DBw6Eq6srhg4dinHjxmH79u04cuQI3njjDfj7+6Ndu3YAgC5dusDPzw+DBg3CiRMnsHnzZkyZMgUhISGwtbVVc9MAABpTyw47KBMRlRpDhw5FWFgYrl69mm/ekiVL0KpVKzRt2rTIy61cuTIcHBxKooqP5OXlVSp+554Uqoadq1evYuDAgWjQoAEGDBgAd3d37N+/H5UrVwYAzJ07Fy+++CL69euHTp06wcvLC6tWrZKfr9PpsG7dOuh0Ovj7++O1117D4MGDMWvWLLU2yYww9dlhB2UiolLjxRdfROXKlREaGmo2PTU1FStXrsTQoUNx+/ZtDBw4EFWrVoWDgwOaNGmCP/7446HLvf8w1rlz59CpUyfY2dnBz88PYWFh+Z4zceJE1K9fHw4ODqhduzamTp2K7GxpINrQ0FDMnDkTJ06ckAfeNdX5/sNYEREReP7552Fvbw93d3cMGzYMqamp8vzXX38dvXv3xhdffIEqVarA3d0dISEh8rqKIyYmBr169YKTkxNcXFwwYMAAs64lJ06cwHPPPQdnZ2e4uLigZcuWOHz4MADpGl89evRAhQoV4OjoiEaNGmHDhg3FrsujqNpB+VGXgbezs8N3332H77777oFlatSooegOeixyy065v7A8EZUXQgDZd9VZt7UDYDoL9iGsrKwwePBghIaGYvLkydDce87KlSthMBgwcOBApKamomXLlpg4cSJcXFywfv16DBo0CHXq1EGbNm0euQ6j0Yi+ffvC09MTBw4cgF6vN+vfY+Ls7IzQ0FB4e3sjIiICb7/9NpydnfH+++/j5ZdfxqlTp7Bp0yZ58F1XV9d8y0hLS0NgYCD8/f1x6NAhJCQk4K233sLIkSPNAt327dtRpUoVbN++HefPn8fLL7+M5s2b4+23337k9hS0faags3PnTuTk5CAkJAQvv/wyduzYAQAIDg5GixYtsHDhQuh0Ohw/fhzW1tKVBUJCQpCVlYVdu3bB0dERkZGRcHJyKnI9Ckv1QQXLMiGHHbbsEFE5kX0X+MRbnXX/33XAxrFQRd988018/vnn2LlzJ5599lkA0iGsfv36ycOSjB8/Xi4/atQobN68GStWrChU2Nm6dSvOnDmDzZs3w9tb2h+ffPJJvn42U6ZMke/XrFkT48ePx/Lly/H+++/D3t4eTk5ODxx812TZsmXIyMjAr7/+CkdHafvnz5+PHj164NNPP5WHZKlQoQLmz58PnU6Hhg0bIigoCNu2bStW2Nm2bRsiIiJw6dIl+WzmX3/9FY0aNcKhQ4fQunVrxMTEYMKECfJloOrVqyc/PyYmBv369UOTJk0AALVr1y5yHYqiVHVQLms0PBuLiKhUatiwIdq3b4+ff/4ZAHD+/Hns3r0bQ4cOBSBdjujDDz9EkyZNULFiRTg5OWHz5s3ywLePEhUVBR8fHznoAJBPrsnrzz//RIcOHeDl5QUnJydMmTKl0OvIu65mzZrJQQcAOnToAKPRiOjoaHlao0aNoNPp5MdVqlQxO8GnqOv08fExG7bFz88Pbm5uiIqKAgCMGzcOb731FgICAjBnzhxcuHBBLjt69Gh89NFH6NChA6ZPn16sDuFFwZYdBQktx9khonLG2kFqYVFr3UUwdOhQjBo1Ct999x2WLFmCOnXq4JlnngEAfP755/j6668xb948NGnSBI6OjhgzZgyyskruWofh4eEIDg7GzJkzERgYCFdXVyxfvhxffvllia0jL9MhJBONRgOjgv+Mz5gxA6+++irWr1+PjRs3Yvr06Vi+fDn69OmDt956C4GBgVi/fj22bNmC2bNn48svv8SoUaMUqQtbdpR0r2VHw7BDROWFRiMdSlLjVoj+OnkNGDAAWq0Wy5Ytw6+//oo333xT7r+zd+9e9OrVC6+99hqaNWuG2rVr4+zZs4Vetq+vL2JjY3Hjxg152v79+83K7Nu3DzVq1MDkyZPRqlUr1KtXD1euXDErY2NjA4Ph4b8hvr6+OHHiBNLS0uRpe/fuhVarRYMGDQpd56IwbV9sbKw8LTIyEklJSWZDv9SvXx9jx47Fli1b0LdvXyxZskSe5+Pjg+HDh2PVqlV477338MMPPyhSV4BhR1nsoExEVGo5OTnh5ZdfxqRJk3Djxg28/vrr8rx69eohLCwM+/btQ1RUFP73v//lG8T2YQICAlC/fn0MGTIEJ06cwO7duzF58mSzMvXq1UNMTAyWL1+OCxcu4JtvvsHq1avNytSsWROXLl3C8ePHcevWLWRmZuZbV3BwMOzs7DBkyBCcOnUK27dvx6hRozBo0KB8l1QqKoPBgOPHj5vdoqKiEBAQgCZNmiA4OBhHjx7FwYMHMXjwYDzzzDNo1aoV0tPTMXLkSOzYsQNXrlzB3r17cejQIfj6+gIAxowZg82bN+PSpUs4evQotm/fLs9TAsOOggRbdoiISrWhQ4fizp07CAwMNOtfM2XKFDz11FMIDAzEs88+Cy8vL/Tu3bvQy9VqtVi9ejXS09PRpk0bvPXWW/j444/NyvTs2RNjx47FyJEj0bx5c+zbtw9Tp041K9OvXz907doVzz33HCpXrlzg6e8ODg7YvHkzEhMT0bp1a/Tv3x+dO3fG/Pnzi7YzCpCamooWLVqY3Xr06AGNRoN//vkHFSpUQKdOnRAQEIDatWvjzz//BCANDXP79m0MHjwY9evXx4ABA9CtWzfMnDkTgBSiQkJC4Ovri65du6J+/fpYsGDBY9f3QTRCsNkhOTkZrq6u0Ov1JXrpiOM/voPmV5fiv0qv4vmRC0tsuUREpUFGRgYuXbqEWrVqwc7OTu3qUBn1sPdZYX+/2bKjKFPLDs/GIiIiUgvDjpK0DDtERERqY9hRUG6fHYYdIiIitTDsKOnetbE0YNghIiJSC8OOgtiyQ0TlAc9zISWVxPuLYUdJPPWciMow04i8d++qdOFPKhdM76/7R4AuCl4uQkmmQQV5GIuIyiCdTgc3Nzf5+koODg7yCMREj0sIgbt37yIhIQFubm5m1/UqKoYdJcktOyrXg4hIIaarcRf3gpJEj+Lm5vbQq74XBsOOkkz/4bDPDhGVURqNBlWqVIGHhweys7PVrg6VMdbW1o/VomPCsKMk+TAWm3aIqGzT6XQl8qNEpAR2UFaU1LLDs7GIiIjUw7CjIA1bdoiIiFTHsKMkjallh2GHiIhILQw7Cso9BZNhh4iISC0MO4q6t3vZskNERKQahh0lmQ5jcVBBIiIi1TDsKEnD3UtERKQ2/horScNTz4mIiNTGsKMkdlAmIiJSHcOOgkzj7LDPDhERkXoYdpQkXxtL3WoQERGVZww7CuIIykREROpj2FESOygTERGpjmFHSXKfHbbsEBERqYVhR0Ea8NpYREREamPYUZKWfXaIiIjUxrCjJF4ugoiISHUMOwrS8NRzIiIi1THsKIodlImIiNTGsKMgjZaHsYiIiNTGsKModlAmIiJSG8OOgjQannpORESkNoYdJWl19+4w7BAREamFYUdBppOxeLkIIiIi9TDsKMp0NhYRERGphWFHQRqOoExERKQ6hh0lcQRlIiIi1THsKEhjuuo5z8YiIiJSDcOOguSrnvMwFhERkWoYdpSk4+UiiIiI1MawoyC27BAREamPYUdJGp6NRUREpDaGHQXxchFERETqY9hRkGmcHR7GIiIiUg/DjqJ4GIuIiEhtDDsK0t47jKVl2CEiIlINw46SeLkIIiIi1THsKMjUQVnLq54TERGphmFHSRruXiIiIrXx11hBGi0HFSQiIlIbw46CNOCp50RERGpj2FESx9khIiJSHcOOgkynnmvADspERERqYdhRksbUskNERERqYdhRElt2iIiIVMewoyCtqWWHXXaIiIhUw7CjJA07KBMREamNYUdBGg3H2SEiIlJbqQk7c+bMgUajwZgxY+RpGRkZCAkJgbu7O5ycnNCvXz/Ex8ebPS8mJgZBQUFwcHCAh4cHJkyYgJycHAvXvmAannpORESkulIRdg4dOoTvv/8eTZs2NZs+duxY/Pvvv1i5ciV27tyJ69evo2/fvvJ8g8GAoKAgZGVlYd++ffjll18QGhqKadOmWXoTHoBXPSciIlKb6mEnNTUVwcHB+OGHH1ChQgV5ul6vx08//YSvvvoKzz//PFq2bIklS5Zg37592L9/PwBgy5YtiIyMxO+//47mzZujW7du+PDDD/Hdd98hKytLrU2SaXS6e/cYdoiIiNSietgJCQlBUFAQAgICzKYfOXIE2dnZZtMbNmyI6tWrIzw8HAAQHh6OJk2awNPTUy4TGBiI5ORknD59+oHrzMzMRHJystlNCRq5ZYennhMREanFSs2VL1++HEePHsWhQ4fyzYuLi4ONjQ3c3NzMpnt6eiIuLk4ukzfomOab5j3I7NmzMXPmzMes/aPlXgiUiIiI1KJay05sbCzeffddLF26FHZ2dhZd96RJk6DX6+VbbGysIuvRyKees2WHiIhILaqFnSNHjiAhIQFPPfUUrKysYGVlhZ07d+Kbb76BlZUVPD09kZWVhaSkJLPnxcfHw8vLCwDg5eWV7+ws02NTmYLY2trCxcXF7KaE3FPPiYiISC2qhZ3OnTsjIiICx48fl2+tWrVCcHCwfN/a2hrbtm2TnxMdHY2YmBj4+/sDAPz9/REREYGEhAS5TFhYGFxcXODn52fxbcqH4+wQERGpTrU+O87OzmjcuLHZNEdHR7i7u8vThw4dinHjxqFixYpwcXHBqFGj4O/vj3bt2gEAunTpAj8/PwwaNAifffYZ4uLiMGXKFISEhMDW1tbi23Q/bZ4RlIUQcksPERERWY6qHZQfZe7cudBqtejXrx8yMzMRGBiIBQsWyPN1Oh3WrVuHESNGwN/fH46OjhgyZAhmzZqlYq3zyHPVcyHkhh4iIiKyII0QotwfY0lOToarqyv0en2J9t9JuhoFtx/bIUXYw2H6Dei0TDtEREQlpbC/36qPs1OWafP02WGmJCIiUgfDjoI0yO2zY2TWISIiUgXDjpJ0efrs8IwsIiIiVTDsKCjv5SJ4FIuIiEgdDDsK0mjNz8YiIiIiy2PYUZBWa9q9goexiIiIVMKwo6i8Z2OpXBUiIqJyimFHQaYRk7UQMDLtEBERqYJhR0EabZ6WHZXrQkREVF4x7ChIo9FJfwEIo7p1ISIiKq8YdhQkH8bSsIMyERGRWhh2FJR7NhYgOIQyERGRKhh2FGQaVBAAjDyORUREpAqGHQVp8rbs8GwsIiIiVTDsKMjUZwdg2CEiIlILw46S8oYdo0HFihAREZVfDDuKYssOERGR2hh2lKRhnx0iIiK1MewoScOzsYiIiNTGsKOo3LDDIZSJiIjUwbCjJLMOyjyMRUREpAaGHSWxzw4REZHqGHYUxbOxiIiI1MawoySzQQU5zg4REZEaGHYUxT47REREamPYUZJZnx2ejUVERKQGhh0lmY2zw5YdIiIiNTDsKIrj7BAREamNYUdJeVp2wD47REREqmDYURIPYxEREamOYUdhxnuHsgR4GIuIiEgNDDsKE6Z+O0aGHSIiIjUw7CjMdPCKh7GIiIjUwbCjMHFvF3NQQSIiInUw7CjMFHE0YNghIiJSA8OOwkx9doxGXhuLiIhIDQw7irt3Nhb77BAREamCYUdhRnkUZYYdIiIiNTDsKCz3MBbDDhERkRoYdiyF18YiIiJSBcOOwuRBBRl2iIiIVMGwozDTODscVJCIiEgdDDsKkyMOww4REZEqGHYUlttBmYexiIiI1MCwozSNqc8OW3aIiIjUwLCjMNM4OwJs2SEiIlIDw47i2LJDRESkJoYdhZn67PCq50REROpg2FFYbsThYSwiIiI1MOwojOPsEBERqYthR2FyxOGp50RERKpg2FGaxnQ2FhEREamBYUdhudfGMqhbESIionKKYUdhPBuLiIhIXQw7ChMcZ4eIiEhVDDuKu9eyw7BDRESkCoYdhQleLoKIiEhVDDsKE6YLgbLPDhERkSqKFXZiY2Nx9epV+fHBgwcxZswYLF68uMQqVnbwMBYREZGaihV2Xn31VWzfvh0AEBcXhxdeeAEHDx7E5MmTMWvWrBKt4JNO7qDMkXaIiIhUUaywc+rUKbRp0wYAsGLFCjRu3Bj79u3D0qVLERoaWpL1KzMEx9khIiJSRbHCTnZ2NmxtbQEAW7duRc+ePQEADRs2xI0bN0qudmWA0NzbxTyMRUREpIpihZ1GjRph0aJF2L17N8LCwtC1a1cAwPXr1+Hu7l6iFXzSyWdjMesQERGpolhh59NPP8X333+PZ599FgMHDkSzZs0AAGvXrpUPb9F9BE89JyIiUoNVcZ707LPP4tatW0hOTkaFChXk6cOGDYODg0OJVa4syG3ZYdghIiJSQ7FadtLT05GZmSkHnStXrmDevHmIjo6Gh4dHoZezcOFCNG3aFC4uLnBxcYG/vz82btwoz8/IyEBISAjc3d3h5OSEfv36IT4+3mwZMTExCAoKgoODAzw8PDBhwgTk5OQUZ7MUwT47RERE6ipW2OnVqxd+/fVXAEBSUhLatm2LL7/8Er1798bChQsLvZxq1aphzpw5OHLkCA4fPoznn38evXr1wunTpwEAY8eOxb///ouVK1di586duH79Ovr27Ss/32AwICgoCFlZWdi3bx9++eUXhIaGYtq0acXZLIVwnB0iIiJViWJwd3cXp06dEkII8cMPP4imTZsKg8EgVqxYIRo2bFicRcoqVKggfvzxR5GUlCSsra3FypUr5XlRUVECgAgPDxdCCLFhwwah1WpFXFycXGbhwoXCxcVFZGZmFnqder1eABB6vf6x6l6Qyx81F2K6i9i1YXmJL5uIiKg8K+zvd7Fadu7evQtnZ2cAwJYtW9C3b19otVq0a9cOV65cKVboMhgMWL58OdLS0uDv748jR44gOzsbAQEBcpmGDRuievXqCA8PBwCEh4ejSZMm8PT0lMsEBgYiOTlZbh1SH/vsEBERqalYYadu3bpYs2YNYmNjsXnzZnTp0gUAkJCQABcXlyItKyIiAk5OTrC1tcXw4cOxevVq+Pn5IS4uDjY2NnBzczMr7+npibi4OADS6M15g45pvmneg2RmZiI5OdnsphT22SEiIlJXscLOtGnTMH78eNSsWRNt2rSBv78/AKmVp0WLFkVaVoMGDXD8+HEcOHAAI0aMwJAhQxAZGVmcahXa7Nmz4erqKt98fHwUXJvpchFs2SEiIlJDscJO//79ERMTg8OHD2Pz5s3y9M6dO2Pu3LlFWpaNjQ3q1q2Lli1bYvbs2WjWrBm+/vpreHl5ISsrC0lJSWbl4+Pj4eXlBQDw8vLKd3aW6bGpTEEmTZoEvV4v32JjY4tU56IwteewYYeIiEgdxQo7gBQmWrRogevXr8tXQG/Tpg0aNmz4WBUyGo3IzMxEy5YtYW1tjW3btsnzoqOjERMTI7ck+fv7IyIiAgkJCXKZsLAwuLi4wM/P74HrsLW1lU93N90Uo7nXsmNkyw4REZEaihV2jEYjZs2aBVdXV9SoUQM1atSAm5sbPvzwQxiL8KM+adIk7Nq1C5cvX0ZERAQmTZqEHTt2IDg4GK6urhg6dCjGjRuH7du348iRI3jjjTfg7++Pdu3aAQC6dOkCPz8/DBo0CCdOnMDmzZsxZcoUhISEyNfuUpu4t4sFD2MRERGpolgjKE+ePBk//fQT5syZgw4dOgAA9uzZgxkzZiAjIwMff/xxoZaTkJCAwYMH48aNG3B1dUXTpk2xefNmvPDCCwCAuXPnQqvVol+/fsjMzERgYCAWLFggP1+n02HdunUYMWIE/P394ejoiCFDhmDWrFnF2Sxl8TAWERGRKjRCFL03ibe3NxYtWiRf7dzkn3/+wTvvvINr166VWAUtITk5Ga6urtDr9SV+SOvCHH/UyYjEjuZz8WzvN0t02UREROVZYX+/i3UYKzExscC+OQ0bNkRiYmJxFlmG8WwsIiIiNRUr7DRr1gzz58/PN33+/Plo2rTpY1eqLDGNsyOMPI5FRESkhmL12fnss88QFBSErVu3ymdGhYeHIzY2Fhs2bCjRCj757o2gzE47REREqihWy84zzzyDs2fPok+fPkhKSkJSUhL69u2L06dP47fffivpOj7RhOkwFgfaISIiUkWxWnYAqZPy/WddnThxAj/99BMWL1782BUrM0zj7PDaWERERKoo9qCCVDhs2SEiIlIXw47iGHaIiIjUxLCjNA07KBMREampSH12+vbt+9D591+0k/IexmKfHSIiIjUUKey4uro+cv7gwYMfq0JlDw9jERERqalIYWfJkiVK1aPsMh3GYtghIiJSBfvsKM50uQiGHSIiIjUw7ChM3GvZ0bDPDhERkSoYdhR379pYPIxFRESkCoYdhQn5KBbDDhERkRoYdhTHcXaIiIjUxLCjuHu7mH12iIiIVMGwozCh4Tg7REREamLYUZiGgwoSERGpimFHYXLLDvvsEBERqYJhR2G8NhYREZG6GHYUppEvF6FyRYiIiMophh2FyS07YMsOERGRGhh2lCZfLoJNO0RERGpg2FGc6XIRbNkhIiJSA8OO0ni5CCIiIlUx7ChNw11MRESkJv4SWwwPYxEREamBYUdhwtSyw8NYREREqmDYURzPxiIiIlITw47i7g0qyMtFEBERqYJhR2m86jkREZGqGHaUdq/PjoYdlImIiFTBsKM407Wx2LJDRESkBoYdpfEwFhERkaoYdiyFYYeIiEgVDDtKk0dQZtghIiJSA8OO0uSrnrODMhERkRoYdhRnGmeHiIiI1MCwozR2UCYiIlIVw47S2GeHiIhIVQw7ijO17LDPDhERkRoYdhSm1Uq72Ghk2CEiIlIDw47CrHTSLjYYGHaIiIjUwLCjMJ1OBwDIYcsOERGRKhh2FGZlOoxlMKhcEyIiovKJYUdh8mEstuwQERGpgmFHYTorKwBs2SEiIlILw47CtNa20h1jlroVISIiKqcYdhRmdS/s6Bh2iIiIVMGwozArGzsAgM6YrXJNiIiIyieGHYVZ29gDAKxENrJy2EmZiIjI0hh2FGZrJ7XsWCMHqZk5KteGiIio/GHYUZjWSuqzY4NspGTwUBYREZGlMewoTQ47OUjJYMsOERGRpTHsKE1nDQCw0WQjmS07REREFsewozStFHZaa88ilS07REREFsewo7S7t+W7PIxFRERkeQw7SvNuId9lB2UiIiLLY9hRmq0zACBDWLNlh4iISAUMO0qzlgYVtNNkIzmdl4wgIiKyNIYdpd0LOwCQdjdNxYoQERGVTww7SrPKDTsZDDtEREQWx7CjNJ2VfDcrI1XFihAREZVPDDsW5JZ2Ue0qEBERlTsMOxbknX5e7SoQERGVO6qGndmzZ6N169ZwdnaGh4cHevfujejoaLMyGRkZCAkJgbu7O5ycnNCvXz/Ex8eblYmJiUFQUBAcHBzg4eGBCRMmICen9J3mfTKnmtpVICIiKndUDTs7d+5ESEgI9u/fj7CwMGRnZ6NLly5IS8vtyDt27Fj8+++/WLlyJXbu3Inr16+jb9++8nyDwYCgoCBkZWVh3759+OWXXxAaGopp06apsUkFyvZuDQAQWXeRYzCqXBsiIqLyRSOEEGpXwuTmzZvw8PDAzp070alTJ+j1elSuXBnLli1D//79AQBnzpyBr68vwsPD0a5dO2zcuBEvvvgirl+/Dk9PTwDAokWLMHHiRNy8eRM2NjaPXG9ycjJcXV2h1+vh4uJS4ttl/KUntJd24t2sdzB98kxUdHx0nYiIiOjhCvv7Xar67Oj1egBAxYoVAQBHjhxBdnY2AgIC5DINGzZE9erVER4eDgAIDw9HkyZN5KADAIGBgUhOTsbp06cLXE9mZiaSk5PNbkrS5hlYUJ/OS0YQERFZUqkJO0ajEWPGjEGHDh3QuHFjAEBcXBxsbGzg5uZmVtbT0xNxcXFymbxBxzTfNK8gs2fPhqurq3zz8fEp4a25j70U3tyhR9JdjqJMRERkSaUm7ISEhODUqVNYvny54uuaNGkS9Hq9fIuNjVV2ha5VAQBemjtIYssOERGRRVk9uojyRo4ciXXr1mHXrl2oVi33jCUvLy9kZWUhKSnJrHUnPj4eXl5ecpmDBw+aLc90tpapzP1sbW1ha2tbwlvxEKbDWMhCMsMOERGRRanasiOEwMiRI7F69Wr8999/qFWrltn8li1bwtraGtu2bZOnRUdHIyYmBv7+/gAAf39/REREICEhQS4TFhYGFxcX+Pn5WWZDHkUnBSsbTTaS7jLsEBERWZKqLTshISFYtmwZ/vnnHzg7O8t9bFxdXWFvbw9XV1cMHToU48aNQ8WKFeHi4oJRo0bB398f7dq1AwB06dIFfn5+GDRoED777DPExcVhypQpCAkJsWzrzcNY3Qs7yGHYISIisjBVw87ChQsBAM8++6zZ9CVLluD1118HAMydOxdarRb9+vVDZmYmAgMDsWDBArmsTqfDunXrMGLECPj7+8PR0RFDhgzBrFmzLLUZj6bVAQA6aU/iMA9jERERWVSpGmdHLUqPs4NlLwNnNwEAxvntxFcDmpf8OoiIiMqZJ3KcnTIr7ZZ8V8/DWERERBbFsGMJL8yU7/LUcyIiIsti2LEEtxoAgExhzRGUiYiILIxhxxKsHQAAtppsJKdlqFwZIiKi8oVhxxLuDSoIAJkZaWCfcCIiIsth2LEEK7vcu4YMpGcbVKwMERFR+cKwYwna3N1cT3uNAwsSERFZEMOOhS2wnsewQ0REZEEMOxZWUZPKM7KIiIgsiGFHBfr0LLWrQEREVG4w7KiAh7GIiIgsh2FHBRxFmYiIyHIYdlTAPjtERESWw7CjAh7GIiIishyGHRWwgzIREZHlMOyoYENEnNpVICIiKjcYdoiIiKhMY9ghIiKiMo1hx1JaDDJ7aDDyyudERESWwLBjKRVqmD2MTbyrUkWIiIjKF4YdS9Fa596FEamZOSpWhoiIqPxg2LEUl6ryXWfc5Vg7REREFsKwYykNu8t3n9ZGIIlj7RAREVkEw46l6Gzlu3dhizts2SEiIrIIhh1L0VnJd9Nhi6Q0tuwQERFZAsOOCqZb/YoLN1PVrgYREVG5wLCjgobaWKw5fl3tahAREZULDDtERERUpjHsEBERUZnGsKOijGyD2lUgIiIq8xh2VJSexbBDRESkNIYdFW0+Had2FYiIiMo8hh1L6vCu2UNXe+sHFCQiIqKSwrBjSTU6AABOGGsDAD5YFaFmbYiIiMoFhh1L0tkAAGwgXSpCn85LRhARESmNYceS5LCTI0/KzGEnZSIiIiUx7FiSlXQx0DraG/Kknt/uVas2RERE5QLDjiVpNPLdnlop5ETHpyA6LkWeHhYZj3Un819KQgihfP2IiIjKIKtHF6ESo9HJd7vojmCtUeqwHDhvFwDgzQ618PPeSwCAhl4uSEjJwC/7LqNtLXfMDTuLqS/6YUBrH8vXm4iI6AnGlh1L0uWeaq5D/r46pqADAAFf7cSrPxzA5tPxmLUuEimZOXj/75P442AMku5m4YddF5GRbUBGtgFHY+7gx90XcSs1E/6zt2Hg4v0wGB/cEiSEQGziXWyMuFFiLUbRcSkYuHg/Dl9OLJHlAVI9Cxp4MTPHgA0RN3AnLQsGo3jotpoYjALGQpQrjYQQRerMnmMwYszyY/ht/5UircdoFMjMMeDK7TTE6TMK/byUjGz8tOcSbujTS0ULZGaOAetP3kBiWhYA6bVff/IGriell8jyj8cm4fudFwr1vnsQIQSOxdyB/m7RT1LYfiYBp67pCz0C+w19+hP73qfSJSwyHot2XigVn/Oi0ognsdYlLDk5Ga6urtDr9XBxcVFuRTejge/aAACW5zyLD3KGKbeuPFpUd0Po621w4NJtjFx2DFkGozzvvRfqo1fzqoiOT8He87egT8/GUzUqoIWPG8Iv3EavFt5wsbPGD7suIi3LgIOXbqNxVVfotBr8X3dfWOu0SMnIRpe5u3Dj3g/kh70a4eRVPab18INRAG8sOYjJQX6o7+mEI1fuYNHOC8jMMaJnM28ENvKCt5s9AOmD9PW2s6jh7giDQWDTvUEXJwQ2QO1KjuhYrxKstFr4TtsEAGjg6YxsoxFWWg02j+mEiGt6fLQ+Cv/rVBvPNvCATisdNtx0Kg7Dfz+C2pUcMSGwAWIS70Kn1WDe1nPo2tgLU4P84OpgjRWHYnHxVhr6t6yG6hUdcDTmDmIS72JAq/ytaTf06Qi/cBs9mnnDWpf7P8O+87eg1Wqw6VQcBvnXQPWKDvL8jGwDftpzCVZaDV5tWx3OdlL4TbqbhY2n4rD3/C20rVURg/xrQgiBf0/egJeLHX7cfRFbIuOxYfTT8PPOfX8ajQIHLyeiZY0KZnX498R1jPrjGABgfJf6aF2zItrWdkfk9WScuq5HncpOCL9wC19sOSs/Z8f4Z/HclzuQ99vg8pwgnLqmx7qTNzDq+bpwtDVvCN5yOg4HLyXiSuJdhEXGAwDcHKzx65ttUMHBBocuJyKoaRXYWunMnmc0ChiFgJVOK782EwIbYPgzdfBr+GW0qVURflVcoMlz2Devv49cxa/7r+D711rCKASm/XMa3m52GPl8XXg42+HTTWewcMcFeLrYYulbbbH3/G1MX3saAHDmw66wszavT7bBiCu301CnspO8zgs3U7EtKh6D/WvmK1/zg/UApPdlyHN1zeYt3nUBO6Jv4puBLeBmbw0rXcH/T4ZFxuPtXw/D2dYKx6a9gHMJqWjo5YyFOy9g+5kE/PpmW2RkG6DVaODqkPtP0sWbqXj+y53y4ylBvhjasRYAIOfefs27v/85fg3vLj+Ofk9Vw5cDmsnLiNNn4PtdF1HR0QbP1K+MahXscfp6Mgb714BGo8H1pHREx6WgcVVXnIlLhoezHVYdvYrhz9SBvY0O/RbuQ6saFTCpuy+2n0lA+7qVzMYNu52aiaMxSWhfxx321jpotQW/lkIInI1PRe3KjvJ7OMdghJVOixyDEZ9sOIMOdd3R2dcTgBRkdRoNrHRaGIwCJ64mQavRoLmPGwxGAa0G8mt46poeDjY61K7sVOC6HyUrR/puMdVdCIFT15JRz9PJ7D2RkpENZztrCCEQeSMZdSo75XvP3O9YzB1sPBWHMQH14GBjhZspmbh4MxXV3R3gYGOVbwy2OH0GKjvbyt9p9zPts4cRQuCzzdGoXtEBA9tUl6c96HNWENN7//mGHvhxcCv8tv8KWlR3Q5OqrsjINsLeRicv01SngtZbkgr7+82wAwuGndsXgG+fAgD8oHsZH6f1Um5d5UytSo64dCst3/R2tSti/8WSaW3ycLZFQkpmvumNvF1Q1c0eNSs5YvGui4VeXugbrZFjEHjr18Nm032ruCDqRnKBz6nkZItbqfnrAADfD2qJdrXd0Wzmlnzz3uhQE0v2Xi503QBgxLN1sHDHBfnxa+2q4/f9MQCA97s2wGebogu1nKCmVbD+5A30aOaNf0/k9kfr2cwba/M8DvD1xNaoePmxT0V7NKriik2n49CnRVVcuZ2GcS80wGs/HQAA+Nd2x+XbaXLIBoDP+jfF+3+dLFS9Gng6o4Kjtfz+eK5BZXi52qFaBQd8vlnatm6NvdDcxw2dfT3w35kEeDjbYcyfx+VlvPdCfXwZdhZOtlbo3cJb3j8mbg7WsNZpcTPP+2Z6Dz/M/DdSfvyCnyfCIuMf+P56lPvf+/2eqiYH7ac+DJOnV3Cwxp1CtCRNCfLFR+ujCrXubo29sPGU9E9J2NhOqOBoA2udFl3n7TJ7XQJ8PXDnbjaOXLmDKUG+MBgFZm88AztrLTKyc//5mvaiH2ati8QQ/xq4lpQhvx/+Gu6PVceuYdkB8/1r8lbHWth2JgEpGdmo4e6ImT0b4cVv9wCQukrOe7k57qRlYc6mM/hfpzoY7F8DWQYj/j5yFfY2VnimfiVoNRqcT0iFlU6DDRFx+OvIVQCArZUWVd3scedultn+61DXHW1qumPu1rP43zO1cfFmmhz6TfJ+ZkzqejjhfEKq/HjF//wx4PvwB+7jr19pjneXHwcA/D60LUL3XUL7OpXQvLob+i7Yh+oVHRCTeBcAcGl2dxy+cgcvLQpHPQ8nLAh+CqmZOfjjYAxWHL5a4PIDfD0x7oX68Hazw5pj13Bdn4Fz8Sm4npSB6PgU/DmsHVIzczD0l8MFPv9h7v/+PT7tBbg52BR5OQ/DsFMEFgs72enAx17yw5oZy5RbFxERUSlycHJneDjblegyC/v7zT47lmRtb/bwx8GtVKoIERGRZRmNjy6jFIYdFQX4eeLynCCc+bCr2lUhIiJSVLZBvbTDU89LATtrHS7PCQIgdez75/h1zFonHdN3tbfmZSWIiOiJx7BDMncnW7zZsRba1q6I/6IS8Grb6mj50Va42ltjYJvqqO/pBC9XO4xfcQLDOtVG/1Y+cLK1wvWkdNhb62AQAq8vOYjE1CwEt6uB8Au3sef8LQBA3xZVUdnZFpdupeHjPk3Q+uOtKm8tERGVBy52VvIZqGpgB2VYsIMyAMyuDmTqpfsz9IV6SkpGNmystPlO4S0sfXo2jsXcQad6lc1OAb2TloVd527iz0Ox2HfhNio62qBaBXvU83BGcx9XDPKvCUA6TdJKq0WTaq7IyjEiy2DEnnM30aJ6BYz4/Qja16mEMQH1sPbEdYxbcQKAdMqz6dTmyFmBuHgzDd5u9qjoaAMhBK4lpaOqmz2MAuj85Q5cvn0XrvbW2PfB8wj4aideauWDZ+pXQr+F5mcp9G9ZDTXdHfBy6+r468hVdKxbCfU8nfD55mhUdLTBq22qo8W9M1D6PVUNb3SoiZspmdBqNUjNyEF6tgGBjTwxf/t5NK/mhud9PbD66DXsPn8L7wc2gIudtfx8ANg8phMqOFhj97lbWHviOj7p2wQvfx+Oq3ek+r/9dC3UqOSISo626DF/D2pVcsS6UR2x8+xNvLP0qFndp73oh/CLt/Fi0yo4E5eCZtVc8d6KE0jLMuDpepWw+9ytfK/d/FdbIMDXEzdTMjHmz+OoVckRQU2rQAPg9/1X0KOZN/48FIs5fZui0+fb5ecN8a+BX8Jzx9mZ+qIfejX3RquPHhxwfxrSClk5Roy4r94rh/vjbHwKnq5bGesjbuDTTWcAAFoN8OubbbHx1A0sPRCDMQH1UMXVDvY2VujZzFs+TRWQTmPfe/4Wgn88gO5NvPBZ/2aY+NdJ+Hm74J1n68BgFMg2SO+LF7/djeC2NVDVzR7PNfSAp4stNNDIQw4U1pQgXwS3rYFXFofDz9sFEdf0OHUtGS+38oFGAxiFgLVOizc61MK8rWex7qR0GZehHWthQmADnIlLwTu/H0Hi3SyzM4YKa9FrLTH89yNm00xn2u1+/zm4O9nAb9rmAp/bumYFvNauBgDASqvFxL9Pom2tihjYpjr2XbhtNiZXDXcHfPlSM6yPuAErrQY/7L5ktqxujb3watvqGPTTwYfWbXyX+qjiao/3Vp7AjB5+eKmVD87EpeDN0EPQp2fDzloLDTRIL+T4Pnk926Ay0jJzoNVo0La2O7797xyaVnPDi02q4MuwaGRkG+Foo0N1d0d0b+yFL8POYuRzdTF/+3l5GZ3qV4aznRUae7vK78G8dd92JgFZOUacvl7wmYwmjjY6vN2pNsIi4/FiU298uukMmlVzxYmrud/HTaq6oqqbPTJyDNgRfRMA8G7neqjv6Yw9528i4poeRiMwsG11/LDronw21MNM7+GHQ5cT4WBjJZ/plVclJxvM7NkYIctyP3+BjTzxdL3KmL72NJpUdcXx2CSz5/Rq7o1/juee0dimZkUcfMBYZ/613XHg0m08bMilcS/UR2ziXay8r37vPFsHCSmZBda7ILZWWmTm5H5mFgQ/he5NqhTquUVV6N9vQUKv1wsAQq/XK7+y0B5CTHeRbqVEVo5BnL6mF0aj8bGXlZGdI+5m5gghhLibmSP06VmFes6fh2LE9aS7+ebdTMkQNSauEx/8fbLQdUjPyhFZOYbCV/o+qRnZIvsxnm8Sn5wuDAaj+PtIrDh8ObHAMulZOfnWdfqaXnT8dJv481BMkddpMBjN7n+5+YzYFhUnTzMajWav862UDHEuPtls2p20TPHhv6fF6WuP93k4fU0v/D/ZKlYejn2s5eT18vf7RI2J68SuswlCCCFyDEYRp08XRqNR3ErJEEajUdxIShfn4pPzPddoNIrM7IJf1+wcgzh46bbIyM554HwhhDh1LUlsPnVD1Ji4TtSYuE6kZ+WIj9dHik83Rokrt9JE/ckbRI2J68S1O9J7OSvHINKzcsTY5cfE2uPX8i03x2AUP+y6IE7E3hFGo1H836qT4tfwyw/dBwaDUYRfuCX06VlCn55l9tpl5xjE6qNXRWximlm9hRAiM9sgDl9OlKediL0jnv9iu9gaGSeKKk6fLu8D0+3gpdtCCCHO3EgW+87fEu1nbxNzw6LFxogb+b5bTN8Rj3IyNkm8v/KEmLn2tEjJyJann41LFmmZ2QU+58+DMeLPgzFiY8QNseporEjPyhGpGdni8q3UR66vuJ/78Au3xPDfDou0zGwxNyxafPD3CXkbVx2NzbePcwxGsefcTZGcniWuJ90Vq47Gmn1nrT95XXyyIdJsv5ne40IIsSM6QUz864S8D/49cU0ci7kjUjKyxT/Hr4mUjGxxOzVTrDoaK7p/vUvsPX9TXs6Qnw+Iyaul79PDl2+LFrO2iJ3RCWb1y8jOEb+GXxb/nYkXN5LSzeb9tPui2HI6TqRn5YhDl26Lq3fuipcW7hM/7LogXlq0T6w5dlUIIX2P/hp+WcTrzZ9f0gr7+82WHVi4ZeePV4Hoe//xjggHPP2UXV8ZIIo48BWVbUajeOAgdZYghMD/rY6Ai701JnXzNZuXmpmD5PRseaDMsiwrx4g952/CRqdDQkoG+j5VTe0qUTlU2N9v9tmxNBvH3PtXDzLsFAKDDuWlZtABpPfj7L5NC5znZGsFJ9vy8bVqY6XF8w091a4GUaHw1HNLa9g9977OVr16EBERlRMMO5bm1zv3foUaqlWDiIiovGDYsTSNBqh87zi/gePnEBERKY1hRw03711k7zzHuSEiIlIaw46a9n2jdg2IiIjKPIYdIiIiKtMYdoiIiKhMY9ghIiKiMo1hR23Xj6ldAyIiojKNYUdte+apXQMiIqIyjWFHDTU65t6/sk+9ehAREZUDDDtqcPbKvZ+WoF49iIiIygGGHTXwMhFEREQWw7Cjhpavmz9Ou6VKNYiIiMoDVcPOrl270KNHD3h7e0Oj0WDNmjVm84UQmDZtGqpUqQJ7e3sEBATg3LlzZmUSExMRHBwMFxcXuLm5YejQoUhNTbXgVhSD5r7d/tebDy6bdRfILOXbQ0REVIqpGnbS0tLQrFkzfPfddwXO/+yzz/DNN99g0aJFOHDgABwdHREYGIiMjAy5THBwME6fPo2wsDCsW7cOu3btwrBhwyy1CcVz/wVAL+0EhMhfzmgEPqkCzK4KnFxhmboRERGVMRohCvqVtTyNRoPVq1ejd+/eAKRWHW9vb7z33nsYP348AECv18PT0xOhoaF45ZVXEBUVBT8/Pxw6dAitWrUCAGzatAndu3fH1atX4e3tXah1Jycnw9XVFXq9Hi4uLopsn5k7l4Gvm5lPq9ERePk3wKGi9NhoADJTgE/z9O+ZoVe+bkRERE+Iwv5+l9o+O5cuXUJcXBwCAgLkaa6urmjbti3Cw8MBAOHh4XBzc5ODDgAEBARAq9XiwIEDD1x2ZmYmkpOTzW4W5VZAB+Ure4DPakmtOSnxwKyKwPzWlq0XERFRGWSldgUeJC4uDgDg6elpNt3T01OeFxcXBw8PD7P5VlZWqFixolymILNnz8bMmTNLuMZFoNE8eF5odyBGCnP5TktfMQRITwQG/QPsXwCk3AD0sUDVloBjZSDiL+ClJUBGMpChB7waS8/LyQSy7wL2FcyXZ8gBzm0BstIA12pA9XbA+a2AZyPApXCtYorKuguc+guo18X8dH0iIqIiKLVhR0mTJk3CuHHj5MfJycnw8fGxbCWeHg/s/iL/dFPQKUjkmntl9gFbJueZ/k/u/T1zpRsAjDoqBZnvn5Yed/lICjXntgKZeqBqK2Dr9Nzn9l4IrBkh3S/okJkQuUHtxkng7Gag/SjA2u7B5e4Xfxo4+SfQcWz+8HW/rdOBg4sBt+rAmIjc6dkZwO3zUih7WHB8XIYcQHfvI5IQBRwJBZ5+D3DyeOjTCi07Hdg0CWgYBNR7oWSWWRgZesDWRdl9Z0lGo7Qt92+PIRvYOgOo/RxQL6DAp1I59bDvKCqTSu1hLC8v6T/5+Ph4s+nx8fHyPC8vLyQkmLd+5OTkIDExUS5TEFtbW7i4uJjdLO7pcY8u8yChQQ+eZwo6APDtU7lBBwC2TAFWvg4c/x2I+tc86AC5QQeQOkSnJgA5WdLjjGTg66ZS69KKwdJyt38krS8+EpjhCqwdBaTEAZ94A+vGSdN/6QH8+RoQe1A6LLewPbD3a+lH/n55u4/Fn5aCDgAkxUh/DTnAqmHAx57Aog5SHbLTpR/vv98GzoVJ5YwG4K+hwP5FD95Pu78Clg4A0pOkx5kpQPQmqRUMAE6tktYT+Y/0o7nAHziwSFp/cSXfkPbfzbPS4/0LgCNLgKX985cVAtgxBzi9pnjrOr8NuHNFCgJxp6R9AkghdU51YKabtD9N+9z0NydLat3Lulu89eaVdVd6/cMLPgGhRBgNwIJ2wE9d8nfyPxIKhM8HlvYr+fUKIY1+nsF+dIWSlfbgeZf3Ahf+U27d2RnAgvbA2tF5HrcDVv1PuXVa0o0TwO0LD56fk1nwCTBKKh1dgc2U2padWrVqwcvLC9u2bUPz5s0BSC0wBw4cwIgR0o+yv78/kpKScOTIEbRs2RIA8N9//8FoNKJt27ZqVb1wbBzVrsHDrXo79/4HMUD4Ail0mIKHyc450g0Ajv4q3QDg8E/SzSTqX/PnnfgDqBsA+PWWWnr2zAVunwMGLgdO/Q1ErDQvn54k/Qif/DN3WlwEsG4skHgRiD0ARKwAJsdJ5U79Jd3aDTdfjtEAhL4otY4BUgfwLh/ntpS1ewfoOhv46w3p8YrB5s+/uB04/od0aM3KRhpGQGcD6K9Kh9qs7Qven8k3gK8aSvcj10gtZ0mxBZcFgMt7gB2zpft1r0rr+WMg0KAb0GYYoNXdt3/uSEMUuPkAF3cCv/eVprd6Ezj8s3R/6i3px98kbKoUuEwG/Ca9ThErABtn4IMr0pdWhh74d7S0nV5NpKCeEie17LV4TarLjRPS6/b0eODaEeD0aimwXjsMXNoFNO4vtYhpNOYBK2KF9Dp2HAc4uuffZzs+kbbXs3Huf+JCSIdvXX2kFr5b0bnTgdxydy6bL08IqbyzF3D9OFDdP7flziTtNpCVArhUyz8v/Q5weAnQ5CXg8m7pnwMreyAnXdq+/j+Zl183VnqNX1kG7P9OamHybi7VY/vHwN1EqXXTsxHQuK/5c3MygS1Tpdcj5bq0/KAvAXs3af7ZzVJw7TS+aC0U8ZGArbP0PimMzBTps1XrGUBnXfj15HX0V+kfoZ7zgacGmc8z5EiH7gFg4uVHt/bmlZUmfY9mZ+RvXc7r7EYg4bR06/mNFKxunpFufb/PLfegFsKSlJMJ5GQAdq7S+2DbLKBSPaD5q9K8A4ukz2/fxYBjpUcvL/Um8H0n6f7QMKnl3sZJ+l5rNhB4YRbwlR/g0wYY8m/JbluGXvqsn1wpbUOlekDDF6V/pACg/8/A0d+Abp8BleuX3HqLSdWzsVJTU3H+/HkAQIsWLfDVV1/hueeeQ8WKFVG9enV8+umnmDNnDn755RfUqlULU6dOxcmTJxEZGQk7O+nN3a1bN8THx2PRokXIzs7GG2+8gVatWmHZsmWFrofFz8YymeFquXWVV/93XfqP7tRf0mO36vkD2/00OkAYir6uinWAXvOBJd2kx+8ckA6jNO5rHh4LMi5K6idlal43/UA8SJ3OwIVt0v32o4B93z66fj7tgNj9hdqUh+r1HfBPiHS/si/wylKpFREAnhoCHP2l4OdVqCn9oGQkSV/21vbArbO58wf8BtTsKIWwY7/nf/7o49KPoekMRWsHoFEf4PhS83I2TkCfRcChn6RwCkg/BNeOApsm5pbz6w0MuFfXS7uBbTOBq4dy59foAFzZK93P+55wqSp9sV/cYb7e5q9JPy5arRQWP7wX3qo0B24cL3ifmAz+B6jWGkiNl567bgxwZl3BZcdEAPOaSPdfXQnU7yKFeK1OakWzrwhsniTty5fv7cf0O8DPXaUfeAAY+KcUSF/8CjBkSdtnZQdcPSiFODs34H+7gJ8DpbADAB/ESi11VZ8CmgcDuz4HEi9JIdalKvDUYCmA1HtBeg9n6KXWk7Mbc+ve/2egftfcf/a2zQJ2fynd7/YZ0PZ/0nsk/Q5g6wRY2eY+9/xW4Pd+QOu3AO+ngH/eAZq+nPsPUO9FgI0DAA0AAfj1Aq4eBn7snLuMOp2l99+1I9JjryZS2H76PakedQOA1/6WApQ+VnqdTQw5Uuu2bw+g6xyppTx6IxC8EnCvk1vOaJBeOycv4My/Uit5g25AtTbSe/vubWDsaWBuo9znDN0K/HTfodaxp4HNk4EqzaSAnTegJkRJ/0z8PTT/+8PRI7e/p3MVqW8nAPj2lAJVQhTw5ibAtar5825fAMKmSf94eDeXPlfJNwC/noCHrzT47dXDUrD8cxCQWcCJPc9PAf77KP90Bc8kLuzvt6phZ8eOHXjuuefyTR8yZAhCQ0MhhMD06dOxePFiJCUloWPHjliwYAHq189NiYmJiRg5ciT+/fdfaLVa9OvXD9988w2cnJwKXQ/Vws6RUODfdy23Piq9WrwGuFaX3hM9vgaWvaR2jUofO1dlDhvV72b+g1wYrtUB/SNCc2nQ7yepRenz2pZbp6MH8F408MuLuWHxcbQfJfU3tNQ/h6bWOkBq6T29WrpvCg0Fef8S8GsvoM7zwN55ytWtcX8g+drD+3YW1oBfpdZPj0ZA8lVgyzSpL6cSpicp1mL2RISd0kK1sHNuqzL9CYiIiEqTui8Ar/1V4ot94sfZKR/Kfc4kIqLy4HyYqqtn2CEiIiLlZVh4AN88GHbUVKO92jUgIiKyjEd11FcQw46aSvvp50RERCXF6iFDBCiMYUdtA/98dBkiIqInnYqX/WHYUVuDrtL4IwVp1MeiVXli6GzUrkHh9X7IKM7F9dIvQM2nH13usdcTCvT9Qbnl13624OlFGVhOKT4WGpT06fcKX7a4r7ktx/N6YvVfIo3X1e4doEKt4rWMvDivZOv0/BTAf6Q0blBe0+5IA18+iFcTaZwzlfDUc6h46rlJepI00NOSrubTP4gBji0FGvUG5jYueKC7NzZJY4/snANcP1bw8qu2At7eBtw6L40c3DxYGjDqQYPWTb0FLH0pd0C28eeBL+oWbZucvYHRx6RgMuu+H6/7B1kb8Js0cNWRX6RB0Zq+lH9gqqcGA10/lQY4q9kRSIgEoDG/HAYgDfbl28N8wK5HaTVUGv1XZ5P/4qsaLSCM0oc7/DtpvI+Wr0vz0hKAMxvMr1MGSKPNthwCNAiSBuD6qYtU72qtgSHrgD9eyd23j/La39IlK2o+LV0O45mJQKW690YXng20eVsaXTgnQ/oi1GikkXX/HS2NEmw642/SVWnkXJO8Y5Z0miANEPfmZulisBf+AyrWzg3h/74rjf8DAJUbSgPTWTsCA5dJgeXiDmmMEfMdJwWlpi9Jg7Yt6pg7y7W69IXZ7GVpALafXsgd5A3IPzDZ6xuk1yAjSapT3mV5+EmjOacnSo8d3KXB6SLXADU6Ak6VgU3/B6Ted2HgvIOt5dWguzSarW8PaRDCH/KPA4Z3DkifIxsnafC45OvS4HbeLaQL6+781HxbUuKAm9HSqMvyMvZLA7UBQEq8NNhc3tHBRx+TBtb74Xnp8cgj0usef1q65EpeQ7dKo2RfOyyN0eReV3qvuFaVRom2spVG5f21Z/5tuV+tTtKI14A0Pk/AdOl7Y9Vb+cu+tc18wL77NX1FGhOm41ipHlummI+qDgBjTkkDC0asuO/JGqDzVGD7J9KP/O1z5rN7fC19Dn8MkAaC7PKx9Drs/04aFK96O2DZAGkbus4GKtUHZlV8cF2t7KTPkNYaMGY/uBwAVG8PBMwAfu5iPr1KM+nz0TxY+oxsfF+aXrWl9Dn+tKb0+M3N0vd9oz5S/Rt2BzqMkb7H407mjtquswGm3iy4Drcv5A7k6eQlDQxp+gzM0AOxh6TxgZ6bJH3u025JZb7yffi25fXiPODQj0DgJ0DtZ4DItdJ+9Lg3Evy6cbmvp9YamHZLup8QJV2OAwBavw3EnwICZgLVlfkHguPsFIHqYcdkx5zcSwQA5qNOznCD/MPVa4EUfG5fkD50eQdrmttYGvkTkL5gYsKBnt9KYSEvIaQvg6RYKQjNbSR9ubrXA0Ydloay/6yWVHbiZekLe/mr0qUZTAr6sntqsLS+vOJOSZeHiDsp/bDW6iRdH2rbTCkYtHnbfBvS7+R+MbQdIf2APTOh4H129DdpVGArO+kDZXtvMMn5raXReZu+DHT/QrroaqUG0qirANDhXWndLlVzP7ym/fL3W9KIy1WaA2//l3tpBqNRGh33fjs+lX5omr0i1aPhfdcuM2RLI49WbSldYgKQvpj/HCR90T39Xu6yb1+QfmAz9ED70UCXDwve7sK4cRJYMQh4firQ5L7rb6XdkgJG3QBp+x51YcTrxwC3GoDDvR+MB5VPvAgc/BFoP1IaEdokM1W63ID+qvlos6Zl7V8ojfoLSCP1Ln1JavVs1Cd/y+fdRCk41O8q/ZCnxAHRG6QfobyvZV6/9AQu7ZTuv7FJCiYbxgPHfpOmjTkFOFY2v+yAELlD3wPS+7b96EdftDVDLw2AeL+bZ6URddsOL3x/vVvnpGvU1eyQO+34H8Ca4dJ7u+/iwi0HkK4jd/OM9L42ZEnvgfDvpEH7TJcyGXsa+L2/FGK7zcl97tpR0qjeVVtK4UUI6R+UM+ulUP3sJCmM2jhKI1en35E+61YFtMJ+XhdIu5n7XQNIl7G4vEe6pEO3z3JHTjZkS9cg+7UnoLUCpt0237/ZGfcGxrtX/5zM3Ofqr0mHTUyf37wBv8c30j98ptGhpyVKl+ao1koKG3nDd/8luZePAcy/l5NigI0fAP4h5q8RIAX5rDTA7t5vyqEfpWvP+b9T4Msji4+U6vb0e7mft8LIyZL2UUHfUfczZEtlL++W3l9xEbmDIRZ2tGP9NWCun3S/2+dA2zzXDTz0k/QPRcPuha9/MRX691uQ0Ov1AoDQ6/VqV0WIjGQh/npLiDMbzKef+FOI6S5C7P3m4c835AhxYbsQ2RlCZN0V4uoRIYzGR6/39kUh1o8XIvFy7rRN/yfE5snm5Q6HSvU4tzX38SfVhLh+4tHrKIpzYUJc2FH852dnCJGSkH/65X1CbJgoREbKw59vNBZuvynBkKPOetWUnSnExg9y31clLfWmELu+FCL5Ru60rHQhojcJkZn68Oftmy/9LU0SLwlhMJTc8uJOCxF7+MHzM9OEOL5ciLTbJbOuv4dJ3zmFdXlfwZ/nopjuIt0WdpQe374oxFeNhAhfYF4u7ba0rWc25L5fLu6Unrtv/uPVobTKzpA+HzdOFu158ZFCHFgsRE62MvUqhML+frNlB6WoZedRMlPMD0WUFo9qFSAiUtu++dLh2NfXFa+jbE5WwS1VpCoexiqCJybsEBERkYyXiyAiIiICww4RERGVcQw7REREVKYx7BAREVGZxrBDREREZRrDDhEREZVpDDtERERUpjHsEBERUZnGsENERERlGsMOERERlWkMO0RERFSmMewQERFRmcawQ0RERGUaww4RERGVaVZqV6A0EEIAkC4VT0RERE8G0++26Xf8QRh2AKSkpAAAfHx8VK4JERERFVVKSgpcXV0fOF8jHhWHygGj0Yjr16/D2dkZGo2mxJabnJwMHx8fxMbGwsXFpcSWS+a4ny2H+9oyuJ8tg/vZMpTcz0IIpKSkwNvbG1rtg3vmsGUHgFarRbVq1RRbvouLCz9IFsD9bDnc15bB/WwZ3M+WodR+fliLjgk7KBMREVGZxrBDREREZRrDjoJsbW0xffp02Nraql2VMo372XK4ry2D+9kyuJ8tozTsZ3ZQJiIiojKNLTtERERUpjHsEBERUZnGsENERERlGsMOERERlWkMOwr67rvvULNmTdjZ2aFt27Y4ePCg2lUqtWbPno3WrVvD2dkZHh4e6N27N6Kjo83KZGRkICQkBO7u7nByckK/fv0QHx9vViYmJgZBQUFwcHCAh4cHJkyYgJycHLMyO3bswFNPPQVbW1vUrVsXoaGhSm9eqTVnzhxoNBqMGTNGnsb9XDKuXbuG1157De7u7rC3t0eTJk1w+PBheb4QAtOmTUOVKlVgb2+PgIAAnDt3zmwZiYmJCA4OhouLC9zc3DB06FCkpqaalTl58iSefvpp2NnZwcfHB5999plFtq80MBgMmDp1KmrVqgV7e3vUqVMHH374odl1krifi2fXrl3o0aMHvL29odFosGbNGrP5ltyvK1euRMOGDWFnZ4cmTZpgw4YNRd8gQYpYvny5sLGxET///LM4ffq0ePvtt4Wbm5uIj49Xu2qlUmBgoFiyZIk4deqUOH78uOjevbuoXr26SE1NlcsMHz5c+Pj4iG3btonDhw+Ldu3aifbt28vzc3JyROPGjUVAQIA4duyY2LBhg6hUqZKYNGmSXObixYvCwcFBjBs3TkRGRopvv/1W6HQ6sWnTJotub2lw8OBBUbNmTdG0aVPx7rvvytO5nx9fYmKiqFGjhnj99dfFgQMHxMWLF8XmzZvF+fPn5TJz5swRrq6uYs2aNeLEiROiZ8+eolatWiI9PV0u07VrV9GsWTOxf/9+sXv3blG3bl0xcOBAeb5erxeenp4iODhYnDp1Svzxxx/C3t5efP/99xbdXrV8/PHHwt3dXaxbt05cunRJrFy5Ujg5OYmvv/5aLsP9XDwbNmwQkydPFqtWrRIAxOrVq83mW2q/7t27V+h0OvHZZ5+JyMhIMWXKFGFtbS0iIiKKtD0MOwpp06aNCAkJkR8bDAbh7e0tZs+erWKtnhwJCQkCgNi5c6cQQoikpCRhbW0tVq5cKZeJiooSAER4eLgQQvpwarVaERcXJ5dZuHChcHFxEZmZmUIIId5//33RqFEjs3W9/PLLIjAwUOlNKlVSUlJEvXr1RFhYmHjmmWfksMP9XDImTpwoOnbs+MD5RqNReHl5ic8//1yelpSUJGxtbcUff/whhBAiMjJSABCHDh2Sy2zcuFFoNBpx7do1IYQQCxYsEBUqVJD3u2ndDRo0KOlNKpWCgoLEm2++aTatb9++Ijg4WAjB/VxS7g87ltyvAwYMEEFBQWb1adu2rfjf//5XpG3gYSwFZGVl4ciRIwgICJCnabVaBAQEIDw8XMWaPTn0ej0AoGLFigCAI0eOIDs722yfNmzYENWrV5f3aXh4OJo0aQJPT0+5TGBgIJKTk3H69Gm5TN5lmMqUt9clJCQEQUFB+fYF93PJWLt2LVq1aoWXXnoJHh4eaNGiBX744Qd5/qVLlxAXF2e2j1xdXdG2bVuz/ezm5oZWrVrJZQICAqDVanHgwAG5TKdOnWBjYyOXCQwMRHR0NO7cuaP0Zqquffv22LZtG86ePQsAOHHiBPbs2YNu3boB4H5WiiX3a0l9lzDsKODWrVswGAxmPwYA4Onpibi4OJVq9eQwGo0YM2YMOnTogMaNGwMA4uLiYGNjAzc3N7OyefdpXFxcgfvcNO9hZZKTk5Genq7E5pQ6y5cvx9GjRzF79ux887ifS8bFixexcOFC1KtXD5s3b8aIESMwevRo/PLLLwBy99PDviPi4uLg4eFhNt/KygoVK1Ys0mtRln3wwQd45ZVX0LBhQ1hbW6NFixYYM2YMgoODAXA/K8WS+/VBZYq633nVcyp1QkJCcOrUKezZs0ftqpQ5sbGxePfddxEWFgY7Ozu1q1NmGY1GtGrVCp988gkAoEWLFjh16hQWLVqEIUOGqFy7smPFihVYunQpli1bhkaNGuH48eMYM2YMvL29uZ/JDFt2FFCpUiXodLp8Z7DEx8fDy8tLpVo9GUaOHIl169Zh+/btqFatmjzdy8sLWVlZSEpKMiufd596eXkVuM9N8x5WxsXFBfb29iW9OaXOkSNHkJCQgKeeegpWVlawsrLCzp078c0338DKygqenp7czyWgSpUq8PPzM5vm6+uLmJgYALn76WHfEV5eXkhISDCbn5OTg8TExCK9FmXZhAkT5NadJk2aYNCgQRg7dqzcasn9rAxL7tcHlSnqfmfYUYCNjQ1atmyJbdu2ydOMRiO2bdsGf39/FWtWegkhMHLkSKxevRr//fcfatWqZTa/ZcuWsLa2Ntun0dHRiImJkfepv78/IiIizD5gYWFhcHFxkX94/P39zZZhKlNeXpfOnTsjIiICx48fl2+tWrVCcHCwfJ/7+fF16NAh39AJZ8+eRY0aNQAAtWrVgpeXl9k+Sk5OxoEDB8z2c1JSEo4cOSKX+e+//2A0GtG2bVu5zK5du5CdnS2XCQsLQ4MGDVChQgXFtq+0uHv3LrRa858xnU4Ho9EIgPtZKZbcryX2XVKk7sxUaMuXLxe2trYiNDRUREZGimHDhgk3NzezM1go14gRI4Srq6vYsWOHuHHjhny7e/euXGb48OGievXq4r///hOHDx8W/v7+wt/fX55vOiW6S5cu4vjx42LTpk2icuXKBZ4SPWHCBBEVFSW+++67cnVKdEHyno0lBPdzSTh48KCwsrISH3/8sTh37pxYunSpcHBwEL///rtcZs6cOcLNzU38888/4uTJk6JXr14FnrrbokULceDAAbFnzx5Rr149s1N3k5KShKenpxg0aJA4deqUWL58uXBwcCjTp0TnNWTIEFG1alX51PNVq1aJSpUqiffff18uw/1cPCkpKeLYsWPi2LFjAoD46quvxLFjx8SVK1eEEJbbr3v37hVWVlbiiy++EFFRUWL69Ok89by0+fbbb0X16tWFjY2NaNOmjdi/f7/aVSq1ABR4W7JkiVwmPT1dvPPOO6JChQrCwcFB9OnTR9y4ccNsOZcvXxbdunUT9vb2olKlSuK9994T2dnZZmW2b98umjdvLmxsbETt2rXN1lEe3R92uJ9Lxr///isaN24sbG1tRcOGDcXixYvN5huNRjF16lTh6ekpbG1tRefOnUV0dLRZmdu3b4uBAwcKJycn4eLiIt544w2RkpJiVubEiROiY8eOwtbWVlStWlXMmTNH8W0rLZKTk8W7774rqlevLuzs7ETt2rXF5MmTzU5l5n4unu3btxf4nTxkyBAhhGX364oVK0T9+vWFjY2NaNSokVi/fn2Rt0cjRJ6hJomIiIjKGPbZISIiojKNYYeIiIjKNIYdIiIiKtMYdoiIiKhMY9ghIiKiMo1hh4iIiMo0hh0iIiIq0xh2iIgKoNFosGbNGrWrQUQlgGGHiEqd119/HRqNJt+ta9eualeNiJ5AVmpXgIioIF27dsWSJUvMptna2qpUGyJ6krFlh4hKJVtbW3h5eZndTFdC1mg0WLhwIbp16wZ7e3vUrl0bf/31l9nzIyIi8Pzzz8Pe3h7u7u4YNmwYUlNTzcr8/PPPaNSoEWxtbVGlShWMHDnSbP6tW7fQp08fODg4oF69eli7dq2yG01EimDYIaIn0tSpU9GvXz+cOHECwcHBeOWVVxAVFQUASEtLQ2BgICpUqIBDhw5h5cqV2Lp1q1mYWbhwIUJCQjBs2DBERERg7dq1qFu3rtk6Zs6ciQEDBuDkyZPo3r07goODkZiYaNHtJKISUORLhxIRKWzIkCFCp9MJR0dHs9vHH38shBACgBg+fLjZc9q2bStGjBghhBBi8eLFokKFCiI1NVWev379eqHVakVcXJwQQghvb28xefLkB9YBgJgyZYr8ODU1VQAQGzduLLHtJCLLYJ8dIiqVnnvuOSxcuNBsWsWKFeX7/v7+ZvP8/f1x/PhxAEBUVBSaNWsGR0dHeX6HDh1gNBoRHR0NjUaD69evo3Pnzg+tQ9OmTeX7jo6OcHFxQUJCQnE3iYhUwrBDRKWSo6NjvsNKJcXe3r5Q5aytrc0eazQaGI1GJapERApinx0ieiLt378/32NfX18AgK+vL06cOIG0tDR5/t69e6HVatGgQQM4OzujZs2a2LZtm0XrTETqYMsOEZVKmZmZiIuLM5tmZWWFSpUqAQBWrlyJVq1aoWPHjli6dCkOHjyIn376CQAQHByM6dOnY8iQIZgxYwZu3ryJUaNGYdCgQfD09AQAzJgxA8OHD4eHhwe6deuGlJQU7N27F6NGjbLshhKR4hh2iKhU2rRpE6pUqWI2rUGDBjhz5gwA6Uyp5cuX45133kGVKlXwxx9/wM/PDwDg4OCAzZs3491330Xr1q3h4OCAfv364auvvpKXNWTIEGRkZGDu3LkYP348KlWqhP79+1tuA4nIYjRCCKF2JYiIikKj0WD16tXo3bu32lUhoicA++wQERFRmcawQ0RERGUa++wQ0ROHR9+JqCjYskNERERlGsMOERERlWkMO0RERFSmMewQERFRmcawQ0RERGUaww4RERGVaQw7REREVKYx7BAREVGZxrBDREREZdr/A8s1VHiEaMMJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predicted Solar Energy Ouput: [1836.129150390625, 322.12078857421875, 319.4498291015625, 1337.8634033203125, 259.6224060058594, 277.2915954589844, 1150.3963623046875, 327.8564453125, 1116.6658935546875, 1739.9664306640625, 223.82748413085938, 920.989013671875, 455.3826904296875, 584.8221435546875, 868.51171875, 268.5933532714844, 252.87197875976562, 443.6199035644531, 422.4750061035156, 332.94854736328125]\n",
      "Actual Solar Energy Output: [1829.  309.  327. 1697.  232.  261. 1079.  332. 1383. 1715.  212.  971.\n",
      "  452.  551.  879.  300.  247.  470.  421.  338.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "predictions[predictions < 0] = 0\n",
    "flattened_predictions = [0 if (isinstance(pred, np.ndarray) and pred.item() < 0) else (0 if pred < 0 else pred.item() if isinstance(pred, np.ndarray) else pred) for pred in predictions]\n",
    "\n",
    "print(f'Predicted Solar Energy Ouput: {flattened_predictions[:20]}')\n",
    "print(f'Actual Solar Energy Output: {y_test[:20].values}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 41.52891443619469\n",
      "Mean Squared Error (MSE): 5659.797727185141\n",
      "Root Mean Squared Error (RMSE): 75.23162717358399\n",
      "Percent Error (PERR): 0.08146783043723332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming predictions and y_test are numpy arrays or pandas series\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "average_y_test = np.mean(y_test)\n",
    "percent_error = mae / average_y_test\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Percent Error (PERR): {percent_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('HydroModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
