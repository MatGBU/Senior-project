{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avishai\\AppData\\Local\\Temp\\ipykernel_57704\\299724603.py:6: DtypeWarning: Columns (12,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('C:/Users/Avishai/Desktop/Senior-project/Two_Year_Training_Set.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv('C:/Users/Avishai/Desktop/Senior-project/Two_Year_Training_Set.csv')\n",
    "data = data.fillna(0)\n",
    "data['BeginDate'] = pd.to_datetime(data['BeginDate']).dt.tz_localize(None)\n",
    "data[\"Sum\"] = data[[\"Coal\", \"Hydro\", \"Natural Gas\", \"Nuclear\", \"Oil\", \"Other\", \"Landfill Gas\", \"Refuse\", \"Solar\", \"Wind\", \"Wood\"]].sum(axis=1)\n",
    "data['Previous_Day'] = data['BeginDate'] - pd.Timedelta(days=1)\n",
    "data['Previous_2Day'] = data['BeginDate'] - pd.Timedelta(days=2)\n",
    "data['Previous_Year'] = data['BeginDate'] - pd.DateOffset(years=1)\n",
    "wind_data = data[['BeginDate', 'Wind','Previous_Day','Previous_Year','Previous_2Day']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_day_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Wind'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Day']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_two_days_before_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Wind'].values\n",
    "    \n",
    "    # Calculate two days before\n",
    "    target_date = row['BeginDate'] - pd.Timedelta(days=2)\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_year_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Wind'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Year']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large computation \n",
    "data['Previous_Year_Wind'] = data.apply(get_previous_year_Wind, axis=1, reference_df=wind_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"2023-10-01\").tz_localize(None)\n",
    "usable_data = data[data['BeginDate'] > cutoff_date].copy()\n",
    "solar_data2 = usable_data[['BeginDate', 'Wind','Previous_Day','Previous_2Day','Previous_Year']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "usable_data['Previous_Day_Wind'] = usable_data.apply(get_previous_day_Wind, axis=1, reference_df=solar_data2)\n",
    "usable_data['Previous_2Day_Wind'] = usable_data.apply(get_two_days_before_Wind, axis=1, reference_df=solar_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (93643, 22)\n",
      "Target shape:  (93643,)\n"
     ]
    }
   ],
   "source": [
    "usable_data['Hour_of_Day'] = usable_data['BeginDate'].dt.hour\n",
    "usable_data['Month'] = usable_data['BeginDate'].dt.month\n",
    "usable_data['Year'] = usable_data['BeginDate'].dt.year\n",
    "usable_data['WindSpeedCubed'] = usable_data['windspeed'] ** 3\n",
    "features = usable_data[['WindSpeedCubed','Month','Year','Previous_Year_Wind','Previous_2Day_Wind','Sum','snowdepth','temp','solarenergy','sealevelpressure', 'humidity','solarenergy','snow', 'precip', 'uvindex', 'cloudcover', 'Previous_Day_Wind','Hour_of_Day','dew','windgust','windspeed','winddir']]\n",
    "\n",
    "# Useless Features , ,\n",
    "target = usable_data['Wind']\n",
    "\n",
    "print(\"Features shape: \", features.shape)\n",
    "print('Target shape: ', target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=70, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avishai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Avishai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 375.7404 - val_loss: 350.6451 - learning_rate: 0.0010\n",
      "Epoch 2/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 341.3485 - val_loss: 291.3764 - learning_rate: 0.0010\n",
      "Epoch 3/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 279.2595 - val_loss: 222.9889 - learning_rate: 0.0010\n",
      "Epoch 4/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 201.5859 - val_loss: 144.9026 - learning_rate: 0.0010\n",
      "Epoch 5/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.4778 - val_loss: 113.3084 - learning_rate: 0.0010\n",
      "Epoch 6/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.9409 - val_loss: 98.9229 - learning_rate: 0.0010\n",
      "Epoch 7/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.6276 - val_loss: 89.5584 - learning_rate: 0.0010\n",
      "Epoch 8/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.7685 - val_loss: 85.9089 - learning_rate: 0.0010\n",
      "Epoch 9/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.4099 - val_loss: 80.1570 - learning_rate: 0.0010\n",
      "Epoch 10/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.4677 - val_loss: 73.9482 - learning_rate: 0.0010\n",
      "Epoch 11/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89.8150 - val_loss: 73.0373 - learning_rate: 0.0010\n",
      "Epoch 12/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88.1975 - val_loss: 69.5393 - learning_rate: 0.0010\n",
      "Epoch 13/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87.2411 - val_loss: 73.3574 - learning_rate: 0.0010\n",
      "Epoch 14/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86.0409 - val_loss: 70.5254 - learning_rate: 0.0010\n",
      "Epoch 15/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84.4544 - val_loss: 65.5499 - learning_rate: 0.0010\n",
      "Epoch 16/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84.5118 - val_loss: 67.5322 - learning_rate: 0.0010\n",
      "Epoch 17/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84.2355 - val_loss: 68.6085 - learning_rate: 0.0010\n",
      "Epoch 18/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82.8851 - val_loss: 64.8698 - learning_rate: 0.0010\n",
      "Epoch 19/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82.4181 - val_loss: 66.5683 - learning_rate: 0.0010\n",
      "Epoch 20/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82.1247 - val_loss: 64.7320 - learning_rate: 0.0010\n",
      "Epoch 21/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81.2950 - val_loss: 65.0129 - learning_rate: 0.0010\n",
      "Epoch 22/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81.8443 - val_loss: 61.8890 - learning_rate: 0.0010\n",
      "Epoch 23/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80.2613 - val_loss: 63.5970 - learning_rate: 0.0010\n",
      "Epoch 24/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80.1962 - val_loss: 58.2499 - learning_rate: 0.0010\n",
      "Epoch 25/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79.6187 - val_loss: 61.9303 - learning_rate: 0.0010\n",
      "Epoch 26/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.8022 - val_loss: 60.0473 - learning_rate: 0.0010\n",
      "Epoch 27/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.8632 - val_loss: 67.0928 - learning_rate: 0.0010\n",
      "Epoch 28/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79.7049 - val_loss: 58.4598 - learning_rate: 0.0010\n",
      "Epoch 29/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.3583 - val_loss: 58.4946 - learning_rate: 0.0010\n",
      "Epoch 30/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.5212 - val_loss: 57.5067 - learning_rate: 0.0010\n",
      "Epoch 31/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.7131 - val_loss: 60.6757 - learning_rate: 0.0010\n",
      "Epoch 32/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.6663 - val_loss: 55.8496 - learning_rate: 0.0010\n",
      "Epoch 33/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.0486 - val_loss: 55.4693 - learning_rate: 0.0010\n",
      "Epoch 34/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.1404 - val_loss: 55.7460 - learning_rate: 0.0010\n",
      "Epoch 35/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.8882 - val_loss: 56.1842 - learning_rate: 0.0010\n",
      "Epoch 36/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.6251 - val_loss: 54.3603 - learning_rate: 0.0010\n",
      "Epoch 37/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.8293 - val_loss: 57.6119 - learning_rate: 0.0010\n",
      "Epoch 38/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.8475 - val_loss: 56.1532 - learning_rate: 0.0010\n",
      "Epoch 39/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.9491 - val_loss: 55.2598 - learning_rate: 0.0010\n",
      "Epoch 40/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.9277 - val_loss: 55.9492 - learning_rate: 0.0010\n",
      "Epoch 41/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.0918 - val_loss: 53.1591 - learning_rate: 0.0010\n",
      "Epoch 42/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.1196 - val_loss: 53.9022 - learning_rate: 0.0010\n",
      "Epoch 43/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.0141 - val_loss: 56.6847 - learning_rate: 0.0010\n",
      "Epoch 44/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.6123 - val_loss: 54.1233 - learning_rate: 0.0010\n",
      "Epoch 45/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.3775 - val_loss: 56.7517 - learning_rate: 0.0010\n",
      "Epoch 46/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.9183 - val_loss: 54.9753 - learning_rate: 0.0010\n",
      "Epoch 47/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.2025 - val_loss: 54.4165 - learning_rate: 0.0010\n",
      "Epoch 48/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.8498 - val_loss: 54.0856 - learning_rate: 0.0010\n",
      "Epoch 49/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.2539 - val_loss: 50.7708 - learning_rate: 0.0010\n",
      "Epoch 50/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.4175 - val_loss: 52.4305 - learning_rate: 0.0010\n",
      "Epoch 51/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.1768 - val_loss: 52.7919 - learning_rate: 0.0010\n",
      "Epoch 52/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.2148 - val_loss: 52.0355 - learning_rate: 0.0010\n",
      "Epoch 53/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.3458 - val_loss: 52.0345 - learning_rate: 0.0010\n",
      "Epoch 54/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.5269 - val_loss: 54.1688 - learning_rate: 0.0010\n",
      "Epoch 55/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.6832 - val_loss: 51.3223 - learning_rate: 0.0010\n",
      "Epoch 56/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.6309 - val_loss: 50.6379 - learning_rate: 0.0010\n",
      "Epoch 57/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.3835 - val_loss: 51.4217 - learning_rate: 0.0010\n",
      "Epoch 58/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.6724 - val_loss: 54.3210 - learning_rate: 0.0010\n",
      "Epoch 59/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.4400 - val_loss: 50.8049 - learning_rate: 0.0010\n",
      "Epoch 60/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.9416 - val_loss: 54.2819 - learning_rate: 0.0010\n",
      "Epoch 61/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.9657 - val_loss: 54.6165 - learning_rate: 0.0010\n",
      "Epoch 62/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.8125 - val_loss: 48.6509 - learning_rate: 0.0010\n",
      "Epoch 63/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.3627 - val_loss: 57.1961 - learning_rate: 0.0010\n",
      "Epoch 64/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.3335 - val_loss: 53.3079 - learning_rate: 0.0010\n",
      "Epoch 65/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.2987 - val_loss: 52.8247 - learning_rate: 0.0010\n",
      "Epoch 66/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.0103 - val_loss: 51.4566 - learning_rate: 0.0010\n",
      "Epoch 67/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.3351 - val_loss: 52.5111 - learning_rate: 0.0010\n",
      "Epoch 68/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.5464 - val_loss: 54.3207 - learning_rate: 0.0010\n",
      "Epoch 69/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.1654 - val_loss: 51.2857 - learning_rate: 0.0010\n",
      "Epoch 70/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.2475 - val_loss: 50.4292 - learning_rate: 0.0010\n",
      "Epoch 71/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.7395 - val_loss: 49.9245 - learning_rate: 0.0010\n",
      "Epoch 72/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.6973 - val_loss: 49.3672 - learning_rate: 0.0010\n",
      "Epoch 73/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.9217 - val_loss: 45.8734 - learning_rate: 5.0000e-04\n",
      "Epoch 74/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.2747 - val_loss: 45.4286 - learning_rate: 5.0000e-04\n",
      "Epoch 75/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.8678 - val_loss: 44.3029 - learning_rate: 5.0000e-04\n",
      "Epoch 76/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.6681 - val_loss: 45.2082 - learning_rate: 5.0000e-04\n",
      "Epoch 77/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.0089 - val_loss: 44.1594 - learning_rate: 5.0000e-04\n",
      "Epoch 78/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.6615 - val_loss: 45.0690 - learning_rate: 5.0000e-04\n",
      "Epoch 79/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.2636 - val_loss: 46.6318 - learning_rate: 5.0000e-04\n",
      "Epoch 80/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.6351 - val_loss: 46.2117 - learning_rate: 5.0000e-04\n",
      "Epoch 81/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.5251 - val_loss: 44.3117 - learning_rate: 5.0000e-04\n",
      "Epoch 82/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.7535 - val_loss: 42.9663 - learning_rate: 5.0000e-04\n",
      "Epoch 83/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.7120 - val_loss: 43.5033 - learning_rate: 5.0000e-04\n",
      "Epoch 84/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.5145 - val_loss: 44.3517 - learning_rate: 5.0000e-04\n",
      "Epoch 85/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.9438 - val_loss: 45.7232 - learning_rate: 5.0000e-04\n",
      "Epoch 86/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.9157 - val_loss: 44.9785 - learning_rate: 5.0000e-04\n",
      "Epoch 87/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.3832 - val_loss: 44.9211 - learning_rate: 5.0000e-04\n",
      "Epoch 88/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.3176 - val_loss: 44.9070 - learning_rate: 5.0000e-04\n",
      "Epoch 89/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.3724 - val_loss: 45.1041 - learning_rate: 5.0000e-04\n",
      "Epoch 90/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.5665 - val_loss: 43.9494 - learning_rate: 5.0000e-04\n",
      "Epoch 91/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.5643 - val_loss: 42.9496 - learning_rate: 5.0000e-04\n",
      "Epoch 92/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.1807 - val_loss: 43.6901 - learning_rate: 5.0000e-04\n",
      "Epoch 93/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.8715 - val_loss: 43.6799 - learning_rate: 5.0000e-04\n",
      "Epoch 94/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.5266 - val_loss: 42.6636 - learning_rate: 5.0000e-04\n",
      "Epoch 95/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.3026 - val_loss: 46.0344 - learning_rate: 5.0000e-04\n",
      "Epoch 96/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.5647 - val_loss: 42.1599 - learning_rate: 5.0000e-04\n",
      "Epoch 97/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.3054 - val_loss: 44.9242 - learning_rate: 5.0000e-04\n",
      "Epoch 98/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.3017 - val_loss: 44.2575 - learning_rate: 5.0000e-04\n",
      "Epoch 99/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.0798 - val_loss: 43.3766 - learning_rate: 5.0000e-04\n",
      "Epoch 100/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.5204 - val_loss: 42.3863 - learning_rate: 5.0000e-04\n",
      "Epoch 101/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.4150 - val_loss: 44.3139 - learning_rate: 5.0000e-04\n",
      "Epoch 102/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.2165 - val_loss: 43.2593 - learning_rate: 5.0000e-04\n",
      "Epoch 103/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.5937 - val_loss: 42.4558 - learning_rate: 5.0000e-04\n",
      "Epoch 104/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.2538 - val_loss: 45.8522 - learning_rate: 5.0000e-04\n",
      "Epoch 105/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.4683 - val_loss: 44.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 106/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.6512 - val_loss: 42.5286 - learning_rate: 5.0000e-04\n",
      "Epoch 107/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.5527 - val_loss: 39.1657 - learning_rate: 2.5000e-04\n",
      "Epoch 108/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.9068 - val_loss: 39.4932 - learning_rate: 2.5000e-04\n",
      "Epoch 109/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.8776 - val_loss: 40.5785 - learning_rate: 2.5000e-04\n",
      "Epoch 110/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.5220 - val_loss: 42.8320 - learning_rate: 2.5000e-04\n",
      "Epoch 111/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.3029 - val_loss: 39.9703 - learning_rate: 2.5000e-04\n",
      "Epoch 112/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.9628 - val_loss: 40.7017 - learning_rate: 2.5000e-04\n",
      "Epoch 113/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.1029 - val_loss: 39.7141 - learning_rate: 2.5000e-04\n",
      "Epoch 114/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.7085 - val_loss: 40.2885 - learning_rate: 2.5000e-04\n",
      "Epoch 115/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.8037 - val_loss: 37.9924 - learning_rate: 2.5000e-04\n",
      "Epoch 116/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.6231 - val_loss: 39.5078 - learning_rate: 2.5000e-04\n",
      "Epoch 117/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.6018 - val_loss: 39.6894 - learning_rate: 2.5000e-04\n",
      "Epoch 118/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.6695 - val_loss: 39.5651 - learning_rate: 2.5000e-04\n",
      "Epoch 119/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.5127 - val_loss: 38.5888 - learning_rate: 2.5000e-04\n",
      "Epoch 120/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.1606 - val_loss: 38.2873 - learning_rate: 2.5000e-04\n",
      "Epoch 121/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.5991 - val_loss: 38.1529 - learning_rate: 2.5000e-04\n",
      "Epoch 122/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.9283 - val_loss: 38.1553 - learning_rate: 2.5000e-04\n",
      "Epoch 123/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.4705 - val_loss: 39.1288 - learning_rate: 2.5000e-04\n",
      "Epoch 124/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.2029 - val_loss: 41.0590 - learning_rate: 2.5000e-04\n",
      "Epoch 125/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.4513 - val_loss: 42.5619 - learning_rate: 2.5000e-04\n",
      "Epoch 126/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.5731 - val_loss: 38.3450 - learning_rate: 1.2500e-04\n",
      "Epoch 127/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1368 - val_loss: 39.3524 - learning_rate: 1.2500e-04\n",
      "Epoch 128/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4248 - val_loss: 37.0945 - learning_rate: 1.2500e-04\n",
      "Epoch 129/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5039 - val_loss: 38.8497 - learning_rate: 1.2500e-04\n",
      "Epoch 130/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6449 - val_loss: 37.2734 - learning_rate: 1.2500e-04\n",
      "Epoch 131/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0695 - val_loss: 38.0029 - learning_rate: 1.2500e-04\n",
      "Epoch 132/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.1713 - val_loss: 37.3393 - learning_rate: 1.2500e-04\n",
      "Epoch 133/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3438 - val_loss: 36.8973 - learning_rate: 1.2500e-04\n",
      "Epoch 134/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.5950 - val_loss: 36.9861 - learning_rate: 1.2500e-04\n",
      "Epoch 135/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4050 - val_loss: 38.1167 - learning_rate: 1.2500e-04\n",
      "Epoch 136/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3423 - val_loss: 37.3700 - learning_rate: 1.2500e-04\n",
      "Epoch 137/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.9784 - val_loss: 37.2627 - learning_rate: 1.2500e-04\n",
      "Epoch 138/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0539 - val_loss: 37.0707 - learning_rate: 1.2500e-04\n",
      "Epoch 139/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2837 - val_loss: 37.3273 - learning_rate: 1.2500e-04\n",
      "Epoch 140/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8896 - val_loss: 37.6905 - learning_rate: 1.2500e-04\n",
      "Epoch 141/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0101 - val_loss: 37.9255 - learning_rate: 1.2500e-04\n",
      "Epoch 142/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5774 - val_loss: 37.4321 - learning_rate: 1.2500e-04\n",
      "Epoch 143/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6812 - val_loss: 37.0759 - learning_rate: 1.2500e-04\n",
      "Epoch 144/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1811 - val_loss: 37.2369 - learning_rate: 6.2500e-05\n",
      "Epoch 145/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2198 - val_loss: 37.1343 - learning_rate: 6.2500e-05\n",
      "Epoch 146/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1312 - val_loss: 36.2104 - learning_rate: 6.2500e-05\n",
      "Epoch 147/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8597 - val_loss: 36.0156 - learning_rate: 6.2500e-05\n",
      "Epoch 148/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4904 - val_loss: 36.4878 - learning_rate: 6.2500e-05\n",
      "Epoch 149/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1603 - val_loss: 36.9462 - learning_rate: 6.2500e-05\n",
      "Epoch 150/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2359 - val_loss: 36.5188 - learning_rate: 6.2500e-05\n",
      "Epoch 151/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6006 - val_loss: 36.9396 - learning_rate: 6.2500e-05\n",
      "Epoch 152/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6985 - val_loss: 36.4260 - learning_rate: 6.2500e-05\n",
      "Epoch 153/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8019 - val_loss: 36.5140 - learning_rate: 6.2500e-05\n",
      "Epoch 154/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.1813 - val_loss: 36.5419 - learning_rate: 6.2500e-05\n",
      "Epoch 155/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1551 - val_loss: 36.2789 - learning_rate: 6.2500e-05\n",
      "Epoch 156/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3177 - val_loss: 36.5851 - learning_rate: 6.2500e-05\n",
      "Epoch 157/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4326 - val_loss: 36.6462 - learning_rate: 6.2500e-05\n",
      "Epoch 158/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4286 - val_loss: 36.0052 - learning_rate: 3.1250e-05\n",
      "Epoch 159/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1976 - val_loss: 35.7262 - learning_rate: 3.1250e-05\n",
      "Epoch 160/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5325 - val_loss: 35.7859 - learning_rate: 3.1250e-05\n",
      "Epoch 161/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0875 - val_loss: 36.1519 - learning_rate: 3.1250e-05\n",
      "Epoch 162/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4252 - val_loss: 35.6034 - learning_rate: 3.1250e-05\n",
      "Epoch 163/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4370 - val_loss: 35.6765 - learning_rate: 3.1250e-05\n",
      "Epoch 164/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7100 - val_loss: 35.9592 - learning_rate: 3.1250e-05\n",
      "Epoch 165/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3537 - val_loss: 35.8276 - learning_rate: 3.1250e-05\n",
      "Epoch 166/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7410 - val_loss: 35.7422 - learning_rate: 3.1250e-05\n",
      "Epoch 167/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5355 - val_loss: 35.8750 - learning_rate: 3.1250e-05\n",
      "Epoch 168/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 63.4564 - val_loss: 36.3198 - learning_rate: 3.1250e-05\n",
      "Epoch 169/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 63.8442 - val_loss: 36.1401 - learning_rate: 3.1250e-05\n",
      "Epoch 170/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 64.2886 - val_loss: 36.0161 - learning_rate: 3.1250e-05\n",
      "Epoch 171/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9345 - val_loss: 36.2227 - learning_rate: 3.1250e-05\n",
      "Epoch 172/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 63.6684 - val_loss: 36.4471 - learning_rate: 3.1250e-05\n",
      "Epoch 173/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 64.0644 - val_loss: 35.7659 - learning_rate: 1.5625e-05\n",
      "Epoch 174/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 63.8224 - val_loss: 35.5276 - learning_rate: 1.5625e-05\n",
      "Epoch 175/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 139ms/step - loss: 63.6650 - val_loss: 35.5668 - learning_rate: 1.5625e-05\n",
      "Epoch 176/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5178 - val_loss: 35.7094 - learning_rate: 1.5625e-05\n",
      "Epoch 177/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7640 - val_loss: 35.9297 - learning_rate: 1.5625e-05\n",
      "Epoch 178/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0063 - val_loss: 35.6944 - learning_rate: 1.5625e-05\n",
      "Epoch 179/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 62.9359 - val_loss: 35.9918 - learning_rate: 1.5625e-05\n",
      "Epoch 180/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5231 - val_loss: 35.3783 - learning_rate: 1.5625e-05\n",
      "Epoch 181/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5228 - val_loss: 35.7503 - learning_rate: 1.5625e-05\n",
      "Epoch 182/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 63.5555 - val_loss: 35.6639 - learning_rate: 1.5625e-05\n",
      "Epoch 183/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0734 - val_loss: 35.8590 - learning_rate: 1.5625e-05\n",
      "Epoch 184/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8601 - val_loss: 35.5583 - learning_rate: 1.5625e-05\n",
      "Epoch 185/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4019 - val_loss: 35.4471 - learning_rate: 1.5625e-05\n",
      "Epoch 186/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0241 - val_loss: 36.1271 - learning_rate: 1.5625e-05\n",
      "Epoch 187/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1875 - val_loss: 35.7281 - learning_rate: 1.5625e-05\n",
      "Epoch 188/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8296 - val_loss: 36.3604 - learning_rate: 1.5625e-05\n",
      "Epoch 189/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 64.1877 - val_loss: 35.1876 - learning_rate: 1.5625e-05\n",
      "Epoch 190/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0176 - val_loss: 35.8828 - learning_rate: 1.5625e-05\n",
      "Epoch 191/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4786 - val_loss: 35.8147 - learning_rate: 1.5625e-05\n",
      "Epoch 192/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0884 - val_loss: 35.9938 - learning_rate: 1.5625e-05\n",
      "Epoch 193/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8802 - val_loss: 35.9963 - learning_rate: 1.5625e-05\n",
      "Epoch 194/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2210 - val_loss: 35.4053 - learning_rate: 1.5625e-05\n",
      "Epoch 195/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5076 - val_loss: 35.8595 - learning_rate: 1.5625e-05\n",
      "Epoch 196/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2589 - val_loss: 35.6730 - learning_rate: 1.5625e-05\n",
      "Epoch 197/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4566 - val_loss: 35.4056 - learning_rate: 1.5625e-05\n",
      "Epoch 198/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3809 - val_loss: 35.1302 - learning_rate: 1.5625e-05\n",
      "Epoch 199/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1025 - val_loss: 35.8465 - learning_rate: 1.5625e-05\n",
      "Epoch 200/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1640 - val_loss: 35.5795 - learning_rate: 1.5625e-05\n",
      "Epoch 201/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1830 - val_loss: 35.8271 - learning_rate: 1.5625e-05\n",
      "Epoch 202/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3281 - val_loss: 35.4650 - learning_rate: 1.5625e-05\n",
      "Epoch 203/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1397 - val_loss: 35.5047 - learning_rate: 1.5625e-05\n",
      "Epoch 204/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3902 - val_loss: 35.5883 - learning_rate: 1.5625e-05\n",
      "Epoch 205/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0724 - val_loss: 35.6553 - learning_rate: 1.5625e-05\n",
      "Epoch 206/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.2084 - val_loss: 35.7344 - learning_rate: 1.5625e-05\n",
      "Epoch 207/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7610 - val_loss: 35.3822 - learning_rate: 1.5625e-05\n",
      "Epoch 208/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5955 - val_loss: 35.4820 - learning_rate: 1.5625e-05\n",
      "Epoch 209/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0156 - val_loss: 35.9032 - learning_rate: 7.8125e-06\n",
      "Epoch 210/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6085 - val_loss: 35.4862 - learning_rate: 7.8125e-06\n",
      "Epoch 211/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2950 - val_loss: 35.4461 - learning_rate: 7.8125e-06\n",
      "Epoch 212/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9161 - val_loss: 35.5009 - learning_rate: 7.8125e-06\n",
      "Epoch 213/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6171 - val_loss: 35.5602 - learning_rate: 7.8125e-06\n",
      "Epoch 214/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2465 - val_loss: 35.3605 - learning_rate: 7.8125e-06\n",
      "Epoch 215/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5257 - val_loss: 35.6891 - learning_rate: 7.8125e-06\n",
      "Epoch 216/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8471 - val_loss: 35.1113 - learning_rate: 7.8125e-06\n",
      "Epoch 217/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6961 - val_loss: 35.8597 - learning_rate: 7.8125e-06\n",
      "Epoch 218/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3483 - val_loss: 35.5177 - learning_rate: 7.8125e-06\n",
      "Epoch 219/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9120 - val_loss: 35.2558 - learning_rate: 7.8125e-06\n",
      "Epoch 220/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6870 - val_loss: 35.3113 - learning_rate: 7.8125e-06\n",
      "Epoch 221/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0257 - val_loss: 35.3600 - learning_rate: 7.8125e-06\n",
      "Epoch 222/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5887 - val_loss: 35.6562 - learning_rate: 7.8125e-06\n",
      "Epoch 223/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8255 - val_loss: 35.3603 - learning_rate: 7.8125e-06\n",
      "Epoch 224/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 63.9949 - val_loss: 35.7398 - learning_rate: 7.8125e-06\n",
      "Epoch 225/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0169 - val_loss: 35.4518 - learning_rate: 7.8125e-06\n",
      "Epoch 226/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8779 - val_loss: 35.5875 - learning_rate: 7.8125e-06\n",
      "Epoch 227/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5829 - val_loss: 35.3795 - learning_rate: 3.9063e-06\n",
      "Epoch 228/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3176 - val_loss: 35.4717 - learning_rate: 3.9063e-06\n",
      "Epoch 229/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0584 - val_loss: 35.3909 - learning_rate: 3.9063e-06\n",
      "Epoch 230/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6112 - val_loss: 35.4514 - learning_rate: 3.9063e-06\n",
      "Epoch 231/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5770 - val_loss: 35.7508 - learning_rate: 3.9063e-06\n",
      "Epoch 232/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4093 - val_loss: 35.3521 - learning_rate: 3.9063e-06\n",
      "Epoch 233/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4729 - val_loss: 35.6106 - learning_rate: 3.9063e-06\n",
      "Epoch 234/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2447 - val_loss: 35.4656 - learning_rate: 3.9063e-06\n",
      "Epoch 235/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7186 - val_loss: 35.0035 - learning_rate: 3.9063e-06\n",
      "Epoch 236/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1515 - val_loss: 35.1550 - learning_rate: 3.9063e-06\n",
      "Epoch 237/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1496 - val_loss: 35.8629 - learning_rate: 3.9063e-06\n",
      "Epoch 238/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6292 - val_loss: 35.4805 - learning_rate: 3.9063e-06\n",
      "Epoch 239/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6661 - val_loss: 35.0475 - learning_rate: 3.9063e-06\n",
      "Epoch 240/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7153 - val_loss: 35.5537 - learning_rate: 3.9063e-06\n",
      "Epoch 241/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4983 - val_loss: 35.3575 - learning_rate: 3.9063e-06\n",
      "Epoch 242/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8489 - val_loss: 35.8995 - learning_rate: 3.9063e-06\n",
      "Epoch 243/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0252 - val_loss: 35.6337 - learning_rate: 3.9063e-06\n",
      "Epoch 244/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0055 - val_loss: 35.4915 - learning_rate: 3.9063e-06\n",
      "Epoch 245/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9342 - val_loss: 35.2719 - learning_rate: 3.9063e-06\n",
      "Epoch 246/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7655 - val_loss: 35.3931 - learning_rate: 1.9531e-06\n",
      "Epoch 247/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3869 - val_loss: 35.1425 - learning_rate: 1.9531e-06\n",
      "Epoch 248/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7685 - val_loss: 35.5771 - learning_rate: 1.9531e-06\n",
      "Epoch 249/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6735 - val_loss: 35.6222 - learning_rate: 1.9531e-06\n",
      "Epoch 250/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4838 - val_loss: 35.4030 - learning_rate: 1.9531e-06\n",
      "Epoch 251/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3156 - val_loss: 35.0556 - learning_rate: 1.9531e-06\n",
      "Epoch 252/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.5334 - val_loss: 35.6855 - learning_rate: 1.9531e-06\n",
      "Epoch 253/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8067 - val_loss: 35.6664 - learning_rate: 1.9531e-06\n",
      "Epoch 254/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7933 - val_loss: 35.2846 - learning_rate: 1.9531e-06\n",
      "Epoch 255/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.6203 - val_loss: 35.5326 - learning_rate: 1.9531e-06\n",
      "Epoch 256/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2772 - val_loss: 35.5373 - learning_rate: 1.0000e-06\n",
      "Epoch 257/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9822 - val_loss: 35.3010 - learning_rate: 1.0000e-06\n",
      "Epoch 258/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1885 - val_loss: 35.5555 - learning_rate: 1.0000e-06\n",
      "Epoch 259/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2818 - val_loss: 35.2015 - learning_rate: 1.0000e-06\n",
      "Epoch 260/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8130 - val_loss: 34.9058 - learning_rate: 1.0000e-06\n",
      "Epoch 261/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9198 - val_loss: 35.8489 - learning_rate: 1.0000e-06\n",
      "Epoch 262/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5230 - val_loss: 35.1507 - learning_rate: 1.0000e-06\n",
      "Epoch 263/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 63.3303 - val_loss: 35.4143 - learning_rate: 1.0000e-06\n",
      "Epoch 264/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9341 - val_loss: 35.3806 - learning_rate: 1.0000e-06\n",
      "Epoch 265/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2686 - val_loss: 35.2287 - learning_rate: 1.0000e-06\n",
      "Epoch 266/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2901 - val_loss: 35.2796 - learning_rate: 1.0000e-06\n",
      "Epoch 267/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1710 - val_loss: 35.3836 - learning_rate: 1.0000e-06\n",
      "Epoch 268/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 62.9607 - val_loss: 35.4146 - learning_rate: 1.0000e-06\n",
      "Epoch 269/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3774 - val_loss: 35.1229 - learning_rate: 1.0000e-06\n",
      "Epoch 270/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5791 - val_loss: 34.9569 - learning_rate: 1.0000e-06\n",
      "Epoch 271/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0731 - val_loss: 35.2850 - learning_rate: 1.0000e-06\n",
      "Epoch 272/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.1338 - val_loss: 35.3788 - learning_rate: 1.0000e-06\n",
      "Epoch 273/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4090 - val_loss: 35.4684 - learning_rate: 1.0000e-06\n",
      "Epoch 274/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8137 - val_loss: 35.5672 - learning_rate: 1.0000e-06\n",
      "Epoch 275/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3669 - val_loss: 35.2613 - learning_rate: 1.0000e-06\n",
      "Epoch 276/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5319 - val_loss: 35.7921 - learning_rate: 1.0000e-06\n",
      "Epoch 277/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.6169 - val_loss: 35.1805 - learning_rate: 1.0000e-06\n",
      "Epoch 278/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0143 - val_loss: 35.3321 - learning_rate: 1.0000e-06\n",
      "Epoch 279/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0380 - val_loss: 35.3728 - learning_rate: 1.0000e-06\n",
      "Epoch 280/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.5573 - val_loss: 35.7598 - learning_rate: 1.0000e-06\n",
      "Epoch 281/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4567 - val_loss: 35.2086 - learning_rate: 1.0000e-06\n",
      "Epoch 282/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6837 - val_loss: 35.2167 - learning_rate: 1.0000e-06\n",
      "Epoch 283/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5706 - val_loss: 35.2310 - learning_rate: 1.0000e-06\n",
      "Epoch 284/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3399 - val_loss: 35.2479 - learning_rate: 1.0000e-06\n",
      "Epoch 285/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3440 - val_loss: 35.1667 - learning_rate: 1.0000e-06\n",
      "Epoch 286/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3307 - val_loss: 34.9162 - learning_rate: 1.0000e-06\n",
      "Epoch 287/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4830 - val_loss: 35.5037 - learning_rate: 1.0000e-06\n",
      "Epoch 288/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5077 - val_loss: 34.8864 - learning_rate: 1.0000e-06\n",
      "Epoch 289/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2529 - val_loss: 35.4686 - learning_rate: 1.0000e-06\n",
      "Epoch 290/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.6004 - val_loss: 35.2483 - learning_rate: 1.0000e-06\n",
      "Epoch 291/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5895 - val_loss: 35.5488 - learning_rate: 1.0000e-06\n",
      "Epoch 292/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1148 - val_loss: 35.2633 - learning_rate: 1.0000e-06\n",
      "Epoch 293/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1425 - val_loss: 35.8073 - learning_rate: 1.0000e-06\n",
      "Epoch 294/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4875 - val_loss: 35.3620 - learning_rate: 1.0000e-06\n",
      "Epoch 295/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4234 - val_loss: 35.2464 - learning_rate: 1.0000e-06\n",
      "Epoch 296/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1847 - val_loss: 35.4199 - learning_rate: 1.0000e-06\n",
      "Epoch 297/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5033 - val_loss: 35.4312 - learning_rate: 1.0000e-06\n",
      "Epoch 298/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1790 - val_loss: 35.1937 - learning_rate: 1.0000e-06\n",
      "Epoch 299/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6272 - val_loss: 35.1556 - learning_rate: 1.0000e-06\n",
      "Epoch 300/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2326 - val_loss: 35.8895 - learning_rate: 1.0000e-06\n",
      "Epoch 301/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6119 - val_loss: 35.3962 - learning_rate: 1.0000e-06\n",
      "Epoch 302/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.4892 - val_loss: 35.4946 - learning_rate: 1.0000e-06\n",
      "Epoch 303/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3638 - val_loss: 35.3183 - learning_rate: 1.0000e-06\n",
      "Epoch 304/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2160 - val_loss: 36.4225 - learning_rate: 1.0000e-06\n",
      "Epoch 305/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4969 - val_loss: 35.4384 - learning_rate: 1.0000e-06\n",
      "Epoch 306/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4719 - val_loss: 35.6729 - learning_rate: 1.0000e-06\n",
      "Epoch 307/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9804 - val_loss: 35.3736 - learning_rate: 1.0000e-06\n",
      "Epoch 308/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2077 - val_loss: 34.9382 - learning_rate: 1.0000e-06\n",
      "Epoch 309/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0632 - val_loss: 35.6212 - learning_rate: 1.0000e-06\n",
      "Epoch 310/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5329 - val_loss: 35.2597 - learning_rate: 1.0000e-06\n",
      "Epoch 311/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.5960 - val_loss: 35.2043 - learning_rate: 1.0000e-06\n",
      "Epoch 312/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3252 - val_loss: 35.3906 - learning_rate: 1.0000e-06\n",
      "Epoch 313/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7923 - val_loss: 35.3880 - learning_rate: 1.0000e-06\n",
      "Epoch 314/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0229 - val_loss: 35.4341 - learning_rate: 1.0000e-06\n",
      "Epoch 315/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0467 - val_loss: 35.4600 - learning_rate: 1.0000e-06\n",
      "Epoch 316/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8854 - val_loss: 35.6198 - learning_rate: 1.0000e-06\n",
      "Epoch 317/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8004 - val_loss: 35.1370 - learning_rate: 1.0000e-06\n",
      "Epoch 318/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6021 - val_loss: 35.7501 - learning_rate: 1.0000e-06\n",
      "Epoch 319/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5445 - val_loss: 35.3494 - learning_rate: 1.0000e-06\n",
      "Epoch 320/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4086 - val_loss: 35.2775 - learning_rate: 1.0000e-06\n",
      "Epoch 321/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7470 - val_loss: 35.0359 - learning_rate: 1.0000e-06\n",
      "Epoch 322/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9676 - val_loss: 35.4340 - learning_rate: 1.0000e-06\n",
      "Epoch 323/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7329 - val_loss: 35.0872 - learning_rate: 1.0000e-06\n",
      "Epoch 324/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1275 - val_loss: 35.4960 - learning_rate: 1.0000e-06\n",
      "Epoch 325/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2434 - val_loss: 35.4293 - learning_rate: 1.0000e-06\n",
      "Epoch 326/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6528 - val_loss: 35.5826 - learning_rate: 1.0000e-06\n",
      "Epoch 327/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1393 - val_loss: 35.3549 - learning_rate: 1.0000e-06\n",
      "Epoch 328/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4907 - val_loss: 35.4313 - learning_rate: 1.0000e-06\n",
      "Epoch 329/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3552 - val_loss: 35.1256 - learning_rate: 1.0000e-06\n",
      "Epoch 330/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4122 - val_loss: 35.5714 - learning_rate: 1.0000e-06\n",
      "Epoch 331/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3787 - val_loss: 35.6151 - learning_rate: 1.0000e-06\n",
      "Epoch 332/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3553 - val_loss: 34.9913 - learning_rate: 1.0000e-06\n",
      "Epoch 333/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2056 - val_loss: 35.3482 - learning_rate: 1.0000e-06\n",
      "Epoch 334/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.6966 - val_loss: 35.6292 - learning_rate: 1.0000e-06\n",
      "Epoch 335/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6254 - val_loss: 35.5309 - learning_rate: 1.0000e-06\n",
      "Epoch 336/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1270 - val_loss: 35.2226 - learning_rate: 1.0000e-06\n",
      "Epoch 337/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7979 - val_loss: 35.2618 - learning_rate: 1.0000e-06\n",
      "Epoch 338/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8038 - val_loss: 35.3681 - learning_rate: 1.0000e-06\n",
      "Epoch 339/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5857 - val_loss: 35.3031 - learning_rate: 1.0000e-06\n",
      "Epoch 340/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0440 - val_loss: 34.9947 - learning_rate: 1.0000e-06\n",
      "Epoch 341/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1718 - val_loss: 35.3814 - learning_rate: 1.0000e-06\n",
      "Epoch 342/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1809 - val_loss: 35.6380 - learning_rate: 1.0000e-06\n",
      "Epoch 343/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9372 - val_loss: 35.3476 - learning_rate: 1.0000e-06\n",
      "Epoch 344/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4024 - val_loss: 35.7154 - learning_rate: 1.0000e-06\n",
      "Epoch 345/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1267 - val_loss: 35.3017 - learning_rate: 1.0000e-06\n",
      "Epoch 346/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4371 - val_loss: 34.7133 - learning_rate: 1.0000e-06\n",
      "Epoch 347/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0053 - val_loss: 35.1489 - learning_rate: 1.0000e-06\n",
      "Epoch 348/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2550 - val_loss: 35.6059 - learning_rate: 1.0000e-06\n",
      "Epoch 349/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8311 - val_loss: 35.7285 - learning_rate: 1.0000e-06\n",
      "Epoch 350/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6423 - val_loss: 35.5419 - learning_rate: 1.0000e-06\n",
      "Epoch 351/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5910 - val_loss: 35.1583 - learning_rate: 1.0000e-06\n",
      "Epoch 352/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1607 - val_loss: 35.2727 - learning_rate: 1.0000e-06\n",
      "Epoch 353/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3925 - val_loss: 35.4846 - learning_rate: 1.0000e-06\n",
      "Epoch 354/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6526 - val_loss: 35.1597 - learning_rate: 1.0000e-06\n",
      "Epoch 355/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7719 - val_loss: 35.2099 - learning_rate: 1.0000e-06\n",
      "Epoch 356/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9583 - val_loss: 35.1671 - learning_rate: 1.0000e-06\n",
      "Epoch 357/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4016 - val_loss: 35.9299 - learning_rate: 1.0000e-06\n",
      "Epoch 358/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9456 - val_loss: 35.7830 - learning_rate: 1.0000e-06\n",
      "Epoch 359/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8766 - val_loss: 35.1554 - learning_rate: 1.0000e-06\n",
      "Epoch 360/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6549 - val_loss: 35.5028 - learning_rate: 1.0000e-06\n",
      "Epoch 361/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8401 - val_loss: 35.4209 - learning_rate: 1.0000e-06\n",
      "Epoch 362/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7131 - val_loss: 34.9492 - learning_rate: 1.0000e-06\n",
      "Epoch 363/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7275 - val_loss: 35.1334 - learning_rate: 1.0000e-06\n",
      "Epoch 364/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2369 - val_loss: 35.2231 - learning_rate: 1.0000e-06\n",
      "Epoch 365/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9740 - val_loss: 35.0906 - learning_rate: 1.0000e-06\n",
      "Epoch 366/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6057 - val_loss: 35.2796 - learning_rate: 1.0000e-06\n",
      "Epoch 367/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3763 - val_loss: 35.5222 - learning_rate: 1.0000e-06\n",
      "Epoch 368/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4392 - val_loss: 35.7500 - learning_rate: 1.0000e-06\n",
      "Epoch 369/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2708 - val_loss: 35.2827 - learning_rate: 1.0000e-06\n",
      "Epoch 370/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1362 - val_loss: 35.6283 - learning_rate: 1.0000e-06\n",
      "Epoch 371/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8516 - val_loss: 35.2405 - learning_rate: 1.0000e-06\n",
      "Epoch 372/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6440 - val_loss: 35.3142 - learning_rate: 1.0000e-06\n",
      "Epoch 373/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8399 - val_loss: 35.1565 - learning_rate: 1.0000e-06\n",
      "Epoch 374/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1926 - val_loss: 35.7763 - learning_rate: 1.0000e-06\n",
      "Epoch 375/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2558 - val_loss: 35.8357 - learning_rate: 1.0000e-06\n",
      "Epoch 376/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5503 - val_loss: 35.7561 - learning_rate: 1.0000e-06\n",
      "Epoch 377/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7609 - val_loss: 35.2749 - learning_rate: 1.0000e-06\n",
      "Epoch 378/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0856 - val_loss: 35.2191 - learning_rate: 1.0000e-06\n",
      "Epoch 379/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5391 - val_loss: 35.2731 - learning_rate: 1.0000e-06\n",
      "Epoch 380/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.5089 - val_loss: 35.2913 - learning_rate: 1.0000e-06\n",
      "Epoch 381/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7580 - val_loss: 35.6322 - learning_rate: 1.0000e-06\n",
      "Epoch 382/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0057 - val_loss: 35.3381 - learning_rate: 1.0000e-06\n",
      "Epoch 383/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 62.8998 - val_loss: 35.1420 - learning_rate: 1.0000e-06\n",
      "Epoch 384/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3824 - val_loss: 35.2673 - learning_rate: 1.0000e-06\n",
      "Epoch 385/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8102 - val_loss: 35.0891 - learning_rate: 1.0000e-06\n",
      "Epoch 386/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5670 - val_loss: 34.9826 - learning_rate: 1.0000e-06\n",
      "Epoch 387/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6487 - val_loss: 35.3655 - learning_rate: 1.0000e-06\n",
      "Epoch 388/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2412 - val_loss: 35.5467 - learning_rate: 1.0000e-06\n",
      "Epoch 389/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7658 - val_loss: 35.4368 - learning_rate: 1.0000e-06\n",
      "Epoch 390/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0261 - val_loss: 35.4403 - learning_rate: 1.0000e-06\n",
      "Epoch 391/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6260 - val_loss: 35.3230 - learning_rate: 1.0000e-06\n",
      "Epoch 392/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5553 - val_loss: 35.5118 - learning_rate: 1.0000e-06\n",
      "Epoch 393/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - loss: 62.6429 - val_loss: 35.6966 - learning_rate: 1.0000e-06\n",
      "Epoch 394/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4859 - val_loss: 35.0203 - learning_rate: 1.0000e-06\n",
      "Epoch 395/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 63.5980 - val_loss: 35.6053 - learning_rate: 1.0000e-06\n",
      "Epoch 396/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0085 - val_loss: 35.6357 - learning_rate: 1.0000e-06\n",
      "Epoch 397/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1184 - val_loss: 35.4687 - learning_rate: 1.0000e-06\n",
      "Epoch 398/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 64.0633 - val_loss: 35.5395 - learning_rate: 1.0000e-06\n",
      "Epoch 399/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2660 - val_loss: 35.0616 - learning_rate: 1.0000e-06\n",
      "Epoch 400/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2500 - val_loss: 35.8755 - learning_rate: 1.0000e-06\n",
      "Epoch 401/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7671 - val_loss: 35.4769 - learning_rate: 1.0000e-06\n",
      "Epoch 402/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.5828 - val_loss: 35.2161 - learning_rate: 1.0000e-06\n",
      "Epoch 403/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8052 - val_loss: 36.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 404/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 64.1584 - val_loss: 35.5173 - learning_rate: 1.0000e-06\n",
      "Epoch 405/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2345 - val_loss: 35.7016 - learning_rate: 1.0000e-06\n",
      "Epoch 406/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8130 - val_loss: 35.4417 - learning_rate: 1.0000e-06\n",
      "Epoch 407/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8900 - val_loss: 34.9260 - learning_rate: 1.0000e-06\n",
      "Epoch 408/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9154 - val_loss: 35.3672 - learning_rate: 1.0000e-06\n",
      "Epoch 409/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1469 - val_loss: 35.4444 - learning_rate: 1.0000e-06\n",
      "Epoch 410/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1152 - val_loss: 35.0577 - learning_rate: 1.0000e-06\n",
      "Epoch 411/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2383 - val_loss: 35.3752 - learning_rate: 1.0000e-06\n",
      "Epoch 412/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7522 - val_loss: 35.1682 - learning_rate: 1.0000e-06\n",
      "Epoch 413/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3550 - val_loss: 35.2533 - learning_rate: 1.0000e-06\n",
      "Epoch 414/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6855 - val_loss: 35.5654 - learning_rate: 1.0000e-06\n",
      "Epoch 415/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3716 - val_loss: 35.0653 - learning_rate: 1.0000e-06\n",
      "Epoch 416/10000\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4531 - val_loss: 35.4283 - learning_rate: 1.0000e-06\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - loss: 34.6745\n",
      "Test Loss: 34.73701095581055\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "istory = model.fit(X_train, y_train, epochs=10000, validation_split=0.15, batch_size=128, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step\n",
      "Predicted Solar Energy Ouput: [951.7403564453125, 75.59417724609375, 424.0429992675781, 106.10009765625, 108.33002471923828, 934.1463012695312, 791.0197143554688, 391.0701599121094, 413.4353332519531, 415.02801513671875, 622.3287963867188, 185.4209747314453, 648.5459594726562, 202.41256713867188, 311.1292419433594, 318.0502014160156, 101.3819580078125, 108.27816772460938, 194.65170288085938, 57.08560562133789]\n",
      "Actual Solar Energy Output: [1033.   51.  448.  104.   96.  983.  792.  420.  445.  382.  605.  171.\n",
      "  655.  167.  289.  325.  108.   89.  237.   34.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "predictions[predictions < 0] = 0\n",
    "flattened_predictions = [0 if (isinstance(pred, np.ndarray) and pred.item() < 0) else (0 if pred < 0 else pred.item() if isinstance(pred, np.ndarray) else pred) for pred in predictions]\n",
    "\n",
    "print(f'Predicted Solar Energy Ouput: {flattened_predictions[:20]}')\n",
    "print(f'Actual Solar Energy Output: {y_test[:20].values}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 32.66408794943614\n",
      "Mean Squared Error (MSE): 2124.4717991271505\n",
      "Root Mean Squared Error (RMSE): 46.09199278754554\n",
      "Percent Error (PERR): 0.08754194581897083\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming predictions and y_test are numpy arrays or pandas series\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "average_y_test = np.mean(y_test)\n",
    "percent_error = mae / average_y_test\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Percent Error (PERR): {percent_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('WindModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
