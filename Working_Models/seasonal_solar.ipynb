{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar ANN - Seasonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 12:41:35.130353: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/lp/l5v0z5894r912dc6qp90m2j00000gn/T/ipykernel_12307/3186583987.py:6: DtypeWarning: Columns (12,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/Users/dltc2020/Documents/Senior-project/Ml/getData/fuelWeatherCombined.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv('../../AutoCombine.csv')     # updated\n",
    "data = data.fillna(0)\n",
    "data['BeginDate'] = pd.to_datetime(data['BeginDate']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest date in the dataset\n",
    "latest_date = data['BeginDate'].max()\n",
    "\n",
    "# Get the month from the latest date\n",
    "latest_month = latest_date.month\n",
    "\n",
    "# Determine the season of the latest date\n",
    "if latest_month in (12, 1, 2):\n",
    "    season_months = [12, 1, 2]  # Winter\n",
    "elif latest_month in (3, 4, 5):\n",
    "    season_months = [3, 4, 5]  # Spring\n",
    "elif latest_month in (6, 7, 8):\n",
    "    season_months = [6, 7, 8]  # Summer\n",
    "else:\n",
    "    season_months = [9, 10, 11]  # Fall\n",
    "\n",
    "# Filter the data to only include months from the same season as the latest date\n",
    "data = data[data['BeginDate'].dt.month.isin(season_months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sum\"] = data[[\"Coal\", \"Hydro\", \"Natural Gas\", \"Nuclear\", \"Oil\", \"Other\", \"Landfill Gas\", \"Refuse\", \"Solar\", \"Wind\", \"Wood\"]].sum(axis=1)\n",
    "data['Previous_Day'] = data['BeginDate'] - pd.Timedelta(days=1)\n",
    "data['Previous_Year'] = data['BeginDate'] - pd.DateOffset(years=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average sum for the latest month (2024-12) is: 11110.603716400854\n",
      "BeginDate\n",
      "2021-12    10884.893254\n",
      "2022-01    12109.617641\n",
      "2022-02    11208.623425\n",
      "2022-12    11345.796365\n",
      "2023-01    11001.740688\n",
      "2023-02    11156.062208\n",
      "2023-12    11000.186551\n",
      "2024-01    11952.686172\n",
      "2024-02    10988.178832\n",
      "2024-12    11431.265306\n",
      "Freq: M, Name: Sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average of 'Sum' for the latest month\n",
    "# Filter the data to include only the rows from the latest month\n",
    "latest_month_data = data[data['BeginDate'].dt.month == latest_month]\n",
    "\n",
    "# Calculate the average of the 'Sum' column for the latest month\n",
    "average_sum_latest_month = latest_month_data['Sum'].mean()\n",
    "print(f\"The average sum for the latest month ({latest_date.strftime('%Y-%m')}) is: {average_sum_latest_month}\")\n",
    "\n",
    "monthly_avg_sum = data.groupby(data['BeginDate'].dt.to_period(\"M\"))['Sum'].mean()\n",
    "# Display the average sum for each month\n",
    "print(monthly_avg_sum)\n",
    "\n",
    "latest_date = data['BeginDate'].max()\n",
    "latest_month_period = latest_date.to_period(\"M\")\n",
    "\n",
    "# Get the average sum for the latest month\n",
    "latest_month_avg_sum = monthly_avg_sum[latest_month_period]\n",
    "\n",
    "# Calculate the scaling factor for each month\n",
    "scaling_factors = latest_month_avg_sum / monthly_avg_sum\n",
    "\n",
    "# Map the scaling factors back to the original dates in the dataframe\n",
    "data['ScalingFactor'] = data['BeginDate'].dt.to_period(\"M\").map(scaling_factors)\n",
    "\n",
    "# Apply the scaling factors to each 'Sum' entry\n",
    "data['AdjustedSum'] = data['Sum'] * data['ScalingFactor']\n",
    "data['AdjustedSolar'] = data['Solar'] * data['ScalingFactor']\n",
    "\n",
    "solar_data = data[['BeginDate', 'AdjustedSolar','Previous_Day','Previous_Year']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_day_Solar(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['AdjustedSolar'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Day']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_two_days_before_Solar(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['AdjustedSolar'].values\n",
    "    \n",
    "    # Calculate two days before\n",
    "    target_date = row['BeginDate'] - pd.Timedelta(days=2)\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_year_Solar(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['AdjustedSolar'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Year']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large computation \n",
    "data['Previous_Year_Solar'] = data.apply(get_previous_year_Solar, axis=1, reference_df=solar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"2021-10-01\").tz_localize(None)\n",
    "usable_data = data[data['BeginDate'] > cutoff_date].copy()\n",
    "solar_data2 = usable_data[['BeginDate', 'Solar','Previous_Day','Previous_Year']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "usable_data['Previous_Day_Solar'] = usable_data.apply(get_previous_day_Solar, axis=1, reference_df=solar_data)\n",
    "usable_data['Previous_2Day_Solar'] = usable_data.apply(get_two_days_before_Solar, axis=1, reference_df=solar_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (57312, 20)\n",
      "Target shape:  (57312,)\n"
     ]
    }
   ],
   "source": [
    "usable_data['Hour_of_Day'] = usable_data['BeginDate'].dt.hour\n",
    "usable_data['Month'] = usable_data['BeginDate'].dt.month\n",
    "usable_data['Year'] = usable_data['BeginDate'].dt.year\n",
    "features = usable_data[['Month','Year','Previous_Year_Solar','Previous_2Day_Solar','AdjustedSum','temp', 'humidity', 'precip', 'uvindex', 'cloudcover', 'solarradiation','Previous_Day_Solar','solarenergy','Hour_of_Day','dew','dew','snow','snowdepth','windspeed','windgust']]\n",
    "\n",
    "# Useless Features , 'winddir',,\n",
    "target = usable_data['Solar']\n",
    "\n",
    "print(\"Features shape: \", features.shape)\n",
    "print('Target shape: ', target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=70, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/usr/local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 58.7694 - val_loss: 54.1848 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49.7658 - val_loss: 44.2873 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.3106 - val_loss: 29.2978 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 29.3149 - val_loss: 22.0593 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.5767 - val_loss: 20.8047 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.8043 - val_loss: 18.3926 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1375 - val_loss: 17.9924 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.3480 - val_loss: 16.7238 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.2760 - val_loss: 16.1355 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.9482 - val_loss: 19.0551 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.7411 - val_loss: 15.8438 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.5110 - val_loss: 16.7661 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.3211 - val_loss: 14.7713 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.4056 - val_loss: 14.6308 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.3481 - val_loss: 14.1760 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.7223 - val_loss: 15.2296 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.3501 - val_loss: 14.0570 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.0996 - val_loss: 14.5948 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.3618 - val_loss: 15.3331 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.1997 - val_loss: 14.5037 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.2826 - val_loss: 13.6545 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.7203 - val_loss: 13.7688 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.8384 - val_loss: 13.8018 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.6188 - val_loss: 13.1289 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.9794 - val_loss: 13.5956 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.9059 - val_loss: 14.0868 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.7847 - val_loss: 12.9553 - learning_rate: 0.0010\n",
      "Epoch 28/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.7055 - val_loss: 12.7148 - learning_rate: 0.0010\n",
      "Epoch 29/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.8590 - val_loss: 14.7847 - learning_rate: 0.0010\n",
      "Epoch 30/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.7630 - val_loss: 13.6460 - learning_rate: 0.0010\n",
      "Epoch 31/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.5286 - val_loss: 13.5354 - learning_rate: 0.0010\n",
      "Epoch 32/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.5475 - val_loss: 12.7382 - learning_rate: 0.0010\n",
      "Epoch 33/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.4716 - val_loss: 12.6204 - learning_rate: 0.0010\n",
      "Epoch 34/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.7803 - val_loss: 13.3471 - learning_rate: 0.0010\n",
      "Epoch 35/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.2472 - val_loss: 13.4951 - learning_rate: 0.0010\n",
      "Epoch 36/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9736 - val_loss: 13.1522 - learning_rate: 0.0010\n",
      "Epoch 37/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.7629 - val_loss: 12.5139 - learning_rate: 0.0010\n",
      "Epoch 38/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.3610 - val_loss: 14.3481 - learning_rate: 0.0010\n",
      "Epoch 39/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.4322 - val_loss: 12.6502 - learning_rate: 0.0010\n",
      "Epoch 40/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0341 - val_loss: 13.4025 - learning_rate: 0.0010\n",
      "Epoch 41/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.5201 - val_loss: 13.0453 - learning_rate: 0.0010\n",
      "Epoch 42/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0602 - val_loss: 15.0315 - learning_rate: 0.0010\n",
      "Epoch 43/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8188 - val_loss: 12.1200 - learning_rate: 0.0010\n",
      "Epoch 44/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9884 - val_loss: 12.2326 - learning_rate: 0.0010\n",
      "Epoch 45/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7431 - val_loss: 13.0426 - learning_rate: 0.0010\n",
      "Epoch 46/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0431 - val_loss: 13.5094 - learning_rate: 0.0010\n",
      "Epoch 47/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6586 - val_loss: 12.0782 - learning_rate: 0.0010\n",
      "Epoch 48/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6775 - val_loss: 12.1661 - learning_rate: 0.0010\n",
      "Epoch 49/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0444 - val_loss: 12.3648 - learning_rate: 0.0010\n",
      "Epoch 50/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.2423 - val_loss: 12.5096 - learning_rate: 0.0010\n",
      "Epoch 51/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0604 - val_loss: 12.4731 - learning_rate: 0.0010\n",
      "Epoch 52/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.1545 - val_loss: 12.5402 - learning_rate: 0.0010\n",
      "Epoch 53/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.3598 - val_loss: 12.8929 - learning_rate: 0.0010\n",
      "Epoch 54/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8095 - val_loss: 12.1105 - learning_rate: 0.0010\n",
      "Epoch 55/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.1426 - val_loss: 11.8230 - learning_rate: 0.0010\n",
      "Epoch 56/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9350 - val_loss: 11.6327 - learning_rate: 0.0010\n",
      "Epoch 57/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.1554 - val_loss: 12.4505 - learning_rate: 0.0010\n",
      "Epoch 58/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8222 - val_loss: 12.4844 - learning_rate: 0.0010\n",
      "Epoch 59/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8826 - val_loss: 12.9023 - learning_rate: 0.0010\n",
      "Epoch 60/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7500 - val_loss: 11.3814 - learning_rate: 0.0010\n",
      "Epoch 61/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0111 - val_loss: 11.5225 - learning_rate: 0.0010\n",
      "Epoch 62/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9456 - val_loss: 11.3564 - learning_rate: 0.0010\n",
      "Epoch 63/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8333 - val_loss: 11.5290 - learning_rate: 0.0010\n",
      "Epoch 64/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9204 - val_loss: 13.2897 - learning_rate: 0.0010\n",
      "Epoch 65/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7096 - val_loss: 11.4464 - learning_rate: 0.0010\n",
      "Epoch 66/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.1135 - val_loss: 11.0611 - learning_rate: 0.0010\n",
      "Epoch 67/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9517 - val_loss: 11.5437 - learning_rate: 0.0010\n",
      "Epoch 68/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8013 - val_loss: 12.2114 - learning_rate: 0.0010\n",
      "Epoch 69/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8490 - val_loss: 11.5184 - learning_rate: 0.0010\n",
      "Epoch 70/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8908 - val_loss: 12.2431 - learning_rate: 0.0010\n",
      "Epoch 71/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.1206 - val_loss: 11.6750 - learning_rate: 0.0010\n",
      "Epoch 72/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8970 - val_loss: 11.8754 - learning_rate: 0.0010\n",
      "Epoch 73/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5211 - val_loss: 12.0029 - learning_rate: 0.0010\n",
      "Epoch 74/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.1816 - val_loss: 11.5870 - learning_rate: 0.0010\n",
      "Epoch 75/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.1331 - val_loss: 12.5179 - learning_rate: 0.0010\n",
      "Epoch 76/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9281 - val_loss: 10.8129 - learning_rate: 0.0010\n",
      "Epoch 77/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7130 - val_loss: 12.5504 - learning_rate: 0.0010\n",
      "Epoch 78/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6448 - val_loss: 11.3942 - learning_rate: 0.0010\n",
      "Epoch 79/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6216 - val_loss: 12.4395 - learning_rate: 0.0010\n",
      "Epoch 80/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.2661 - val_loss: 10.9108 - learning_rate: 0.0010\n",
      "Epoch 81/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3947 - val_loss: 12.3336 - learning_rate: 0.0010\n",
      "Epoch 82/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8733 - val_loss: 12.4939 - learning_rate: 0.0010\n",
      "Epoch 83/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6820 - val_loss: 11.9983 - learning_rate: 0.0010\n",
      "Epoch 84/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7180 - val_loss: 11.7198 - learning_rate: 0.0010\n",
      "Epoch 85/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5275 - val_loss: 12.1616 - learning_rate: 0.0010\n",
      "Epoch 86/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8991 - val_loss: 12.5140 - learning_rate: 0.0010\n",
      "Epoch 87/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.2017 - val_loss: 13.8284 - learning_rate: 5.0000e-04\n",
      "Epoch 88/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0921 - val_loss: 11.9253 - learning_rate: 5.0000e-04\n",
      "Epoch 89/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4883 - val_loss: 10.9114 - learning_rate: 5.0000e-04\n",
      "Epoch 90/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.8316 - val_loss: 10.8605 - learning_rate: 5.0000e-04\n",
      "Epoch 91/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4108 - val_loss: 10.8227 - learning_rate: 5.0000e-04\n",
      "Epoch 92/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9473 - val_loss: 10.6544 - learning_rate: 5.0000e-04\n",
      "Epoch 93/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4765 - val_loss: 10.4375 - learning_rate: 5.0000e-04\n",
      "Epoch 94/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0982 - val_loss: 11.3014 - learning_rate: 5.0000e-04\n",
      "Epoch 95/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6088 - val_loss: 10.9139 - learning_rate: 5.0000e-04\n",
      "Epoch 96/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9482 - val_loss: 11.9438 - learning_rate: 5.0000e-04\n",
      "Epoch 97/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0252 - val_loss: 11.9650 - learning_rate: 5.0000e-04\n",
      "Epoch 98/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6652 - val_loss: 10.5097 - learning_rate: 5.0000e-04\n",
      "Epoch 99/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.1097 - val_loss: 10.3509 - learning_rate: 5.0000e-04\n",
      "Epoch 100/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0318 - val_loss: 11.4402 - learning_rate: 5.0000e-04\n",
      "Epoch 101/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.8843 - val_loss: 10.8637 - learning_rate: 5.0000e-04\n",
      "Epoch 102/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5313 - val_loss: 11.2801 - learning_rate: 5.0000e-04\n",
      "Epoch 103/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3355 - val_loss: 11.4315 - learning_rate: 5.0000e-04\n",
      "Epoch 104/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6401 - val_loss: 11.1810 - learning_rate: 5.0000e-04\n",
      "Epoch 105/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6858 - val_loss: 11.3573 - learning_rate: 5.0000e-04\n",
      "Epoch 106/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0218 - val_loss: 10.0898 - learning_rate: 5.0000e-04\n",
      "Epoch 107/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.1600 - val_loss: 10.2345 - learning_rate: 5.0000e-04\n",
      "Epoch 108/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9398 - val_loss: 10.5622 - learning_rate: 5.0000e-04\n",
      "Epoch 109/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0528 - val_loss: 11.1041 - learning_rate: 5.0000e-04\n",
      "Epoch 110/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0319 - val_loss: 11.5724 - learning_rate: 5.0000e-04\n",
      "Epoch 111/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9300 - val_loss: 10.6651 - learning_rate: 5.0000e-04\n",
      "Epoch 112/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5992 - val_loss: 10.1291 - learning_rate: 5.0000e-04\n",
      "Epoch 113/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7027 - val_loss: 10.2890 - learning_rate: 5.0000e-04\n",
      "Epoch 114/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5607 - val_loss: 10.0164 - learning_rate: 5.0000e-04\n",
      "Epoch 115/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0618 - val_loss: 10.3387 - learning_rate: 5.0000e-04\n",
      "Epoch 116/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7741 - val_loss: 11.0993 - learning_rate: 5.0000e-04\n",
      "Epoch 117/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6859 - val_loss: 10.7444 - learning_rate: 5.0000e-04\n",
      "Epoch 118/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9305 - val_loss: 10.0706 - learning_rate: 5.0000e-04\n",
      "Epoch 119/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.2516 - val_loss: 10.8475 - learning_rate: 5.0000e-04\n",
      "Epoch 120/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.2665 - val_loss: 10.4459 - learning_rate: 5.0000e-04\n",
      "Epoch 121/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7537 - val_loss: 10.1020 - learning_rate: 5.0000e-04\n",
      "Epoch 122/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5842 - val_loss: 10.4746 - learning_rate: 5.0000e-04\n",
      "Epoch 123/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.1627 - val_loss: 11.2525 - learning_rate: 5.0000e-04\n",
      "Epoch 124/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4546 - val_loss: 11.3355 - learning_rate: 5.0000e-04\n",
      "Epoch 125/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7291 - val_loss: 10.5692 - learning_rate: 2.5000e-04\n",
      "Epoch 126/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5698 - val_loss: 10.0531 - learning_rate: 2.5000e-04\n",
      "Epoch 127/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4489 - val_loss: 9.6267 - learning_rate: 2.5000e-04\n",
      "Epoch 128/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.8544 - val_loss: 9.9050 - learning_rate: 2.5000e-04\n",
      "Epoch 129/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9131 - val_loss: 10.2237 - learning_rate: 2.5000e-04\n",
      "Epoch 130/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5991 - val_loss: 9.6444 - learning_rate: 2.5000e-04\n",
      "Epoch 131/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0451 - val_loss: 9.5910 - learning_rate: 2.5000e-04\n",
      "Epoch 132/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6174 - val_loss: 10.1267 - learning_rate: 2.5000e-04\n",
      "Epoch 133/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8586 - val_loss: 10.0558 - learning_rate: 2.5000e-04\n",
      "Epoch 134/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5202 - val_loss: 9.0571 - learning_rate: 2.5000e-04\n",
      "Epoch 135/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0997 - val_loss: 9.6927 - learning_rate: 2.5000e-04\n",
      "Epoch 136/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6459 - val_loss: 9.6911 - learning_rate: 2.5000e-04\n",
      "Epoch 137/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3459 - val_loss: 10.4573 - learning_rate: 2.5000e-04\n",
      "Epoch 138/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9278 - val_loss: 9.3778 - learning_rate: 2.5000e-04\n",
      "Epoch 139/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5427 - val_loss: 9.3237 - learning_rate: 2.5000e-04\n",
      "Epoch 140/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5817 - val_loss: 9.7071 - learning_rate: 2.5000e-04\n",
      "Epoch 141/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8950 - val_loss: 9.3753 - learning_rate: 2.5000e-04\n",
      "Epoch 142/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1351 - val_loss: 9.4609 - learning_rate: 2.5000e-04\n",
      "Epoch 143/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5165 - val_loss: 9.2245 - learning_rate: 2.5000e-04\n",
      "Epoch 144/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5193 - val_loss: 9.4766 - learning_rate: 2.5000e-04\n",
      "Epoch 145/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7631 - val_loss: 9.7359 - learning_rate: 1.2500e-04\n",
      "Epoch 146/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.8061 - val_loss: 9.4762 - learning_rate: 1.2500e-04\n",
      "Epoch 147/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3724 - val_loss: 9.5240 - learning_rate: 1.2500e-04\n",
      "Epoch 148/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6082 - val_loss: 9.4143 - learning_rate: 1.2500e-04\n",
      "Epoch 149/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4131 - val_loss: 9.4751 - learning_rate: 1.2500e-04\n",
      "Epoch 150/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0318 - val_loss: 9.5475 - learning_rate: 1.2500e-04\n",
      "Epoch 151/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9684 - val_loss: 9.2709 - learning_rate: 1.2500e-04\n",
      "Epoch 152/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1807 - val_loss: 9.0597 - learning_rate: 1.2500e-04\n",
      "Epoch 153/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2074 - val_loss: 8.9907 - learning_rate: 1.2500e-04\n",
      "Epoch 154/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1543 - val_loss: 9.7039 - learning_rate: 1.2500e-04\n",
      "Epoch 155/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2203 - val_loss: 9.4130 - learning_rate: 1.2500e-04\n",
      "Epoch 156/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9420 - val_loss: 9.3016 - learning_rate: 1.2500e-04\n",
      "Epoch 157/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6751 - val_loss: 9.1740 - learning_rate: 1.2500e-04\n",
      "Epoch 158/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1018 - val_loss: 9.6137 - learning_rate: 1.2500e-04\n",
      "Epoch 159/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3921 - val_loss: 9.5270 - learning_rate: 1.2500e-04\n",
      "Epoch 160/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2539 - val_loss: 9.1302 - learning_rate: 1.2500e-04\n",
      "Epoch 161/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1307 - val_loss: 9.1761 - learning_rate: 1.2500e-04\n",
      "Epoch 162/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9679 - val_loss: 9.6115 - learning_rate: 1.2500e-04\n",
      "Epoch 163/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5530 - val_loss: 9.3617 - learning_rate: 1.2500e-04\n",
      "Epoch 164/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6367 - val_loss: 8.9764 - learning_rate: 6.2500e-05\n",
      "Epoch 165/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8640 - val_loss: 9.0922 - learning_rate: 6.2500e-05\n",
      "Epoch 166/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2187 - val_loss: 8.9045 - learning_rate: 6.2500e-05\n",
      "Epoch 167/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.1731 - val_loss: 8.7110 - learning_rate: 6.2500e-05\n",
      "Epoch 168/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2189 - val_loss: 8.9944 - learning_rate: 6.2500e-05\n",
      "Epoch 169/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9452 - val_loss: 9.1514 - learning_rate: 6.2500e-05\n",
      "Epoch 170/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8289 - val_loss: 8.9065 - learning_rate: 6.2500e-05\n",
      "Epoch 171/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9358 - val_loss: 8.6867 - learning_rate: 6.2500e-05\n",
      "Epoch 172/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.5120 - val_loss: 9.1460 - learning_rate: 6.2500e-05\n",
      "Epoch 173/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2382 - val_loss: 8.9422 - learning_rate: 6.2500e-05\n",
      "Epoch 174/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9350 - val_loss: 8.9443 - learning_rate: 6.2500e-05\n",
      "Epoch 175/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8104 - val_loss: 9.4857 - learning_rate: 6.2500e-05\n",
      "Epoch 176/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7190 - val_loss: 9.0758 - learning_rate: 6.2500e-05\n",
      "Epoch 177/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1860 - val_loss: 9.2256 - learning_rate: 6.2500e-05\n",
      "Epoch 178/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2345 - val_loss: 8.9839 - learning_rate: 6.2500e-05\n",
      "Epoch 179/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0344 - val_loss: 9.1545 - learning_rate: 6.2500e-05\n",
      "Epoch 180/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3258 - val_loss: 9.0291 - learning_rate: 6.2500e-05\n",
      "Epoch 181/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0038 - val_loss: 9.6146 - learning_rate: 6.2500e-05\n",
      "Epoch 182/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2810 - val_loss: 8.9686 - learning_rate: 3.1250e-05\n",
      "Epoch 183/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9884 - val_loss: 8.9865 - learning_rate: 3.1250e-05\n",
      "Epoch 184/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5332 - val_loss: 9.0034 - learning_rate: 3.1250e-05\n",
      "Epoch 185/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0065 - val_loss: 9.0576 - learning_rate: 3.1250e-05\n",
      "Epoch 186/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9577 - val_loss: 8.9124 - learning_rate: 3.1250e-05\n",
      "Epoch 187/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0785 - val_loss: 8.9015 - learning_rate: 3.1250e-05\n",
      "Epoch 188/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0445 - val_loss: 8.8927 - learning_rate: 3.1250e-05\n",
      "Epoch 189/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8777 - val_loss: 8.8998 - learning_rate: 3.1250e-05\n",
      "Epoch 190/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5696 - val_loss: 9.0072 - learning_rate: 3.1250e-05\n",
      "Epoch 191/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2122 - val_loss: 8.9968 - learning_rate: 3.1250e-05\n",
      "Epoch 192/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.3122 - val_loss: 8.9903 - learning_rate: 1.5625e-05\n",
      "Epoch 193/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1290 - val_loss: 8.8801 - learning_rate: 1.5625e-05\n",
      "Epoch 194/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9239 - val_loss: 8.7670 - learning_rate: 1.5625e-05\n",
      "Epoch 195/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0119 - val_loss: 8.9987 - learning_rate: 1.5625e-05\n",
      "Epoch 196/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3212 - val_loss: 8.8101 - learning_rate: 1.5625e-05\n",
      "Epoch 197/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7955 - val_loss: 9.0436 - learning_rate: 1.5625e-05\n",
      "Epoch 198/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1333 - val_loss: 8.8430 - learning_rate: 1.5625e-05\n",
      "Epoch 199/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9709 - val_loss: 8.9758 - learning_rate: 1.5625e-05\n",
      "Epoch 200/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8433 - val_loss: 8.7955 - learning_rate: 1.5625e-05\n",
      "Epoch 201/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2970 - val_loss: 9.0838 - learning_rate: 1.5625e-05\n",
      "Epoch 202/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1547 - val_loss: 8.8033 - learning_rate: 7.8125e-06\n",
      "Epoch 203/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.4509 - val_loss: 8.7151 - learning_rate: 7.8125e-06\n",
      "Epoch 204/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8186 - val_loss: 9.0405 - learning_rate: 7.8125e-06\n",
      "Epoch 205/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9389 - val_loss: 9.0800 - learning_rate: 7.8125e-06\n",
      "Epoch 206/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9190 - val_loss: 9.0182 - learning_rate: 7.8125e-06\n",
      "Epoch 207/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9262 - val_loss: 8.9903 - learning_rate: 7.8125e-06\n",
      "Epoch 208/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0167 - val_loss: 8.8666 - learning_rate: 7.8125e-06\n",
      "Epoch 209/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1867 - val_loss: 8.8124 - learning_rate: 7.8125e-06\n",
      "Epoch 210/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7545 - val_loss: 8.9074 - learning_rate: 7.8125e-06\n",
      "Epoch 211/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7952 - val_loss: 9.0351 - learning_rate: 7.8125e-06\n",
      "Epoch 212/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9998 - val_loss: 8.8963 - learning_rate: 3.9063e-06\n",
      "Epoch 213/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8632 - val_loss: 8.7779 - learning_rate: 3.9063e-06\n",
      "Epoch 214/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3392 - val_loss: 8.8846 - learning_rate: 3.9063e-06\n",
      "Epoch 215/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9511 - val_loss: 8.8434 - learning_rate: 3.9063e-06\n",
      "Epoch 216/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5453 - val_loss: 8.7954 - learning_rate: 3.9063e-06\n",
      "Epoch 217/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9348 - val_loss: 8.8790 - learning_rate: 3.9063e-06\n",
      "Epoch 218/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.5871 - val_loss: 8.8290 - learning_rate: 3.9063e-06\n",
      "Epoch 219/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1519 - val_loss: 8.7817 - learning_rate: 3.9063e-06\n",
      "Epoch 220/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7166 - val_loss: 9.1229 - learning_rate: 3.9063e-06\n",
      "Epoch 221/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9586 - val_loss: 8.9035 - learning_rate: 3.9063e-06\n",
      "Epoch 222/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1970 - val_loss: 8.8730 - learning_rate: 1.9531e-06\n",
      "Epoch 223/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4143 - val_loss: 8.7524 - learning_rate: 1.9531e-06\n",
      "Epoch 224/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1000 - val_loss: 8.7397 - learning_rate: 1.9531e-06\n",
      "Epoch 225/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2393 - val_loss: 8.6896 - learning_rate: 1.9531e-06\n",
      "Epoch 226/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0341 - val_loss: 8.8903 - learning_rate: 1.9531e-06\n",
      "Epoch 227/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1443 - val_loss: 8.8016 - learning_rate: 1.9531e-06\n",
      "Epoch 228/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8196 - val_loss: 8.6797 - learning_rate: 1.9531e-06\n",
      "Epoch 229/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6345 - val_loss: 8.7747 - learning_rate: 1.9531e-06\n",
      "Epoch 230/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1826 - val_loss: 8.8666 - learning_rate: 1.9531e-06\n",
      "Epoch 231/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7510 - val_loss: 8.7964 - learning_rate: 1.9531e-06\n",
      "Epoch 232/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3676 - val_loss: 8.8383 - learning_rate: 1.9531e-06\n",
      "Epoch 233/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7955 - val_loss: 8.9482 - learning_rate: 1.9531e-06\n",
      "Epoch 234/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0939 - val_loss: 8.7568 - learning_rate: 1.9531e-06\n",
      "Epoch 235/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3216 - val_loss: 8.8833 - learning_rate: 1.9531e-06\n",
      "Epoch 236/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2404 - val_loss: 8.9714 - learning_rate: 1.9531e-06\n",
      "Epoch 237/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9194 - val_loss: 8.8782 - learning_rate: 1.9531e-06\n",
      "Epoch 238/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8631 - val_loss: 8.9247 - learning_rate: 1.9531e-06\n",
      "Epoch 239/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6045 - val_loss: 8.7572 - learning_rate: 1.0000e-06\n",
      "Epoch 240/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2293 - val_loss: 9.0137 - learning_rate: 1.0000e-06\n",
      "Epoch 241/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8499 - val_loss: 8.8120 - learning_rate: 1.0000e-06\n",
      "Epoch 242/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4041 - val_loss: 8.8500 - learning_rate: 1.0000e-06\n",
      "Epoch 243/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1533 - val_loss: 8.8517 - learning_rate: 1.0000e-06\n",
      "Epoch 244/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0647 - val_loss: 8.7704 - learning_rate: 1.0000e-06\n",
      "Epoch 245/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2980 - val_loss: 8.8851 - learning_rate: 1.0000e-06\n",
      "Epoch 246/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9662 - val_loss: 9.0180 - learning_rate: 1.0000e-06\n",
      "Epoch 247/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2884 - val_loss: 8.7091 - learning_rate: 1.0000e-06\n",
      "Epoch 248/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1522 - val_loss: 9.0474 - learning_rate: 1.0000e-06\n",
      "Epoch 249/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6462 - val_loss: 8.9030 - learning_rate: 1.0000e-06\n",
      "Epoch 250/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7771 - val_loss: 8.8081 - learning_rate: 1.0000e-06\n",
      "Epoch 251/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0250 - val_loss: 8.8954 - learning_rate: 1.0000e-06\n",
      "Epoch 252/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7505 - val_loss: 8.8780 - learning_rate: 1.0000e-06\n",
      "Epoch 253/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3219 - val_loss: 8.8008 - learning_rate: 1.0000e-06\n",
      "Epoch 254/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9490 - val_loss: 8.8471 - learning_rate: 1.0000e-06\n",
      "Epoch 255/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1164 - val_loss: 9.0251 - learning_rate: 1.0000e-06\n",
      "Epoch 256/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.4463 - val_loss: 8.7992 - learning_rate: 1.0000e-06\n",
      "Epoch 257/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0202 - val_loss: 9.0268 - learning_rate: 1.0000e-06\n",
      "Epoch 258/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0142 - val_loss: 8.8109 - learning_rate: 1.0000e-06\n",
      "Epoch 259/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6557 - val_loss: 8.7460 - learning_rate: 1.0000e-06\n",
      "Epoch 260/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3906 - val_loss: 8.9125 - learning_rate: 1.0000e-06\n",
      "Epoch 261/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6592 - val_loss: 8.8844 - learning_rate: 1.0000e-06\n",
      "Epoch 262/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3847 - val_loss: 8.8227 - learning_rate: 1.0000e-06\n",
      "Epoch 263/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2414 - val_loss: 8.7874 - learning_rate: 1.0000e-06\n",
      "Epoch 264/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3328 - val_loss: 8.8608 - learning_rate: 1.0000e-06\n",
      "Epoch 265/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1028 - val_loss: 8.8400 - learning_rate: 1.0000e-06\n",
      "Epoch 266/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3557 - val_loss: 8.9061 - learning_rate: 1.0000e-06\n",
      "Epoch 267/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6442 - val_loss: 8.7433 - learning_rate: 1.0000e-06\n",
      "Epoch 268/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9302 - val_loss: 8.6399 - learning_rate: 1.0000e-06\n",
      "Epoch 269/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3543 - val_loss: 8.8498 - learning_rate: 1.0000e-06\n",
      "Epoch 270/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3799 - val_loss: 8.8642 - learning_rate: 1.0000e-06\n",
      "Epoch 271/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7369 - val_loss: 8.7938 - learning_rate: 1.0000e-06\n",
      "Epoch 272/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6408 - val_loss: 8.9507 - learning_rate: 1.0000e-06\n",
      "Epoch 273/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0604 - val_loss: 8.7082 - learning_rate: 1.0000e-06\n",
      "Epoch 274/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9875 - val_loss: 9.0496 - learning_rate: 1.0000e-06\n",
      "Epoch 275/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9637 - val_loss: 8.8174 - learning_rate: 1.0000e-06\n",
      "Epoch 276/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.5052 - val_loss: 8.9547 - learning_rate: 1.0000e-06\n",
      "Epoch 277/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2215 - val_loss: 8.8329 - learning_rate: 1.0000e-06\n",
      "Epoch 278/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2780 - val_loss: 8.7505 - learning_rate: 1.0000e-06\n",
      "Epoch 279/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0512 - val_loss: 9.1571 - learning_rate: 1.0000e-06\n",
      "Epoch 280/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1047 - val_loss: 8.8089 - learning_rate: 1.0000e-06\n",
      "Epoch 281/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9511 - val_loss: 8.7378 - learning_rate: 1.0000e-06\n",
      "Epoch 282/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7777 - val_loss: 8.8073 - learning_rate: 1.0000e-06\n",
      "Epoch 283/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0288 - val_loss: 8.8500 - learning_rate: 1.0000e-06\n",
      "Epoch 284/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9187 - val_loss: 8.9020 - learning_rate: 1.0000e-06\n",
      "Epoch 285/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0854 - val_loss: 9.0002 - learning_rate: 1.0000e-06\n",
      "Epoch 286/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0710 - val_loss: 8.8537 - learning_rate: 1.0000e-06\n",
      "Epoch 287/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6773 - val_loss: 8.7404 - learning_rate: 1.0000e-06\n",
      "Epoch 288/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4495 - val_loss: 8.8816 - learning_rate: 1.0000e-06\n",
      "Epoch 289/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.8220 - val_loss: 8.9064 - learning_rate: 1.0000e-06\n",
      "Epoch 290/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8276 - val_loss: 8.9258 - learning_rate: 1.0000e-06\n",
      "Epoch 291/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7550 - val_loss: 8.8208 - learning_rate: 1.0000e-06\n",
      "Epoch 292/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0905 - val_loss: 8.9775 - learning_rate: 1.0000e-06\n",
      "Epoch 293/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5998 - val_loss: 8.7980 - learning_rate: 1.0000e-06\n",
      "Epoch 294/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3910 - val_loss: 8.6903 - learning_rate: 1.0000e-06\n",
      "Epoch 295/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9887 - val_loss: 8.7720 - learning_rate: 1.0000e-06\n",
      "Epoch 296/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3241 - val_loss: 8.9167 - learning_rate: 1.0000e-06\n",
      "Epoch 297/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9986 - val_loss: 8.8442 - learning_rate: 1.0000e-06\n",
      "Epoch 298/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7552 - val_loss: 8.8460 - learning_rate: 1.0000e-06\n",
      "Epoch 299/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9229 - val_loss: 8.9569 - learning_rate: 1.0000e-06\n",
      "Epoch 300/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7407 - val_loss: 8.8365 - learning_rate: 1.0000e-06\n",
      "Epoch 301/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.6031 - val_loss: 8.7317 - learning_rate: 1.0000e-06\n",
      "Epoch 302/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2235 - val_loss: 8.8414 - learning_rate: 1.0000e-06\n",
      "Epoch 303/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2793 - val_loss: 8.7728 - learning_rate: 1.0000e-06\n",
      "Epoch 304/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3349 - val_loss: 8.7377 - learning_rate: 1.0000e-06\n",
      "Epoch 305/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9909 - val_loss: 8.9791 - learning_rate: 1.0000e-06\n",
      "Epoch 306/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3001 - val_loss: 8.8328 - learning_rate: 1.0000e-06\n",
      "Epoch 307/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3966 - val_loss: 8.7914 - learning_rate: 1.0000e-06\n",
      "Epoch 308/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2210 - val_loss: 8.6664 - learning_rate: 1.0000e-06\n",
      "Epoch 309/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8396 - val_loss: 8.8799 - learning_rate: 1.0000e-06\n",
      "Epoch 310/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4285 - val_loss: 8.8312 - learning_rate: 1.0000e-06\n",
      "Epoch 311/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1477 - val_loss: 8.7245 - learning_rate: 1.0000e-06\n",
      "Epoch 312/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1723 - val_loss: 8.7675 - learning_rate: 1.0000e-06\n",
      "Epoch 313/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8280 - val_loss: 8.9497 - learning_rate: 1.0000e-06\n",
      "Epoch 314/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8804 - val_loss: 8.9394 - learning_rate: 1.0000e-06\n",
      "Epoch 315/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1489 - val_loss: 8.7985 - learning_rate: 1.0000e-06\n",
      "Epoch 316/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0665 - val_loss: 8.7742 - learning_rate: 1.0000e-06\n",
      "Epoch 317/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9697 - val_loss: 8.8589 - learning_rate: 1.0000e-06\n",
      "Epoch 318/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.5355 - val_loss: 8.9482 - learning_rate: 1.0000e-06\n",
      "Epoch 319/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2148 - val_loss: 8.8542 - learning_rate: 1.0000e-06\n",
      "Epoch 320/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5732 - val_loss: 8.8039 - learning_rate: 1.0000e-06\n",
      "Epoch 321/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2034 - val_loss: 8.8560 - learning_rate: 1.0000e-06\n",
      "Epoch 322/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7555 - val_loss: 8.8646 - learning_rate: 1.0000e-06\n",
      "Epoch 323/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4894 - val_loss: 8.8325 - learning_rate: 1.0000e-06\n",
      "Epoch 324/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7652 - val_loss: 8.9583 - learning_rate: 1.0000e-06\n",
      "Epoch 325/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6768 - val_loss: 8.9810 - learning_rate: 1.0000e-06\n",
      "Epoch 326/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9200 - val_loss: 8.7376 - learning_rate: 1.0000e-06\n",
      "Epoch 327/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9251 - val_loss: 8.8314 - learning_rate: 1.0000e-06\n",
      "Epoch 328/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.9594 - val_loss: 8.7065 - learning_rate: 1.0000e-06\n",
      "Epoch 329/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0647 - val_loss: 8.8172 - learning_rate: 1.0000e-06\n",
      "Epoch 330/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1040 - val_loss: 8.8385 - learning_rate: 1.0000e-06\n",
      "Epoch 331/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0254 - val_loss: 8.6796 - learning_rate: 1.0000e-06\n",
      "Epoch 332/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2997 - val_loss: 8.7570 - learning_rate: 1.0000e-06\n",
      "Epoch 333/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1470 - val_loss: 8.8165 - learning_rate: 1.0000e-06\n",
      "Epoch 334/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0356 - val_loss: 8.8075 - learning_rate: 1.0000e-06\n",
      "Epoch 335/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7499 - val_loss: 8.9347 - learning_rate: 1.0000e-06\n",
      "Epoch 336/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8578 - val_loss: 8.7425 - learning_rate: 1.0000e-06\n",
      "Epoch 337/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.0219 - val_loss: 8.8577 - learning_rate: 1.0000e-06\n",
      "Epoch 338/500\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.7626 - val_loss: 8.8755 - learning_rate: 1.0000e-06\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 8.7449\n",
      "Test Loss: 8.7421875\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, validation_split=0.2, batch_size=128, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n",
      "Predicted Solar Energy Ouput: [3.8727269172668457, 509.99395751953125, 2.047168731689453, 4.955155849456787, 0.7242593765258789, 1.3204565048217773, 198.98492431640625, 35.93510055541992, 15.786930084228516, 0.0, 1.7536331415176392, 120.72695922851562, 31.975669860839844, 4.231215000152588, 338.49359130859375, 22.975399017333984, 128.468505859375, 25.191295623779297, 277.7015686035156, 1.242236852645874]\n",
      "Actual Solar Energy Output: [  2. 514.  10.   5.   0.   0. 208.  56.  10.   0.   0. 127.  23.   4.\n",
      " 350.   5.  88.  30. 361.   1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "predictions[predictions < 0] = 0\n",
    "flattened_predictions = [0 if (isinstance(pred, np.ndarray) and pred.item() < 0) else (0 if pred < 0 else pred.item() if isinstance(pred, np.ndarray) else pred) for pred in predictions]\n",
    "\n",
    "print(f'Predicted Solar Energy Ouput: {flattened_predictions[:20]}')\n",
    "print(f'Actual Solar Energy Output: {y_test[:20].values}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.34362558987891\n",
      "Mean Squared Error (MSE): 384.34769594339207\n",
      "Root Mean Squared Error (RMSE): 19.604787577104528\n",
      "Percent Error (PERR): 0.14335408755775345\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming predictions and y_test are numpy arrays or pandas series\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "average_y_test = np.mean(y_test)\n",
    "percent_error = mae / average_y_test\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Percent Error (PERR): {percent_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('SolarModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
