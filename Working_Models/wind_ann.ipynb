{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/l5v0z5894r912dc6qp90m2j00000gn/T/ipykernel_6232/4057516515.py:6: DtypeWarning: Columns (12,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/Users/dltc2020/Documents/Senior-project/Ml/getData/fuelWeatherCombined.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv('/Users/dltc2020/Documents/Senior-project/Ml/getData/fuelWeatherCombined.csv')\n",
    "data = data.fillna(0)\n",
    "data['BeginDate'] = pd.to_datetime(data['BeginDate']).dt.tz_localize(None)\n",
    "data[\"Sum\"] = data[[\"Coal\", \"Hydro\", \"Natural Gas\", \"Nuclear\", \"Oil\", \"Other\", \"Landfill Gas\", \"Refuse\", \"Solar\", \"Wind\", \"Wood\"]].sum(axis=1)\n",
    "data['Previous_Day'] = data['BeginDate'] - pd.Timedelta(days=1)\n",
    "data['Previous_2Day'] = data['BeginDate'] - pd.Timedelta(days=2)\n",
    "data['Previous_Year'] = data['BeginDate'] - pd.DateOffset(years=1)\n",
    "wind_data = data[['BeginDate', 'Wind','Previous_Day','Previous_Year','Previous_2Day']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_day_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Wind'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Day']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_two_days_before_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Wind'].values\n",
    "    \n",
    "    # Calculate two days before\n",
    "    target_date = row['BeginDate'] - pd.Timedelta(days=2)\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def get_previous_year_Wind(row, reference_df):\n",
    "    # Sort reference_df by 'BeginDate' for fast lookups\n",
    "    sorted_dates = reference_df['BeginDate'].values\n",
    "    solar_values = reference_df['Wind'].values\n",
    "    \n",
    "    # Perform binary search to find the index of the closest date\n",
    "    target_date = row['Previous_Year']\n",
    "    pos = bisect_left(sorted_dates, target_date)\n",
    "    \n",
    "    # Find the closest date and return corresponding Solar value\n",
    "    if pos == 0:\n",
    "        return solar_values[0]\n",
    "    if pos == len(sorted_dates):\n",
    "        return solar_values[-1]\n",
    "    \n",
    "    before = sorted_dates[pos - 1]\n",
    "    after = sorted_dates[pos]\n",
    "    \n",
    "    # Return the Solar value corresponding to the closest date\n",
    "    if abs(target_date - before) <= abs(target_date - after):\n",
    "        return solar_values[pos - 1]\n",
    "    else:\n",
    "        return solar_values[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large computation \n",
    "data['Previous_Year_Wind'] = data.apply(get_previous_year_Wind, axis=1, reference_df=wind_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"2023-12-01\").tz_localize(None)\n",
    "usable_data = data[data['BeginDate'] > cutoff_date].copy()\n",
    "solar_data2 = usable_data[['BeginDate', 'Wind','Previous_Day','Previous_2Day','Previous_Year']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "usable_data['Previous_Day_Wind'] = usable_data.apply(get_previous_day_Wind, axis=1, reference_df=solar_data2)\n",
    "usable_data['Previous_2Day_Wind'] = usable_data.apply(get_two_days_before_Wind, axis=1, reference_df=solar_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (87965, 22)\n",
      "Target shape:  (87965,)\n"
     ]
    }
   ],
   "source": [
    "usable_data['Hour_of_Day'] = usable_data['BeginDate'].dt.hour\n",
    "usable_data['Month'] = usable_data['BeginDate'].dt.month\n",
    "usable_data['Year'] = usable_data['BeginDate'].dt.year\n",
    "usable_data['WindSpeedCubed'] = usable_data['windspeed'] ** 3\n",
    "features = usable_data[['WindSpeedCubed','Month','Year','Previous_Year_Wind','Previous_2Day_Wind','Sum','snowdepth','temp','solarenergy','sealevelpressure', 'humidity','solarenergy','snow', 'precip', 'uvindex', 'cloudcover', 'Previous_Day_Wind','Hour_of_Day','dew','windgust','windspeed','winddir']]\n",
    "\n",
    "# Useless Features , ,\n",
    "target = usable_data['Wind']\n",
    "\n",
    "print(\"Features shape: \", features.shape)\n",
    "print('Target shape: ', target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=70, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/usr/local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 389.6194 - val_loss: 369.5273 - learning_rate: 0.0010\n",
      "Epoch 2/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.7372 - val_loss: 314.0874 - learning_rate: 0.0010\n",
      "Epoch 3/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 301.9385 - val_loss: 246.9019 - learning_rate: 0.0010\n",
      "Epoch 4/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 228.9501 - val_loss: 167.3081 - learning_rate: 0.0010\n",
      "Epoch 5/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162.8644 - val_loss: 115.1978 - learning_rate: 0.0010\n",
      "Epoch 6/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.8505 - val_loss: 101.7205 - learning_rate: 0.0010\n",
      "Epoch 7/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.6584 - val_loss: 87.6205 - learning_rate: 0.0010\n",
      "Epoch 8/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.6569 - val_loss: 82.5310 - learning_rate: 0.0010\n",
      "Epoch 9/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.7855 - val_loss: 79.8241 - learning_rate: 0.0010\n",
      "Epoch 10/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.3004 - val_loss: 82.7142 - learning_rate: 0.0010\n",
      "Epoch 11/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.8646 - val_loss: 73.7631 - learning_rate: 0.0010\n",
      "Epoch 12/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89.7177 - val_loss: 71.1839 - learning_rate: 0.0010\n",
      "Epoch 13/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88.7418 - val_loss: 68.6564 - learning_rate: 0.0010\n",
      "Epoch 14/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86.4323 - val_loss: 71.5539 - learning_rate: 0.0010\n",
      "Epoch 15/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84.4765 - val_loss: 71.1896 - learning_rate: 0.0010\n",
      "Epoch 16/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85.1368 - val_loss: 64.2121 - learning_rate: 0.0010\n",
      "Epoch 17/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83.4541 - val_loss: 64.8617 - learning_rate: 0.0010\n",
      "Epoch 18/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83.3395 - val_loss: 61.7848 - learning_rate: 0.0010\n",
      "Epoch 19/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 82.0570 - val_loss: 61.6848 - learning_rate: 0.0010\n",
      "Epoch 20/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81.9310 - val_loss: 63.2684 - learning_rate: 0.0010\n",
      "Epoch 21/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81.1893 - val_loss: 62.3653 - learning_rate: 0.0010\n",
      "Epoch 22/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80.8799 - val_loss: 58.8564 - learning_rate: 0.0010\n",
      "Epoch 23/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79.7284 - val_loss: 59.9131 - learning_rate: 0.0010\n",
      "Epoch 24/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 80.0698 - val_loss: 58.5541 - learning_rate: 0.0010\n",
      "Epoch 25/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 79.3481 - val_loss: 56.8408 - learning_rate: 0.0010\n",
      "Epoch 26/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.2339 - val_loss: 58.3246 - learning_rate: 0.0010\n",
      "Epoch 27/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.5974 - val_loss: 56.4115 - learning_rate: 0.0010\n",
      "Epoch 28/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.8443 - val_loss: 55.6470 - learning_rate: 0.0010\n",
      "Epoch 29/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.7079 - val_loss: 59.4669 - learning_rate: 0.0010\n",
      "Epoch 30/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.7894 - val_loss: 55.1490 - learning_rate: 0.0010\n",
      "Epoch 31/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.2271 - val_loss: 55.9702 - learning_rate: 0.0010\n",
      "Epoch 32/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77.5162 - val_loss: 54.4984 - learning_rate: 0.0010\n",
      "Epoch 33/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.5978 - val_loss: 55.4574 - learning_rate: 0.0010\n",
      "Epoch 34/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.6524 - val_loss: 53.3108 - learning_rate: 0.0010\n",
      "Epoch 35/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.5600 - val_loss: 58.7122 - learning_rate: 0.0010\n",
      "Epoch 36/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.2223 - val_loss: 54.9472 - learning_rate: 0.0010\n",
      "Epoch 37/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.5928 - val_loss: 54.3933 - learning_rate: 0.0010\n",
      "Epoch 38/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.3369 - val_loss: 54.9193 - learning_rate: 0.0010\n",
      "Epoch 39/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.8175 - val_loss: 57.0124 - learning_rate: 0.0010\n",
      "Epoch 40/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.0043 - val_loss: 55.8207 - learning_rate: 0.0010\n",
      "Epoch 41/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.2917 - val_loss: 57.0030 - learning_rate: 0.0010\n",
      "Epoch 42/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.3347 - val_loss: 55.5246 - learning_rate: 0.0010\n",
      "Epoch 43/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.1061 - val_loss: 54.1934 - learning_rate: 0.0010\n",
      "Epoch 44/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 74.9501 - val_loss: 54.5694 - learning_rate: 0.0010\n",
      "Epoch 45/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.5698 - val_loss: 45.9517 - learning_rate: 5.0000e-04\n",
      "Epoch 46/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71.3194 - val_loss: 47.5115 - learning_rate: 5.0000e-04\n",
      "Epoch 47/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71.7113 - val_loss: 46.4645 - learning_rate: 5.0000e-04\n",
      "Epoch 48/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71.2793 - val_loss: 44.9860 - learning_rate: 5.0000e-04\n",
      "Epoch 49/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.9024 - val_loss: 45.6999 - learning_rate: 5.0000e-04\n",
      "Epoch 50/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.6857 - val_loss: 45.5516 - learning_rate: 5.0000e-04\n",
      "Epoch 51/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.1383 - val_loss: 46.7820 - learning_rate: 5.0000e-04\n",
      "Epoch 52/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.7619 - val_loss: 47.1753 - learning_rate: 5.0000e-04\n",
      "Epoch 53/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.5124 - val_loss: 47.0674 - learning_rate: 5.0000e-04\n",
      "Epoch 54/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.5488 - val_loss: 46.2356 - learning_rate: 5.0000e-04\n",
      "Epoch 55/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71.3893 - val_loss: 44.7854 - learning_rate: 5.0000e-04\n",
      "Epoch 56/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.9682 - val_loss: 46.3796 - learning_rate: 5.0000e-04\n",
      "Epoch 57/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.4764 - val_loss: 45.8367 - learning_rate: 5.0000e-04\n",
      "Epoch 58/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.7919 - val_loss: 45.0551 - learning_rate: 5.0000e-04\n",
      "Epoch 59/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 71.2261 - val_loss: 47.9776 - learning_rate: 5.0000e-04\n",
      "Epoch 60/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.9598 - val_loss: 48.7989 - learning_rate: 5.0000e-04\n",
      "Epoch 61/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.8732 - val_loss: 44.9174 - learning_rate: 5.0000e-04\n",
      "Epoch 62/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.3704 - val_loss: 45.2780 - learning_rate: 5.0000e-04\n",
      "Epoch 63/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.7181 - val_loss: 48.0659 - learning_rate: 5.0000e-04\n",
      "Epoch 64/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.7038 - val_loss: 43.9194 - learning_rate: 5.0000e-04\n",
      "Epoch 65/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.4674 - val_loss: 43.2619 - learning_rate: 5.0000e-04\n",
      "Epoch 66/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.1393 - val_loss: 43.8350 - learning_rate: 5.0000e-04\n",
      "Epoch 67/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.2772 - val_loss: 43.1852 - learning_rate: 5.0000e-04\n",
      "Epoch 68/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.8895 - val_loss: 44.6435 - learning_rate: 5.0000e-04\n",
      "Epoch 69/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.4247 - val_loss: 43.6930 - learning_rate: 5.0000e-04\n",
      "Epoch 70/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.1961 - val_loss: 43.8983 - learning_rate: 5.0000e-04\n",
      "Epoch 71/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.3714 - val_loss: 44.2655 - learning_rate: 5.0000e-04\n",
      "Epoch 72/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.3724 - val_loss: 44.1389 - learning_rate: 5.0000e-04\n",
      "Epoch 73/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.2088 - val_loss: 46.2509 - learning_rate: 5.0000e-04\n",
      "Epoch 74/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.3136 - val_loss: 44.3410 - learning_rate: 5.0000e-04\n",
      "Epoch 75/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.8591 - val_loss: 45.4258 - learning_rate: 5.0000e-04\n",
      "Epoch 76/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.3429 - val_loss: 45.6259 - learning_rate: 5.0000e-04\n",
      "Epoch 77/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.7574 - val_loss: 44.0909 - learning_rate: 5.0000e-04\n",
      "Epoch 78/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.9750 - val_loss: 41.2745 - learning_rate: 2.5000e-04\n",
      "Epoch 79/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.3820 - val_loss: 44.9661 - learning_rate: 2.5000e-04\n",
      "Epoch 80/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.3158 - val_loss: 40.3801 - learning_rate: 2.5000e-04\n",
      "Epoch 81/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.8464 - val_loss: 40.4649 - learning_rate: 2.5000e-04\n",
      "Epoch 82/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.8091 - val_loss: 42.5468 - learning_rate: 2.5000e-04\n",
      "Epoch 83/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.1087 - val_loss: 40.1182 - learning_rate: 2.5000e-04\n",
      "Epoch 84/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.6565 - val_loss: 40.8973 - learning_rate: 2.5000e-04\n",
      "Epoch 85/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.5879 - val_loss: 41.3077 - learning_rate: 2.5000e-04\n",
      "Epoch 86/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.4109 - val_loss: 44.3992 - learning_rate: 2.5000e-04\n",
      "Epoch 87/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.4287 - val_loss: 41.1020 - learning_rate: 2.5000e-04\n",
      "Epoch 88/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.0702 - val_loss: 40.9379 - learning_rate: 2.5000e-04\n",
      "Epoch 89/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.1429 - val_loss: 39.7677 - learning_rate: 2.5000e-04\n",
      "Epoch 90/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 67.2936 - val_loss: 39.5288 - learning_rate: 2.5000e-04\n",
      "Epoch 91/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.6488 - val_loss: 40.1885 - learning_rate: 2.5000e-04\n",
      "Epoch 92/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.6201 - val_loss: 40.4219 - learning_rate: 2.5000e-04\n",
      "Epoch 93/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.8341 - val_loss: 39.6088 - learning_rate: 2.5000e-04\n",
      "Epoch 94/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.1564 - val_loss: 39.8364 - learning_rate: 2.5000e-04\n",
      "Epoch 95/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.4781 - val_loss: 40.8660 - learning_rate: 2.5000e-04\n",
      "Epoch 96/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.8189 - val_loss: 40.4893 - learning_rate: 2.5000e-04\n",
      "Epoch 97/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.9190 - val_loss: 40.8765 - learning_rate: 2.5000e-04\n",
      "Epoch 98/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.0084 - val_loss: 40.5023 - learning_rate: 2.5000e-04\n",
      "Epoch 99/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.5553 - val_loss: 40.8533 - learning_rate: 2.5000e-04\n",
      "Epoch 100/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.3933 - val_loss: 40.7822 - learning_rate: 2.5000e-04\n",
      "Epoch 101/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.2704 - val_loss: 38.3816 - learning_rate: 1.2500e-04\n",
      "Epoch 102/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.7248 - val_loss: 37.3992 - learning_rate: 1.2500e-04\n",
      "Epoch 103/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.7945 - val_loss: 37.9583 - learning_rate: 1.2500e-04\n",
      "Epoch 104/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.3037 - val_loss: 37.3479 - learning_rate: 1.2500e-04\n",
      "Epoch 105/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8892 - val_loss: 38.1867 - learning_rate: 1.2500e-04\n",
      "Epoch 106/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.7869 - val_loss: 37.8432 - learning_rate: 1.2500e-04\n",
      "Epoch 107/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.0477 - val_loss: 37.7563 - learning_rate: 1.2500e-04\n",
      "Epoch 108/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0325 - val_loss: 38.1042 - learning_rate: 1.2500e-04\n",
      "Epoch 109/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.3080 - val_loss: 38.4307 - learning_rate: 1.2500e-04\n",
      "Epoch 110/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.1105 - val_loss: 39.0243 - learning_rate: 1.2500e-04\n",
      "Epoch 111/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.4777 - val_loss: 37.4176 - learning_rate: 1.2500e-04\n",
      "Epoch 112/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.9285 - val_loss: 37.3291 - learning_rate: 1.2500e-04\n",
      "Epoch 113/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.8561 - val_loss: 37.7914 - learning_rate: 1.2500e-04\n",
      "Epoch 114/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.5503 - val_loss: 37.2300 - learning_rate: 1.2500e-04\n",
      "Epoch 115/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.1033 - val_loss: 37.8199 - learning_rate: 1.2500e-04\n",
      "Epoch 116/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6769 - val_loss: 37.7830 - learning_rate: 1.2500e-04\n",
      "Epoch 117/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8453 - val_loss: 37.5887 - learning_rate: 1.2500e-04\n",
      "Epoch 118/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6315 - val_loss: 36.7513 - learning_rate: 1.2500e-04\n",
      "Epoch 119/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.9106 - val_loss: 37.5369 - learning_rate: 1.2500e-04\n",
      "Epoch 120/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.8480 - val_loss: 36.5083 - learning_rate: 1.2500e-04\n",
      "Epoch 121/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2812 - val_loss: 37.3317 - learning_rate: 1.2500e-04\n",
      "Epoch 122/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.6902 - val_loss: 38.1907 - learning_rate: 1.2500e-04\n",
      "Epoch 123/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0332 - val_loss: 37.2583 - learning_rate: 1.2500e-04\n",
      "Epoch 124/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8773 - val_loss: 37.3339 - learning_rate: 1.2500e-04\n",
      "Epoch 125/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0603 - val_loss: 38.2191 - learning_rate: 1.2500e-04\n",
      "Epoch 126/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0929 - val_loss: 36.8849 - learning_rate: 1.2500e-04\n",
      "Epoch 127/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1952 - val_loss: 37.7766 - learning_rate: 1.2500e-04\n",
      "Epoch 128/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0344 - val_loss: 37.7008 - learning_rate: 1.2500e-04\n",
      "Epoch 129/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.4414 - val_loss: 37.3211 - learning_rate: 1.2500e-04\n",
      "Epoch 130/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.1129 - val_loss: 36.8328 - learning_rate: 1.2500e-04\n",
      "Epoch 131/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8091 - val_loss: 36.8919 - learning_rate: 6.2500e-05\n",
      "Epoch 132/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6854 - val_loss: 36.0249 - learning_rate: 6.2500e-05\n",
      "Epoch 133/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4890 - val_loss: 37.1095 - learning_rate: 6.2500e-05\n",
      "Epoch 134/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.9404 - val_loss: 36.1813 - learning_rate: 6.2500e-05\n",
      "Epoch 135/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5441 - val_loss: 36.0759 - learning_rate: 6.2500e-05\n",
      "Epoch 136/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6582 - val_loss: 36.3803 - learning_rate: 6.2500e-05\n",
      "Epoch 137/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0969 - val_loss: 36.6938 - learning_rate: 6.2500e-05\n",
      "Epoch 138/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8707 - val_loss: 36.4025 - learning_rate: 6.2500e-05\n",
      "Epoch 139/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0291 - val_loss: 36.0650 - learning_rate: 6.2500e-05\n",
      "Epoch 140/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0294 - val_loss: 37.1502 - learning_rate: 6.2500e-05\n",
      "Epoch 141/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5417 - val_loss: 36.6240 - learning_rate: 6.2500e-05\n",
      "Epoch 142/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.7731 - val_loss: 36.3027 - learning_rate: 6.2500e-05\n",
      "Epoch 143/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3321 - val_loss: 35.6335 - learning_rate: 3.1250e-05\n",
      "Epoch 144/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3131 - val_loss: 35.8592 - learning_rate: 3.1250e-05\n",
      "Epoch 145/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3149 - val_loss: 36.1696 - learning_rate: 3.1250e-05\n",
      "Epoch 146/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.0346 - val_loss: 35.5526 - learning_rate: 3.1250e-05\n",
      "Epoch 147/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1409 - val_loss: 36.1326 - learning_rate: 3.1250e-05\n",
      "Epoch 148/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5492 - val_loss: 35.9948 - learning_rate: 3.1250e-05\n",
      "Epoch 149/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6284 - val_loss: 35.4693 - learning_rate: 3.1250e-05\n",
      "Epoch 150/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8892 - val_loss: 35.8042 - learning_rate: 3.1250e-05\n",
      "Epoch 151/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0153 - val_loss: 35.7172 - learning_rate: 3.1250e-05\n",
      "Epoch 152/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8620 - val_loss: 35.3044 - learning_rate: 3.1250e-05\n",
      "Epoch 153/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9449 - val_loss: 36.0931 - learning_rate: 3.1250e-05\n",
      "Epoch 154/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.3296 - val_loss: 35.8539 - learning_rate: 3.1250e-05\n",
      "Epoch 155/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7440 - val_loss: 35.6323 - learning_rate: 3.1250e-05\n",
      "Epoch 156/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0164 - val_loss: 35.3921 - learning_rate: 3.1250e-05\n",
      "Epoch 157/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0063 - val_loss: 36.3725 - learning_rate: 3.1250e-05\n",
      "Epoch 158/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8488 - val_loss: 35.3377 - learning_rate: 3.1250e-05\n",
      "Epoch 159/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2426 - val_loss: 35.4085 - learning_rate: 3.1250e-05\n",
      "Epoch 160/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4480 - val_loss: 36.3166 - learning_rate: 3.1250e-05\n",
      "Epoch 161/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0764 - val_loss: 36.1930 - learning_rate: 3.1250e-05\n",
      "Epoch 162/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1376 - val_loss: 36.4047 - learning_rate: 3.1250e-05\n",
      "Epoch 163/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0506 - val_loss: 35.7479 - learning_rate: 1.5625e-05\n",
      "Epoch 164/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3685 - val_loss: 35.5023 - learning_rate: 1.5625e-05\n",
      "Epoch 165/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.8176 - val_loss: 35.6677 - learning_rate: 1.5625e-05\n",
      "Epoch 166/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8403 - val_loss: 35.4539 - learning_rate: 1.5625e-05\n",
      "Epoch 167/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0690 - val_loss: 35.3481 - learning_rate: 1.5625e-05\n",
      "Epoch 168/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3000 - val_loss: 35.7259 - learning_rate: 1.5625e-05\n",
      "Epoch 169/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1236 - val_loss: 35.4172 - learning_rate: 1.5625e-05\n",
      "Epoch 170/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4171 - val_loss: 35.3139 - learning_rate: 1.5625e-05\n",
      "Epoch 171/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1630 - val_loss: 35.6470 - learning_rate: 1.5625e-05\n",
      "Epoch 172/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3474 - val_loss: 35.4179 - learning_rate: 1.5625e-05\n",
      "Epoch 173/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6303 - val_loss: 35.1660 - learning_rate: 7.8125e-06\n",
      "Epoch 174/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.6476 - val_loss: 35.3331 - learning_rate: 7.8125e-06\n",
      "Epoch 175/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3382 - val_loss: 35.9265 - learning_rate: 7.8125e-06\n",
      "Epoch 176/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.7860 - val_loss: 35.1330 - learning_rate: 7.8125e-06\n",
      "Epoch 177/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9996 - val_loss: 35.3810 - learning_rate: 7.8125e-06\n",
      "Epoch 178/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7125 - val_loss: 35.2712 - learning_rate: 7.8125e-06\n",
      "Epoch 179/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1910 - val_loss: 35.3124 - learning_rate: 7.8125e-06\n",
      "Epoch 180/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2577 - val_loss: 35.6604 - learning_rate: 7.8125e-06\n",
      "Epoch 181/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0454 - val_loss: 35.3156 - learning_rate: 7.8125e-06\n",
      "Epoch 182/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6990 - val_loss: 35.4751 - learning_rate: 7.8125e-06\n",
      "Epoch 183/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5921 - val_loss: 35.3317 - learning_rate: 7.8125e-06\n",
      "Epoch 184/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.7156 - val_loss: 35.5778 - learning_rate: 7.8125e-06\n",
      "Epoch 185/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9725 - val_loss: 35.4341 - learning_rate: 7.8125e-06\n",
      "Epoch 186/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7618 - val_loss: 34.9658 - learning_rate: 7.8125e-06\n",
      "Epoch 187/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3979 - val_loss: 35.4635 - learning_rate: 7.8125e-06\n",
      "Epoch 188/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0013 - val_loss: 35.6713 - learning_rate: 7.8125e-06\n",
      "Epoch 189/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4670 - val_loss: 35.4662 - learning_rate: 7.8125e-06\n",
      "Epoch 190/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2814 - val_loss: 35.2639 - learning_rate: 7.8125e-06\n",
      "Epoch 191/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4843 - val_loss: 35.1426 - learning_rate: 7.8125e-06\n",
      "Epoch 192/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9149 - val_loss: 35.2551 - learning_rate: 7.8125e-06\n",
      "Epoch 193/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1648 - val_loss: 35.1346 - learning_rate: 7.8125e-06\n",
      "Epoch 194/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5103 - val_loss: 35.7814 - learning_rate: 7.8125e-06\n",
      "Epoch 195/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0018 - val_loss: 35.1009 - learning_rate: 7.8125e-06\n",
      "Epoch 196/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5443 - val_loss: 35.4793 - learning_rate: 7.8125e-06\n",
      "Epoch 197/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6440 - val_loss: 35.3795 - learning_rate: 3.9063e-06\n",
      "Epoch 198/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0931 - val_loss: 35.5174 - learning_rate: 3.9063e-06\n",
      "Epoch 199/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2971 - val_loss: 35.1833 - learning_rate: 3.9063e-06\n",
      "Epoch 200/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1646 - val_loss: 35.2307 - learning_rate: 3.9063e-06\n",
      "Epoch 201/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8626 - val_loss: 35.4423 - learning_rate: 3.9063e-06\n",
      "Epoch 202/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3239 - val_loss: 35.1689 - learning_rate: 3.9063e-06\n",
      "Epoch 203/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1370 - val_loss: 35.0293 - learning_rate: 3.9063e-06\n",
      "Epoch 204/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9724 - val_loss: 35.0554 - learning_rate: 3.9063e-06\n",
      "Epoch 205/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2156 - val_loss: 35.1376 - learning_rate: 3.9063e-06\n",
      "Epoch 206/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4134 - val_loss: 35.6093 - learning_rate: 3.9063e-06\n",
      "Epoch 207/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3259 - val_loss: 35.5980 - learning_rate: 1.9531e-06\n",
      "Epoch 208/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9126 - val_loss: 35.0544 - learning_rate: 1.9531e-06\n",
      "Epoch 209/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3297 - val_loss: 35.2204 - learning_rate: 1.9531e-06\n",
      "Epoch 210/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1095 - val_loss: 34.9308 - learning_rate: 1.9531e-06\n",
      "Epoch 211/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7180 - val_loss: 35.3410 - learning_rate: 1.9531e-06\n",
      "Epoch 212/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3220 - val_loss: 35.2415 - learning_rate: 1.9531e-06\n",
      "Epoch 213/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5370 - val_loss: 35.4380 - learning_rate: 1.9531e-06\n",
      "Epoch 214/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1693 - val_loss: 35.2083 - learning_rate: 1.9531e-06\n",
      "Epoch 215/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1064 - val_loss: 35.0044 - learning_rate: 1.9531e-06\n",
      "Epoch 216/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7608 - val_loss: 35.3115 - learning_rate: 1.9531e-06\n",
      "Epoch 217/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4995 - val_loss: 35.4218 - learning_rate: 1.9531e-06\n",
      "Epoch 218/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3448 - val_loss: 35.5168 - learning_rate: 1.9531e-06\n",
      "Epoch 219/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3584 - val_loss: 35.3747 - learning_rate: 1.9531e-06\n",
      "Epoch 220/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9842 - val_loss: 35.5789 - learning_rate: 1.9531e-06\n",
      "Epoch 221/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.8267 - val_loss: 35.0002 - learning_rate: 1.0000e-06\n",
      "Epoch 222/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6483 - val_loss: 34.9784 - learning_rate: 1.0000e-06\n",
      "Epoch 223/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0899 - val_loss: 35.3343 - learning_rate: 1.0000e-06\n",
      "Epoch 224/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5347 - val_loss: 35.3052 - learning_rate: 1.0000e-06\n",
      "Epoch 225/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3324 - val_loss: 34.9443 - learning_rate: 1.0000e-06\n",
      "Epoch 226/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9434 - val_loss: 35.6112 - learning_rate: 1.0000e-06\n",
      "Epoch 227/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2458 - val_loss: 35.5849 - learning_rate: 1.0000e-06\n",
      "Epoch 228/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2758 - val_loss: 35.0126 - learning_rate: 1.0000e-06\n",
      "Epoch 229/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1463 - val_loss: 34.9818 - learning_rate: 1.0000e-06\n",
      "Epoch 230/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2194 - val_loss: 35.0349 - learning_rate: 1.0000e-06\n",
      "Epoch 231/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3999 - val_loss: 34.6229 - learning_rate: 1.0000e-06\n",
      "Epoch 232/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5388 - val_loss: 35.4583 - learning_rate: 1.0000e-06\n",
      "Epoch 233/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3434 - val_loss: 34.7394 - learning_rate: 1.0000e-06\n",
      "Epoch 234/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2209 - val_loss: 34.8953 - learning_rate: 1.0000e-06\n",
      "Epoch 235/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2817 - val_loss: 34.9828 - learning_rate: 1.0000e-06\n",
      "Epoch 236/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1234 - val_loss: 35.1886 - learning_rate: 1.0000e-06\n",
      "Epoch 237/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0075 - val_loss: 35.0129 - learning_rate: 1.0000e-06\n",
      "Epoch 238/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8310 - val_loss: 35.2288 - learning_rate: 1.0000e-06\n",
      "Epoch 239/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5424 - val_loss: 34.8501 - learning_rate: 1.0000e-06\n",
      "Epoch 240/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9866 - val_loss: 34.8927 - learning_rate: 1.0000e-06\n",
      "Epoch 241/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1292 - val_loss: 34.7337 - learning_rate: 1.0000e-06\n",
      "Epoch 242/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.0895 - val_loss: 35.0812 - learning_rate: 1.0000e-06\n",
      "Epoch 243/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9423 - val_loss: 35.2508 - learning_rate: 1.0000e-06\n",
      "Epoch 244/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7440 - val_loss: 35.3186 - learning_rate: 1.0000e-06\n",
      "Epoch 245/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7432 - val_loss: 34.9927 - learning_rate: 1.0000e-06\n",
      "Epoch 246/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9054 - val_loss: 34.9659 - learning_rate: 1.0000e-06\n",
      "Epoch 247/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4263 - val_loss: 35.2788 - learning_rate: 1.0000e-06\n",
      "Epoch 248/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2749 - val_loss: 35.0100 - learning_rate: 1.0000e-06\n",
      "Epoch 249/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3767 - val_loss: 35.2546 - learning_rate: 1.0000e-06\n",
      "Epoch 250/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4163 - val_loss: 35.0536 - learning_rate: 1.0000e-06\n",
      "Epoch 251/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6202 - val_loss: 34.8072 - learning_rate: 1.0000e-06\n",
      "Epoch 252/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.6217 - val_loss: 35.0849 - learning_rate: 1.0000e-06\n",
      "Epoch 253/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6143 - val_loss: 35.5645 - learning_rate: 1.0000e-06\n",
      "Epoch 254/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3321 - val_loss: 35.1914 - learning_rate: 1.0000e-06\n",
      "Epoch 255/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3354 - val_loss: 34.9918 - learning_rate: 1.0000e-06\n",
      "Epoch 256/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8215 - val_loss: 35.0657 - learning_rate: 1.0000e-06\n",
      "Epoch 257/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5473 - val_loss: 35.0165 - learning_rate: 1.0000e-06\n",
      "Epoch 258/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7649 - val_loss: 35.0694 - learning_rate: 1.0000e-06\n",
      "Epoch 259/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2851 - val_loss: 35.1328 - learning_rate: 1.0000e-06\n",
      "Epoch 260/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7356 - val_loss: 35.1394 - learning_rate: 1.0000e-06\n",
      "Epoch 261/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6217 - val_loss: 35.1721 - learning_rate: 1.0000e-06\n",
      "Epoch 262/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.4496 - val_loss: 35.3656 - learning_rate: 1.0000e-06\n",
      "Epoch 263/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7729 - val_loss: 35.3501 - learning_rate: 1.0000e-06\n",
      "Epoch 264/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1337 - val_loss: 35.4864 - learning_rate: 1.0000e-06\n",
      "Epoch 265/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.9258 - val_loss: 34.8798 - learning_rate: 1.0000e-06\n",
      "Epoch 266/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6500 - val_loss: 35.2720 - learning_rate: 1.0000e-06\n",
      "Epoch 267/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9584 - val_loss: 34.9405 - learning_rate: 1.0000e-06\n",
      "Epoch 268/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0038 - val_loss: 34.7117 - learning_rate: 1.0000e-06\n",
      "Epoch 269/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6305 - val_loss: 35.3627 - learning_rate: 1.0000e-06\n",
      "Epoch 270/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9122 - val_loss: 34.9727 - learning_rate: 1.0000e-06\n",
      "Epoch 271/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.7791 - val_loss: 35.0390 - learning_rate: 1.0000e-06\n",
      "Epoch 272/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3583 - val_loss: 35.0650 - learning_rate: 1.0000e-06\n",
      "Epoch 273/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6030 - val_loss: 35.2382 - learning_rate: 1.0000e-06\n",
      "Epoch 274/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7800 - val_loss: 34.9705 - learning_rate: 1.0000e-06\n",
      "Epoch 275/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7106 - val_loss: 34.9781 - learning_rate: 1.0000e-06\n",
      "Epoch 276/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2832 - val_loss: 35.0509 - learning_rate: 1.0000e-06\n",
      "Epoch 277/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2480 - val_loss: 35.2631 - learning_rate: 1.0000e-06\n",
      "Epoch 278/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0778 - val_loss: 35.5069 - learning_rate: 1.0000e-06\n",
      "Epoch 279/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.5321 - val_loss: 35.0513 - learning_rate: 1.0000e-06\n",
      "Epoch 280/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4296 - val_loss: 35.0184 - learning_rate: 1.0000e-06\n",
      "Epoch 281/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.5083 - val_loss: 34.9220 - learning_rate: 1.0000e-06\n",
      "Epoch 282/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3780 - val_loss: 35.1905 - learning_rate: 1.0000e-06\n",
      "Epoch 283/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4725 - val_loss: 35.0361 - learning_rate: 1.0000e-06\n",
      "Epoch 284/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1815 - val_loss: 35.3535 - learning_rate: 1.0000e-06\n",
      "Epoch 285/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3600 - val_loss: 35.0278 - learning_rate: 1.0000e-06\n",
      "Epoch 286/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2013 - val_loss: 35.2597 - learning_rate: 1.0000e-06\n",
      "Epoch 287/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.2657 - val_loss: 35.4574 - learning_rate: 1.0000e-06\n",
      "Epoch 288/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.2819 - val_loss: 35.2495 - learning_rate: 1.0000e-06\n",
      "Epoch 289/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9172 - val_loss: 35.2846 - learning_rate: 1.0000e-06\n",
      "Epoch 290/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.0934 - val_loss: 35.2778 - learning_rate: 1.0000e-06\n",
      "Epoch 291/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7733 - val_loss: 35.1933 - learning_rate: 1.0000e-06\n",
      "Epoch 292/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.9782 - val_loss: 35.0036 - learning_rate: 1.0000e-06\n",
      "Epoch 293/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.7888 - val_loss: 35.4887 - learning_rate: 1.0000e-06\n",
      "Epoch 294/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.3771 - val_loss: 34.9449 - learning_rate: 1.0000e-06\n",
      "Epoch 295/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.4643 - val_loss: 35.0192 - learning_rate: 1.0000e-06\n",
      "Epoch 296/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.1266 - val_loss: 35.1484 - learning_rate: 1.0000e-06\n",
      "Epoch 297/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3681 - val_loss: 35.2560 - learning_rate: 1.0000e-06\n",
      "Epoch 298/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.8190 - val_loss: 34.8103 - learning_rate: 1.0000e-06\n",
      "Epoch 299/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.6065 - val_loss: 35.3428 - learning_rate: 1.0000e-06\n",
      "Epoch 300/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9684 - val_loss: 35.2072 - learning_rate: 1.0000e-06\n",
      "Epoch 301/10000\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.9140 - val_loss: 35.2290 - learning_rate: 1.0000e-06\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 34.5446\n",
      "Test Loss: 34.61167526245117\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "istory = model.fit(X_train, y_train, epochs=10000, validation_split=0.15, batch_size=128, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(istory.history['loss'], label='Training Loss')\n",
    "plt.plot(istory.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step\n",
      "Predicted Solar Energy Ouput: [430.88311767578125, 125.16282653808594, 938.4105224609375, 564.237060546875, 304.5792541503906, 286.64794921875, 500.0708312988281, 848.8567504882812, 579.801025390625, 554.027099609375, 948.560791015625, 110.82482147216797, 968.2252197265625, 144.90594482421875, 145.1515655517578, 956.0179443359375, 1081.5330810546875, 212.81826782226562, 388.2565002441406, 213.42526245117188]\n",
      "Actual Solar Energy Output: [ 428.  113.  973.  564.  372.  280.  491.  841.  600.  542.  994.   38.\n",
      " 1032.  148.  172. 1055. 1064.  190.  394.  215.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "predictions[predictions < 0] = 0\n",
    "flattened_predictions = [0 if (isinstance(pred, np.ndarray) and pred.item() < 0) else (0 if pred < 0 else pred.item() if isinstance(pred, np.ndarray) else pred) for pred in predictions]\n",
    "\n",
    "print(f'Predicted Solar Energy Ouput: {flattened_predictions[:20]}')\n",
    "print(f'Actual Solar Energy Output: {y_test[:20].values}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 32.959901446840256\n",
      "Mean Squared Error (MSE): 2104.4198158403715\n",
      "Root Mean Squared Error (RMSE): 45.87395574659298\n",
      "Percent Error (PERR): 0.08530493630991995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming predictions and y_test are numpy arrays or pandas series\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "average_y_test = np.mean(y_test)\n",
    "percent_error = mae / average_y_test\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Percent Error (PERR): {percent_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('WindModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
